"use strict";(self.webpackChunk_N_E=self.webpackChunk_N_E||[]).push([[935],{2445:(e,t,r)=>{r.r(t),r.d(t,{ASTFeatureExtractor:()=>u,ASTForAudioClassification:()=>m,ASTModel:()=>p,ASTPreTrainedModel:()=>_,AlbertForMaskedLM:()=>h,AlbertForQuestionAnswering:()=>g,AlbertForSequenceClassification:()=>f,AlbertModel:()=>M,AlbertPreTrainedModel:()=>w,AlbertTokenizer:()=>T,ArceeForCausalLM:()=>P,ArceeModel:()=>x,ArceePreTrainedModel:()=>b,AudioClassificationPipeline:()=>F,AutoConfig:()=>k,AutoFeatureExtractor:()=>y,AutoImageProcessor:()=>v,AutoModel:()=>C,AutoModelForAudioClassification:()=>S,AutoModelForAudioFrameClassification:()=>E,AutoModelForAudioTextToText:()=>A,AutoModelForCTC:()=>L,AutoModelForCausalLM:()=>I,AutoModelForDepthEstimation:()=>D,AutoModelForDocumentQuestionAnswering:()=>z,AutoModelForImageClassification:()=>j,AutoModelForImageFeatureExtraction:()=>V,AutoModelForImageMatting:()=>O,AutoModelForImageSegmentation:()=>N,AutoModelForImageTextToText:()=>B,AutoModelForImageToImage:()=>G,AutoModelForMaskGeneration:()=>R,AutoModelForMaskedLM:()=>q,AutoModelForNormalEstimation:()=>$,AutoModelForObjectDetection:()=>W,AutoModelForPoseEstimation:()=>U,AutoModelForQuestionAnswering:()=>Q,AutoModelForSemanticSegmentation:()=>X,AutoModelForSeq2SeqLM:()=>H,AutoModelForSequenceClassification:()=>J,AutoModelForSpeechSeq2Seq:()=>Y,AutoModelForTextToSpectrogram:()=>K,AutoModelForTextToWaveform:()=>Z,AutoModelForTokenClassification:()=>ee,AutoModelForUniversalSegmentation:()=>et,AutoModelForVision2Seq:()=>er,AutoModelForXVector:()=>eo,AutoModelForZeroShotObjectDetection:()=>es,AutoProcessor:()=>ea,AutoTokenizer:()=>ei,AutomaticSpeechRecognitionPipeline:()=>en,BackgroundRemovalPipeline:()=>el,BartForConditionalGeneration:()=>ec,BartForSequenceClassification:()=>ed,BartModel:()=>eu,BartPretrainedModel:()=>em,BartTokenizer:()=>ep,BaseModelOutput:()=>e_,BaseStreamer:()=>eh,BeitFeatureExtractor:()=>eg,BeitForImageClassification:()=>ef,BeitModel:()=>eM,BeitPreTrainedModel:()=>ew,BertForMaskedLM:()=>eT,BertForQuestionAnswering:()=>eP,BertForSequenceClassification:()=>ex,BertForTokenClassification:()=>eb,BertModel:()=>eF,BertPreTrainedModel:()=>ek,BertTokenizer:()=>ey,BitImageProcessor:()=>ev,BlenderbotForConditionalGeneration:()=>eC,BlenderbotModel:()=>eS,BlenderbotPreTrainedModel:()=>eE,BlenderbotSmallForConditionalGeneration:()=>eA,BlenderbotSmallModel:()=>eL,BlenderbotSmallPreTrainedModel:()=>eI,BlenderbotSmallTokenizer:()=>eD,BlenderbotTokenizer:()=>ez,BloomForCausalLM:()=>ej,BloomModel:()=>eV,BloomPreTrainedModel:()=>eO,BloomTokenizer:()=>eN,CLIPFeatureExtractor:()=>eB,CLIPImageProcessor:()=>eG,CLIPModel:()=>eR,CLIPPreTrainedModel:()=>eq,CLIPSegForImageSegmentation:()=>e$,CLIPSegModel:()=>eW,CLIPSegPreTrainedModel:()=>eU,CLIPTextModel:()=>eQ,CLIPTextModelWithProjection:()=>eX,CLIPTokenizer:()=>eH,CLIPVisionModel:()=>eJ,CLIPVisionModelWithProjection:()=>eY,CamembertForMaskedLM:()=>eK,CamembertForQuestionAnswering:()=>eZ,CamembertForSequenceClassification:()=>e0,CamembertForTokenClassification:()=>e1,CamembertModel:()=>e2,CamembertPreTrainedModel:()=>e3,CamembertTokenizer:()=>e4,CausalLMOutput:()=>e5,CausalLMOutputWithPast:()=>e8,ChineseCLIPFeatureExtractor:()=>e6,ChineseCLIPModel:()=>e9,ChineseCLIPPreTrainedModel:()=>e7,ClapAudioModelWithProjection:()=>te,ClapFeatureExtractor:()=>tt,ClapModel:()=>tr,ClapPreTrainedModel:()=>to,ClapTextModelWithProjection:()=>ts,ClassifierFreeGuidanceLogitsProcessor:()=>ta,CodeGenForCausalLM:()=>ti,CodeGenModel:()=>tn,CodeGenPreTrainedModel:()=>tl,CodeGenTokenizer:()=>tc,CodeLlamaTokenizer:()=>td,CohereForCausalLM:()=>tu,CohereModel:()=>tm,CoherePreTrainedModel:()=>tp,CohereTokenizer:()=>t_,ConvBertForMaskedLM:()=>th,ConvBertForQuestionAnswering:()=>tg,ConvBertForSequenceClassification:()=>tf,ConvBertForTokenClassification:()=>tM,ConvBertModel:()=>tw,ConvBertPreTrainedModel:()=>tT,ConvBertTokenizer:()=>tP,ConvNextFeatureExtractor:()=>tx,ConvNextForImageClassification:()=>tb,ConvNextImageProcessor:()=>tF,ConvNextModel:()=>tk,ConvNextPreTrainedModel:()=>ty,ConvNextV2ForImageClassification:()=>tv,ConvNextV2Model:()=>tC,ConvNextV2PreTrainedModel:()=>tS,DFineForObjectDetection:()=>tE,DFineModel:()=>tA,DFinePreTrainedModel:()=>tL,DINOv3ConvNextModel:()=>tI,DINOv3ConvNextPreTrainedModel:()=>tD,DINOv3ViTImageProcessor:()=>tz,DINOv3ViTModel:()=>tj,DINOv3ViTPreTrainedModel:()=>tV,DPTFeatureExtractor:()=>tO,DPTForDepthEstimation:()=>tN,DPTImageProcessor:()=>tB,DPTModel:()=>tG,DPTPreTrainedModel:()=>tR,DacDecoderModel:()=>tq,DacDecoderOutput:()=>t$,DacEncoderModel:()=>tW,DacEncoderOutput:()=>tU,DacFeatureExtractor:()=>tQ,DacModel:()=>tX,DacPreTrainedModel:()=>tH,DataTypeMap:()=>tJ,DebertaForMaskedLM:()=>tY,DebertaForQuestionAnswering:()=>tK,DebertaForSequenceClassification:()=>tZ,DebertaForTokenClassification:()=>t0,DebertaModel:()=>t1,DebertaPreTrainedModel:()=>t2,DebertaTokenizer:()=>t3,DebertaV2ForMaskedLM:()=>t4,DebertaV2ForQuestionAnswering:()=>t5,DebertaV2ForSequenceClassification:()=>t8,DebertaV2ForTokenClassification:()=>t6,DebertaV2Model:()=>t9,DebertaV2PreTrainedModel:()=>t7,DebertaV2Tokenizer:()=>re,DecisionTransformerModel:()=>rt,DecisionTransformerPreTrainedModel:()=>rr,DeiTFeatureExtractor:()=>ro,DeiTForImageClassification:()=>rs,DeiTImageProcessor:()=>ra,DeiTModel:()=>ri,DeiTPreTrainedModel:()=>rn,DepthAnythingForDepthEstimation:()=>rl,DepthAnythingPreTrainedModel:()=>rc,DepthEstimationPipeline:()=>rd,DepthProForDepthEstimation:()=>ru,DepthProPreTrainedModel:()=>rm,DetrFeatureExtractor:()=>rp,DetrForObjectDetection:()=>r_,DetrForSegmentation:()=>rh,DetrImageProcessor:()=>rg,DetrModel:()=>rf,DetrObjectDetectionOutput:()=>rM,DetrPreTrainedModel:()=>rw,DetrSegmentationOutput:()=>rT,Dinov2ForImageClassification:()=>rP,Dinov2Model:()=>rx,Dinov2PreTrainedModel:()=>rb,Dinov2WithRegistersForImageClassification:()=>rF,Dinov2WithRegistersModel:()=>rk,Dinov2WithRegistersPreTrainedModel:()=>ry,DistilBertForMaskedLM:()=>rv,DistilBertForQuestionAnswering:()=>rC,DistilBertForSequenceClassification:()=>rS,DistilBertForTokenClassification:()=>rE,DistilBertModel:()=>rA,DistilBertPreTrainedModel:()=>rL,DistilBertTokenizer:()=>rI,DocumentQuestionAnsweringPipeline:()=>rD,DonutFeatureExtractor:()=>rz,DonutImageProcessor:()=>rj,DonutSwinModel:()=>rV,DonutSwinPreTrainedModel:()=>rO,EdgeTamModel:()=>rN,EfficientNetForImageClassification:()=>rB,EfficientNetImageProcessor:()=>rG,EfficientNetModel:()=>rR,EfficientNetPreTrainedModel:()=>rq,ElectraForMaskedLM:()=>r$,ElectraForQuestionAnswering:()=>rW,ElectraForSequenceClassification:()=>rU,ElectraForTokenClassification:()=>rQ,ElectraModel:()=>rX,ElectraPreTrainedModel:()=>rH,ElectraTokenizer:()=>rJ,EncodecFeatureExtractor:()=>rY,EosTokenCriteria:()=>rK,Ernie4_5ForCausalLM:()=>rZ,Ernie4_5Model:()=>r0,Ernie4_5PreTrainedModel:()=>r1,EsmForMaskedLM:()=>r2,EsmForSequenceClassification:()=>r3,EsmForTokenClassification:()=>r4,EsmModel:()=>r5,EsmPreTrainedModel:()=>r8,EsmTokenizer:()=>r6,ExaoneForCausalLM:()=>r9,ExaoneModel:()=>r7,ExaonePreTrainedModel:()=>oe,FFT:()=>ot,FalconForCausalLM:()=>or,FalconModel:()=>oo,FalconPreTrainedModel:()=>os,FalconTokenizer:()=>oa,FastViTForImageClassification:()=>oi,FastViTModel:()=>on,FastViTPreTrainedModel:()=>ol,FeatureExtractionPipeline:()=>oc,FeatureExtractor:()=>od,FillMaskPipeline:()=>ou,Florence2ForConditionalGeneration:()=>om,Florence2PreTrainedModel:()=>op,Florence2Processor:()=>o_,ForcedBOSTokenLogitsProcessor:()=>oh,ForcedEOSTokenLogitsProcessor:()=>og,GLPNFeatureExtractor:()=>of,GLPNForDepthEstimation:()=>oM,GLPNModel:()=>ow,GLPNPreTrainedModel:()=>oT,GPT2LMHeadModel:()=>oP,GPT2Model:()=>ox,GPT2PreTrainedModel:()=>ob,GPT2Tokenizer:()=>oF,GPTBigCodeForCausalLM:()=>ok,GPTBigCodeModel:()=>oy,GPTBigCodePreTrainedModel:()=>ov,GPTJForCausalLM:()=>oC,GPTJModel:()=>oS,GPTJPreTrainedModel:()=>oE,GPTNeoForCausalLM:()=>oA,GPTNeoModel:()=>oL,GPTNeoPreTrainedModel:()=>oI,GPTNeoXForCausalLM:()=>oD,GPTNeoXModel:()=>oz,GPTNeoXPreTrainedModel:()=>oj,GPTNeoXTokenizer:()=>oV,Gemma2ForCausalLM:()=>oO,Gemma2Model:()=>oN,Gemma2PreTrainedModel:()=>oB,Gemma3ForCausalLM:()=>oG,Gemma3Model:()=>oR,Gemma3PreTrainedModel:()=>oq,Gemma3nAudioFeatureExtractor:()=>o$,Gemma3nForConditionalGeneration:()=>oW,Gemma3nPreTrainedModel:()=>oU,Gemma3nProcessor:()=>oQ,GemmaForCausalLM:()=>oX,GemmaModel:()=>oH,GemmaPreTrainedModel:()=>oJ,GemmaTokenizer:()=>oY,GlmForCausalLM:()=>oK,GlmModel:()=>oZ,GlmPreTrainedModel:()=>o0,GraniteForCausalLM:()=>o1,GraniteModel:()=>o2,GraniteMoeHybridForCausalLM:()=>o3,GraniteMoeHybridModel:()=>o4,GraniteMoeHybridPreTrainedModel:()=>o5,GranitePreTrainedModel:()=>o8,Grok1Tokenizer:()=>o6,GroundingDinoForObjectDetection:()=>o9,GroundingDinoImageProcessor:()=>o7,GroundingDinoPreTrainedModel:()=>se,GroundingDinoProcessor:()=>st,GroupViTModel:()=>sr,GroupViTPreTrainedModel:()=>so,HeliumForCausalLM:()=>ss,HeliumModel:()=>sa,HeliumPreTrainedModel:()=>si,HerbertTokenizer:()=>sn,HieraForImageClassification:()=>sl,HieraModel:()=>sc,HieraPreTrainedModel:()=>sd,HubertForCTC:()=>su,HubertForSequenceClassification:()=>sm,HubertModel:()=>sp,HubertPreTrainedModel:()=>s_,IJepaForImageClassification:()=>sh,IJepaModel:()=>sg,IJepaPreTrainedModel:()=>sf,Idefics3ForConditionalGeneration:()=>sM,Idefics3ImageProcessor:()=>sw,Idefics3PreTrainedModel:()=>sT,Idefics3Processor:()=>sP,ImageClassificationPipeline:()=>sx,ImageFeatureExtractionPipeline:()=>sb,ImageFeatureExtractor:()=>sF,ImageMattingOutput:()=>sk,ImageProcessor:()=>sy,ImageSegmentationPipeline:()=>sv,ImageToImagePipeline:()=>sC,ImageToTextPipeline:()=>sS,InterruptableStoppingCriteria:()=>sE,JAISLMHeadModel:()=>sA,JAISModel:()=>sL,JAISPreTrainedModel:()=>sI,JinaCLIPImageProcessor:()=>sD,JinaCLIPModel:()=>sz,JinaCLIPPreTrainedModel:()=>sj,JinaCLIPProcessor:()=>sV,JinaCLIPTextModel:()=>sO,JinaCLIPVisionModel:()=>sN,Lfm2ForCausalLM:()=>sB,Lfm2Model:()=>sG,Lfm2PreTrainedModel:()=>sR,LiteWhisperForConditionalGeneration:()=>sq,Llama4ForCausalLM:()=>s$,Llama4PreTrainedModel:()=>sW,LlamaForCausalLM:()=>sU,LlamaModel:()=>sQ,LlamaPreTrainedModel:()=>sX,LlamaTokenizer:()=>sH,LlavaForConditionalGeneration:()=>sJ,LlavaOnevisionForConditionalGeneration:()=>sY,LlavaOnevisionImageProcessor:()=>sK,LlavaPreTrainedModel:()=>sZ,LlavaProcessor:()=>s0,LlavaQwen2ForCausalLM:()=>s1,LogitsProcessor:()=>s2,LogitsProcessorList:()=>s3,LogitsWarper:()=>s4,LongT5ForConditionalGeneration:()=>s5,LongT5Model:()=>s8,LongT5PreTrainedModel:()=>s6,M2M100ForConditionalGeneration:()=>s9,M2M100Model:()=>s7,M2M100PreTrainedModel:()=>ae,M2M100Tokenizer:()=>at,MBart50Tokenizer:()=>ar,MBartForCausalLM:()=>ao,MBartForConditionalGeneration:()=>as,MBartForSequenceClassification:()=>aa,MBartModel:()=>ai,MBartPreTrainedModel:()=>an,MBartTokenizer:()=>al,MPNetForMaskedLM:()=>ac,MPNetForQuestionAnswering:()=>ad,MPNetForSequenceClassification:()=>au,MPNetForTokenClassification:()=>am,MPNetModel:()=>ap,MPNetPreTrainedModel:()=>a_,MPNetTokenizer:()=>ah,MT5ForConditionalGeneration:()=>ag,MT5Model:()=>af,MT5PreTrainedModel:()=>aM,MarianMTModel:()=>aw,MarianModel:()=>aT,MarianPreTrainedModel:()=>aP,MarianTokenizer:()=>ax,Mask2FormerImageProcessor:()=>ab,MaskFormerFeatureExtractor:()=>aF,MaskFormerForInstanceSegmentation:()=>ak,MaskFormerImageProcessor:()=>ay,MaskFormerModel:()=>av,MaskFormerPreTrainedModel:()=>aC,MaskedLMOutput:()=>aS,MaxLengthCriteria:()=>aE,Metric3DForDepthEstimation:()=>aA,Metric3DPreTrainedModel:()=>aL,Metric3Dv2ForDepthEstimation:()=>aI,Metric3Dv2PreTrainedModel:()=>aD,MgpstrForSceneTextRecognition:()=>az,MgpstrModelOutput:()=>aj,MgpstrPreTrainedModel:()=>aV,MgpstrProcessor:()=>aO,MgpstrTokenizer:()=>aN,MimiDecoderModel:()=>aB,MimiDecoderOutput:()=>aG,MimiEncoderModel:()=>aR,MimiEncoderOutput:()=>aq,MimiModel:()=>a$,MimiPreTrainedModel:()=>aW,MinLengthLogitsProcessor:()=>aU,MinNewTokensLengthLogitsProcessor:()=>aQ,Ministral3ForCausalLM:()=>aX,Ministral3Model:()=>aH,Ministral3PreTrainedModel:()=>aJ,MinistralForCausalLM:()=>aY,MinistralModel:()=>aK,MinistralPreTrainedModel:()=>aZ,Mistral3ForConditionalGeneration:()=>a0,MistralForCausalLM:()=>a1,MistralModel:()=>a2,MistralPreTrainedModel:()=>a3,MobileBertForMaskedLM:()=>a4,MobileBertForQuestionAnswering:()=>a5,MobileBertForSequenceClassification:()=>a8,MobileBertModel:()=>a6,MobileBertPreTrainedModel:()=>a9,MobileBertTokenizer:()=>a7,MobileLLMForCausalLM:()=>ie,MobileLLMModel:()=>it,MobileLLMPreTrainedModel:()=>ir,MobileNetV1FeatureExtractor:()=>io,MobileNetV1ForImageClassification:()=>is,MobileNetV1ForSemanticSegmentation:()=>ia,MobileNetV1ImageProcessor:()=>ii,MobileNetV1Model:()=>il,MobileNetV1PreTrainedModel:()=>ic,MobileNetV2FeatureExtractor:()=>id,MobileNetV2ForImageClassification:()=>iu,MobileNetV2ForSemanticSegmentation:()=>im,MobileNetV2ImageProcessor:()=>ip,MobileNetV2Model:()=>i_,MobileNetV2PreTrainedModel:()=>ih,MobileNetV3FeatureExtractor:()=>ig,MobileNetV3ForImageClassification:()=>iM,MobileNetV3ForSemanticSegmentation:()=>iw,MobileNetV3ImageProcessor:()=>iT,MobileNetV3Model:()=>iP,MobileNetV3PreTrainedModel:()=>ix,MobileNetV4FeatureExtractor:()=>ib,MobileNetV4ForImageClassification:()=>iF,MobileNetV4ForSemanticSegmentation:()=>ik,MobileNetV4ImageProcessor:()=>iy,MobileNetV4Model:()=>iv,MobileNetV4PreTrainedModel:()=>iC,MobileViTFeatureExtractor:()=>iS,MobileViTForImageClassification:()=>iE,MobileViTImageProcessor:()=>iA,MobileViTModel:()=>iL,MobileViTPreTrainedModel:()=>iI,MobileViTV2ForImageClassification:()=>iD,MobileViTV2Model:()=>iz,MobileViTV2PreTrainedModel:()=>ij,ModelOutput:()=>iV,ModernBertDecoderForCausalLM:()=>iO,ModernBertDecoderModel:()=>iN,ModernBertDecoderPreTrainedModel:()=>iB,ModernBertForMaskedLM:()=>iG,ModernBertForSequenceClassification:()=>iR,ModernBertForTokenClassification:()=>iq,ModernBertModel:()=>i$,ModernBertPreTrainedModel:()=>iW,Moondream1ForConditionalGeneration:()=>iU,MoonshineFeatureExtractor:()=>iQ,MoonshineForConditionalGeneration:()=>iX,MoonshineModel:()=>iH,MoonshinePreTrainedModel:()=>iJ,MoonshineProcessor:()=>iY,MptForCausalLM:()=>iK,MptModel:()=>iZ,MptPreTrainedModel:()=>i0,MultiModalityCausalLM:()=>i1,MultiModalityPreTrainedModel:()=>i2,MusicgenForCausalLM:()=>i3,MusicgenForConditionalGeneration:()=>i4,MusicgenModel:()=>i5,MusicgenPreTrainedModel:()=>i8,NanoChatForCausalLM:()=>i6,NanoChatModel:()=>i9,NanoChatPreTrainedModel:()=>i7,NeoBertForMaskedLM:()=>ne,NeoBertForQuestionAnswering:()=>nt,NeoBertForSequenceClassification:()=>nr,NeoBertForTokenClassification:()=>no,NeoBertModel:()=>ns,NeoBertPreTrainedModel:()=>na,NllbTokenizer:()=>ni,NoBadWordsLogitsProcessor:()=>nn,NoRepeatNGramLogitsProcessor:()=>nl,NomicBertModel:()=>nc,NomicBertPreTrainedModel:()=>nd,NougatImageProcessor:()=>nu,NougatTokenizer:()=>nm,OPTForCausalLM:()=>np,OPTModel:()=>n_,OPTPreTrainedModel:()=>nh,ObjectDetectionPipeline:()=>ng,Olmo2ForCausalLM:()=>nf,Olmo2Model:()=>nM,Olmo2PreTrainedModel:()=>nw,OlmoForCausalLM:()=>nT,OlmoModel:()=>nP,OlmoPreTrainedModel:()=>nx,OpenELMForCausalLM:()=>nb,OpenELMModel:()=>nF,OpenELMPreTrainedModel:()=>nk,OwlViTFeatureExtractor:()=>ny,OwlViTForObjectDetection:()=>nv,OwlViTImageProcessor:()=>nC,OwlViTModel:()=>nS,OwlViTPreTrainedModel:()=>nE,OwlViTProcessor:()=>nA,Owlv2ForObjectDetection:()=>nL,Owlv2ImageProcessor:()=>nI,Owlv2Model:()=>nD,Owlv2PreTrainedModel:()=>nz,PaliGemmaForConditionalGeneration:()=>nj,PaliGemmaPreTrainedModel:()=>nV,PaliGemmaProcessor:()=>nO,ParakeetFeatureExtractor:()=>nN,ParakeetForCTC:()=>nB,ParakeetPreTrainedModel:()=>nG,PatchTSMixerForPrediction:()=>nR,PatchTSMixerModel:()=>nq,PatchTSMixerPreTrainedModel:()=>n$,PatchTSTForPrediction:()=>nW,PatchTSTModel:()=>nU,PatchTSTPreTrainedModel:()=>nQ,Phi3ForCausalLM:()=>nX,Phi3Model:()=>nH,Phi3PreTrainedModel:()=>nJ,Phi3VForCausalLM:()=>nY,Phi3VImageProcessor:()=>nK,Phi3VPreTrainedModel:()=>nZ,Phi3VProcessor:()=>n0,PhiForCausalLM:()=>n1,PhiModel:()=>n2,PhiPreTrainedModel:()=>n3,Pipeline:()=>n4,PixtralImageProcessor:()=>n5,PixtralProcessor:()=>n8,PreTrainedModel:()=>n6,PreTrainedTokenizer:()=>n9,PretrainedConfig:()=>n7,PretrainedMixin:()=>le,Processor:()=>lt,PvtForImageClassification:()=>lr,PvtImageProcessor:()=>lo,PvtModel:()=>ls,PvtPreTrainedModel:()=>la,PyAnnoteFeatureExtractor:()=>li,PyAnnoteForAudioFrameClassification:()=>ln,PyAnnoteModel:()=>ll,PyAnnotePreTrainedModel:()=>lc,PyAnnoteProcessor:()=>ld,QuestionAnsweringModelOutput:()=>lu,QuestionAnsweringPipeline:()=>lm,Qwen2ForCausalLM:()=>lp,Qwen2Model:()=>l_,Qwen2PreTrainedModel:()=>lh,Qwen2Tokenizer:()=>lg,Qwen2VLForConditionalGeneration:()=>lf,Qwen2VLImageProcessor:()=>lM,Qwen2VLPreTrainedModel:()=>lw,Qwen2VLProcessor:()=>lT,Qwen3ForCausalLM:()=>lP,Qwen3Model:()=>lx,Qwen3PreTrainedModel:()=>lb,RFDetrForObjectDetection:()=>lF,RFDetrModel:()=>lk,RFDetrObjectDetectionOutput:()=>ly,RFDetrPreTrainedModel:()=>lv,RTDetrForObjectDetection:()=>lC,RTDetrImageProcessor:()=>lS,RTDetrModel:()=>lE,RTDetrObjectDetectionOutput:()=>lA,RTDetrPreTrainedModel:()=>lL,RTDetrV2ForObjectDetection:()=>lI,RTDetrV2Model:()=>lD,RTDetrV2ObjectDetectionOutput:()=>lz,RTDetrV2PreTrainedModel:()=>lj,RawAudio:()=>lV,RawImage:()=>lO,RawVideo:()=>lN,RawVideoFrame:()=>lB,RepetitionPenaltyLogitsProcessor:()=>lG,ResNetForImageClassification:()=>lR,ResNetModel:()=>lq,ResNetPreTrainedModel:()=>l$,RoFormerForMaskedLM:()=>lW,RoFormerForQuestionAnswering:()=>lU,RoFormerForSequenceClassification:()=>lQ,RoFormerForTokenClassification:()=>lX,RoFormerModel:()=>lH,RoFormerPreTrainedModel:()=>lJ,RoFormerTokenizer:()=>lY,RobertaForMaskedLM:()=>lK,RobertaForQuestionAnswering:()=>lZ,RobertaForSequenceClassification:()=>l0,RobertaForTokenClassification:()=>l1,RobertaModel:()=>l2,RobertaPreTrainedModel:()=>l3,RobertaTokenizer:()=>l4,Sam2ImageProcessor:()=>l5,Sam2ImageSegmentationOutput:()=>l8,Sam2Model:()=>l6,Sam2PreTrainedModel:()=>l9,Sam2Processor:()=>l7,Sam2VideoProcessor:()=>ce,Sam3ImageProcessor:()=>ct,Sam3TrackerModel:()=>cr,SamImageProcessor:()=>co,SamImageSegmentationOutput:()=>cs,SamModel:()=>ca,SamPreTrainedModel:()=>ci,SamProcessor:()=>cn,SapiensForDepthEstimation:()=>cl,SapiensForNormalEstimation:()=>cc,SapiensForSemanticSegmentation:()=>cd,SapiensPreTrainedModel:()=>cu,SeamlessM4TFeatureExtractor:()=>cm,SegformerFeatureExtractor:()=>cp,SegformerForImageClassification:()=>c_,SegformerForSemanticSegmentation:()=>ch,SegformerImageProcessor:()=>cg,SegformerModel:()=>cf,SegformerPreTrainedModel:()=>cM,Seq2SeqLMOutput:()=>cw,SequenceClassifierOutput:()=>cT,SiglipImageProcessor:()=>cP,SiglipModel:()=>cx,SiglipPreTrainedModel:()=>cb,SiglipTextModel:()=>cF,SiglipTokenizer:()=>ck,SiglipVisionModel:()=>cy,SmolLM3ForCausalLM:()=>cv,SmolLM3Model:()=>cC,SmolLM3PreTrainedModel:()=>cS,SmolVLMForConditionalGeneration:()=>cE,SmolVLMImageProcessor:()=>cA,SmolVLMProcessor:()=>cL,SnacDecoderModel:()=>cI,SnacEncoderModel:()=>cD,SnacFeatureExtractor:()=>cz,SnacModel:()=>cj,SnacPreTrainedModel:()=>cV,SpeechT5FeatureExtractor:()=>cO,SpeechT5ForSpeechToText:()=>cN,SpeechT5ForTextToSpeech:()=>cB,SpeechT5HifiGan:()=>cG,SpeechT5Model:()=>cR,SpeechT5PreTrainedModel:()=>cq,SpeechT5Processor:()=>c$,SpeechT5Tokenizer:()=>cW,SqueezeBertForMaskedLM:()=>cU,SqueezeBertForQuestionAnswering:()=>cQ,SqueezeBertForSequenceClassification:()=>cX,SqueezeBertModel:()=>cH,SqueezeBertPreTrainedModel:()=>cJ,SqueezeBertTokenizer:()=>cY,StableLmForCausalLM:()=>cK,StableLmModel:()=>cZ,StableLmPreTrainedModel:()=>c0,Starcoder2ForCausalLM:()=>c1,Starcoder2Model:()=>c2,Starcoder2PreTrainedModel:()=>c3,StoppingCriteria:()=>c4,StoppingCriteriaList:()=>c5,StyleTextToSpeech2Model:()=>c8,StyleTextToSpeech2PreTrainedModel:()=>c6,SummarizationPipeline:()=>c9,SupertonicForConditionalGeneration:()=>c7,SupertonicPreTrainedModel:()=>de,SuppressTokensAtBeginLogitsProcessor:()=>dt,Swin2SRForImageSuperResolution:()=>dr,Swin2SRImageProcessor:()=>ds,Swin2SRModel:()=>da,Swin2SRPreTrainedModel:()=>di,SwinForImageClassification:()=>dn,SwinForSemanticSegmentation:()=>dl,SwinModel:()=>dc,SwinPreTrainedModel:()=>dd,T5ForConditionalGeneration:()=>du,T5Model:()=>dm,T5PreTrainedModel:()=>dp,T5Tokenizer:()=>d_,TableTransformerForObjectDetection:()=>dh,TableTransformerModel:()=>dg,TableTransformerObjectDetectionOutput:()=>df,TableTransformerPreTrainedModel:()=>dM,TemperatureLogitsWarper:()=>dw,Tensor:()=>dT,Text2TextGenerationPipeline:()=>dP,TextClassificationPipeline:()=>dx,TextGenerationPipeline:()=>db,TextStreamer:()=>dF,TextToAudioPipeline:()=>dk,TokenClassificationPipeline:()=>dy,TokenClassifierOutput:()=>dv,TokenizerModel:()=>dC,TopKLogitsWarper:()=>dS,TopPLogitsWarper:()=>dE,TrOCRForCausalLM:()=>dA,TrOCRPreTrainedModel:()=>dL,TranslationPipeline:()=>dI,UltravoxModel:()=>dD,UltravoxPreTrainedModel:()=>dz,UltravoxProcessor:()=>dj,UniSpeechForCTC:()=>dV,UniSpeechForSequenceClassification:()=>dO,UniSpeechModel:()=>dN,UniSpeechPreTrainedModel:()=>dB,UniSpeechSatForAudioFrameClassification:()=>dG,UniSpeechSatForCTC:()=>dR,UniSpeechSatForSequenceClassification:()=>dq,UniSpeechSatModel:()=>d$,UniSpeechSatPreTrainedModel:()=>dW,VLChatProcessor:()=>dU,VLMImageProcessor:()=>dQ,VaultGemmaForCausalLM:()=>dX,VaultGemmaModel:()=>dH,VaultGemmaPreTrainedModel:()=>dJ,ViTFeatureExtractor:()=>dY,ViTForImageClassification:()=>dK,ViTImageProcessor:()=>dZ,ViTMAEModel:()=>d0,ViTMAEPreTrainedModel:()=>d1,ViTMSNForImageClassification:()=>d2,ViTMSNModel:()=>d3,ViTMSNPreTrainedModel:()=>d4,ViTModel:()=>d5,ViTPreTrainedModel:()=>d8,VisionEncoderDecoderModel:()=>d6,VitMatteForImageMatting:()=>d9,VitMatteImageProcessor:()=>d7,VitMattePreTrainedModel:()=>ue,VitPoseForPoseEstimation:()=>ut,VitPoseImageProcessor:()=>ur,VitPosePreTrainedModel:()=>uo,VitsModel:()=>us,VitsModelOutput:()=>ua,VitsPreTrainedModel:()=>ui,VitsTokenizer:()=>un,VoxtralForConditionalGeneration:()=>ul,VoxtralProcessor:()=>uc,Wav2Vec2BertForCTC:()=>ud,Wav2Vec2BertForSequenceClassification:()=>uu,Wav2Vec2BertModel:()=>um,Wav2Vec2BertPreTrainedModel:()=>up,Wav2Vec2CTCTokenizer:()=>u_,Wav2Vec2FeatureExtractor:()=>uh,Wav2Vec2ForAudioFrameClassification:()=>ug,Wav2Vec2ForCTC:()=>uf,Wav2Vec2ForSequenceClassification:()=>uM,Wav2Vec2Model:()=>uw,Wav2Vec2PreTrainedModel:()=>uT,Wav2Vec2Processor:()=>uP,Wav2Vec2ProcessorWithLM:()=>ux,WavLMForAudioFrameClassification:()=>ub,WavLMForCTC:()=>uF,WavLMForSequenceClassification:()=>uk,WavLMForXVector:()=>uy,WavLMModel:()=>uv,WavLMPreTrainedModel:()=>uC,WeSpeakerFeatureExtractor:()=>uS,WeSpeakerResNetModel:()=>uE,WeSpeakerResNetPreTrainedModel:()=>uA,WhisperFeatureExtractor:()=>uL,WhisperForConditionalGeneration:()=>uI,WhisperModel:()=>uD,WhisperPreTrainedModel:()=>uz,WhisperProcessor:()=>uj,WhisperTextStreamer:()=>uV,WhisperTimeStampLogitsProcessor:()=>uO,WhisperTokenizer:()=>uN,XLMForQuestionAnswering:()=>uB,XLMForSequenceClassification:()=>uG,XLMForTokenClassification:()=>uR,XLMModel:()=>uq,XLMPreTrainedModel:()=>u$,XLMRobertaForMaskedLM:()=>uW,XLMRobertaForQuestionAnswering:()=>uU,XLMRobertaForSequenceClassification:()=>uQ,XLMRobertaForTokenClassification:()=>uX,XLMRobertaModel:()=>uH,XLMRobertaPreTrainedModel:()=>uJ,XLMRobertaTokenizer:()=>uY,XLMTokenizer:()=>uK,XLMWithLMHeadModel:()=>uZ,XVectorOutput:()=>u0,YolosFeatureExtractor:()=>u1,YolosForObjectDetection:()=>u2,YolosImageProcessor:()=>u3,YolosModel:()=>u4,YolosObjectDetectionOutput:()=>u5,YolosPreTrainedModel:()=>u8,ZeroShotAudioClassificationPipeline:()=>u6,ZeroShotClassificationPipeline:()=>u9,ZeroShotImageClassificationPipeline:()=>u7,ZeroShotObjectDetectionPipeline:()=>me,bankers_round:()=>mt,cat:()=>mr,cos_sim:()=>mo,dot:()=>ms,dynamic_time_warping:()=>ma,env:()=>mi,full:()=>mn,full_like:()=>ml,getCacheShapes:()=>mc,hamming:()=>md,hanning:()=>mu,interpolate:()=>mm,interpolate_4d:()=>mp,interpolate_data:()=>m_,is_chinese_char:()=>mh,layer_norm:()=>mg,load_image:()=>mf,load_video:()=>mM,log_softmax:()=>mw,magnitude:()=>mT,matmul:()=>mP,max:()=>mx,mean:()=>mb,mean_pooling:()=>mF,medianFilter:()=>mk,mel_filter_bank:()=>my,min:()=>mv,ones:()=>mC,ones_like:()=>mS,permute:()=>mE,permute_data:()=>mA,pipeline:()=>mL,quantize_embeddings:()=>mI,rand:()=>mD,randn:()=>mz,read_audio:()=>mj,rfft:()=>mV,round:()=>mO,slice:()=>mN,softmax:()=>mB,spectrogram:()=>mG,stack:()=>mR,std_mean:()=>mq,topk:()=>m$,window_function:()=>mW,zeros:()=>mU,zeros_like:()=>mQ});var o=r(7208),s=r(7670),a=r(459),i=r(887).hp,n={"onnxruntime-common":e=>{e.exports=o},"onnxruntime-web":e=>{e.exports=s},"?2ce3":()=>{},"?7992":()=>{},"?5af5":()=>{},"?2b25":()=>{},"?db59":()=>{},"?383f":()=>{},"?fa4b":()=>{},"./node_modules/@huggingface/jinja/dist/index.js":(e,t,r)=>{r.r(t),r.d(t,{Environment:()=>en,Interpreter:()=>ed,Template:()=>ep,parse:()=>R,tokenize:()=>d});var o=Object.freeze({Text:"Text",NumericLiteral:"NumericLiteral",StringLiteral:"StringLiteral",Identifier:"Identifier",Equals:"Equals",OpenParen:"OpenParen",CloseParen:"CloseParen",OpenStatement:"OpenStatement",CloseStatement:"CloseStatement",OpenExpression:"OpenExpression",CloseExpression:"CloseExpression",OpenSquareBracket:"OpenSquareBracket",CloseSquareBracket:"CloseSquareBracket",OpenCurlyBracket:"OpenCurlyBracket",CloseCurlyBracket:"CloseCurlyBracket",Comma:"Comma",Dot:"Dot",Colon:"Colon",Pipe:"Pipe",CallOperator:"CallOperator",AdditiveBinaryOperator:"AdditiveBinaryOperator",MultiplicativeBinaryOperator:"MultiplicativeBinaryOperator",ComparisonBinaryOperator:"ComparisonBinaryOperator",UnaryOperator:"UnaryOperator",Comment:"Comment"}),s=class{constructor(e,t){this.value=e,this.type=t}};function a(e){return/\w/.test(e)}function i(e){return/[0-9]/.test(e)}function n(e){return/\s/.test(e)}var l=[["{%",o.OpenStatement],["%}",o.CloseStatement],["{{",o.OpenExpression],["}}",o.CloseExpression],["(",o.OpenParen],[")",o.CloseParen],["{",o.OpenCurlyBracket],["}",o.CloseCurlyBracket],["[",o.OpenSquareBracket],["]",o.CloseSquareBracket],[",",o.Comma],[".",o.Dot],[":",o.Colon],["|",o.Pipe],["<=",o.ComparisonBinaryOperator],[">=",o.ComparisonBinaryOperator],["==",o.ComparisonBinaryOperator],["!=",o.ComparisonBinaryOperator],["<",o.ComparisonBinaryOperator],[">",o.ComparisonBinaryOperator],["+",o.AdditiveBinaryOperator],["-",o.AdditiveBinaryOperator],["~",o.AdditiveBinaryOperator],["*",o.MultiplicativeBinaryOperator],["/",o.MultiplicativeBinaryOperator],["%",o.MultiplicativeBinaryOperator],["=",o.Equals]],c=new Map([["n","\n"],["t","	"],["r","\r"],["b","\b"],["f","\f"],["v","\v"],["'","'"],['"','"'],["\\","\\"]]);function d(e,t={}){let r=[],u=function(e,t={}){return e.endsWith("\n")&&(e=e.slice(0,-1)),t.lstrip_blocks&&(e=e.replace(/^[ \t]*({[#%-])/gm,"$1")),t.trim_blocks&&(e=e.replace(/([#%-]})\n/g,"$1")),e.replace(/{%\s*(end)?generation\s*%}/gs,"")}(e,t),m=0,p=0,_=e=>{let t="";for(;e(u[m]);){if("\\"===u[m]){if(++m>=u.length)throw SyntaxError("Unexpected end of input");let e=u[m++],r=c.get(e);if(void 0===r)throw SyntaxError(`Unexpected escaped character: ${e}`);t+=r;continue}if(t+=u[m++],m>=u.length)throw SyntaxError("Unexpected end of input")}return t},h=()=>{let e=r.at(-1);e&&e.type===o.Text&&(e.value=e.value.trimEnd(),""===e.value&&r.pop())},g=()=>{for(;m<u.length&&n(u[m]);)++m};e:for(;m<u.length;){let e=r.at(-1)?.type;if(void 0===e||e===o.CloseStatement||e===o.CloseExpression||e===o.Comment){let e="";for(;m<u.length&&("{"!==u[m]||"%"!==u[m+1]&&"{"!==u[m+1]&&"#"!==u[m+1]);)e+=u[m++];if(e.length>0){r.push(new s(e,o.Text));continue}}if("{"===u[m]&&"#"===u[m+1]){let e="-"===u[m+=2];e&&++m;let t="";for(;"#"!==u[m]||"}"!==u[m+1];){if(m+2>=u.length)throw SyntaxError("Missing end of comment tag");t+=u[m++]}let a=t.endsWith("-");a&&(t=t.slice(0,-1)),e&&h(),r.push(new s(t,o.Comment)),m+=2,a&&g();continue}if("{%-"===u.slice(m,m+3)){h(),r.push(new s("{%",o.OpenStatement)),m+=3;continue}if("{{-"===u.slice(m,m+3)){h(),r.push(new s("{{",o.OpenExpression)),p=0,m+=3;continue}if(_(n),"-%}"===u.slice(m,m+3)){r.push(new s("%}",o.CloseStatement)),m+=3,g();continue}if("-}}"===u.slice(m,m+3)){r.push(new s("}}",o.CloseExpression)),m+=3,g();continue}let t=u[m];if("-"===t||"+"===t){let e=r.at(-1)?.type;if(e===o.Text||void 0===e)throw SyntaxError(`Unexpected character: ${t}`);switch(e){case o.Identifier:case o.NumericLiteral:case o.StringLiteral:case o.CloseParen:case o.CloseSquareBracket:break;default:{++m;let e=_(i);r.push(new s(`${t}${e}`,e.length>0?o.NumericLiteral:o.UnaryOperator));continue}}}for(let[e,t]of l)if(("}}"!==e||!(p>0))&&u.slice(m,m+e.length)===e){r.push(new s(e,t)),t===o.OpenExpression?p=0:t===o.OpenCurlyBracket?++p:t===o.CloseCurlyBracket&&--p,m+=e.length;continue e}if("'"===t||'"'===t){++m;let e=_(e=>e!==t);r.push(new s(e,o.StringLiteral)),++m;continue}if(i(t)){let e=_(i);if("."===u[m]&&i(u[m+1])){++m;let t=_(i);e=`${e}.${t}`}r.push(new s(e,o.NumericLiteral));continue}if(a(t)){let e=_(a);r.push(new s(e,o.Identifier));continue}throw SyntaxError(`Unexpected character: ${t}`)}return r}var u=class{type="Statement"},m=class extends u{constructor(e){super(),this.body=e}type="Program"},p=class extends u{constructor(e,t,r){super(),this.test=e,this.body=t,this.alternate=r}type="If"},_=class extends u{constructor(e,t,r,o){super(),this.loopvar=e,this.iterable=t,this.body=r,this.defaultBlock=o}type="For"},h=class extends u{type="Break"},g=class extends u{type="Continue"},f=class extends u{constructor(e,t,r){super(),this.assignee=e,this.value=t,this.body=r}type="Set"},M=class extends u{constructor(e,t,r){super(),this.name=e,this.args=t,this.body=r}type="Macro"},w=class extends u{constructor(e){super(),this.value=e}type="Comment"},T=class extends u{type="Expression"},P=class extends T{constructor(e,t,r){super(),this.object=e,this.property=t,this.computed=r}type="MemberExpression"},x=class extends T{constructor(e,t){super(),this.callee=e,this.args=t}type="CallExpression"},b=class extends T{constructor(e){super(),this.value=e}type="Identifier"},F=class extends T{constructor(e){super(),this.value=e}type="Literal"},k=class extends F{type="IntegerLiteral"},y=class extends F{type="FloatLiteral"},v=class extends F{type="StringLiteral"},C=class extends F{type="ArrayLiteral"},S=class extends F{type="TupleLiteral"},E=class extends F{type="ObjectLiteral"},A=class extends T{constructor(e,t,r){super(),this.operator=e,this.left=t,this.right=r}type="BinaryExpression"},L=class extends T{constructor(e,t){super(),this.operand=e,this.filter=t}type="FilterExpression"},I=class extends u{constructor(e,t){super(),this.filter=e,this.body=t}type="FilterStatement"},D=class extends T{constructor(e,t){super(),this.lhs=e,this.test=t}type="SelectExpression"},z=class extends T{constructor(e,t,r){super(),this.operand=e,this.negate=t,this.test=r}type="TestExpression"},j=class extends T{constructor(e,t){super(),this.operator=e,this.argument=t}type="UnaryExpression"},V=class extends T{constructor(e,t,r){super(),this.start=e,this.stop=t,this.step=r}type="SliceExpression"},O=class extends T{constructor(e,t){super(),this.key=e,this.value=t}type="KeywordArgumentExpression"},N=class extends T{constructor(e){super(),this.argument=e}type="SpreadExpression"},B=class extends u{constructor(e,t,r){super(),this.call=e,this.callerArgs=t,this.body=r}type="CallStatement"},G=class extends T{constructor(e,t,r){super(),this.condition=e,this.trueExpr=t,this.falseExpr=r}type="Ternary"};function R(e){let t=new m([]),r=0;function a(t,o){let s=e[r++];if(!s||s.type!==t)throw Error(`Parser Error: ${o}. ${s.type} !== ${t}.`);return s}function i(e){if(!c(e))throw SyntaxError(`Expected ${e}`);++r}function n(...t){return r+t.length<=e.length&&t.every((t,o)=>t===e[r+o].type)}function l(...t){return e[r]?.type===o.OpenStatement&&e[r+1]?.type===o.Identifier&&t.includes(e[r+1]?.value)}function c(...t){return r+t.length<=e.length&&t.every((t,o)=>"Identifier"===e[r+o].type&&t===e[r+o].value)}function d(e=!1){let t=e?H:u,s=[t()],a=n(o.Comma);for(;a&&(++r,s.push(t()),n(o.Comma)););return a?new S(s):s[0]}function u(){return function e(){let t=T();if(c("if")){++r;let o=T();return c("else")?(++r,new G(o,t,e())):new D(t,o)}return t}()}function T(){let t=F();for(;c("or");){let o=e[r];++r,t=new A(o,t,F())}return t}function F(){let t=R();for(;c("and");){let o=e[r];++r,t=new A(o,t,R())}return t}function R(){let t;for(;c("not");){let o=e[r];++r,t=new j(o,R())}return t??function(){let t=q();for(;;){let a;if(c("not","in"))a=new s("not in",o.Identifier),r+=2;else if(c("in"))a=e[r++];else if(n(o.ComparisonBinaryOperator))a=e[r++];else break;t=new A(a,t,q())}return t}()}function q(){let t=Q();for(;n(o.AdditiveBinaryOperator);){let o=e[r];++r,t=new A(o,t,Q())}return t}function $(e){let t=new x(e,W());return t=U(t),n(o.OpenParen)&&(t=$(t)),t}function W(){a(o.OpenParen,"Expected opening parenthesis for arguments list");let t=function(){let t=[];for(;!n(o.CloseParen);){let s;if(e[r].type===o.MultiplicativeBinaryOperator&&"*"===e[r].value)++r,s=new N(u());else if(s=u(),n(o.Equals)){if(++r,!(s instanceof b))throw SyntaxError("Expected identifier for keyword argument");s=new O(s,u())}t.push(s),n(o.Comma)&&++r}return t}();return a(o.CloseParen,"Expected closing parenthesis for arguments list"),t}function U(t){for(;n(o.Dot)||n(o.OpenSquareBracket);){let s;let i=e[r];++r;let l=i.type===o.OpenSquareBracket;if(l)s=function(){let e=[],t=!1;for(;!n(o.CloseSquareBracket);)n(o.Colon)?(e.push(void 0),++r,t=!0):(e.push(u()),n(o.Colon)&&(++r,t=!0));if(0===e.length)throw SyntaxError("Expected at least one argument for member/slice expression");if(t){if(e.length>3)throw SyntaxError("Expected 0-3 arguments for slice expression");return new V(...e)}return e[0]}(),a(o.CloseSquareBracket,"Expected closing square bracket");else if("Identifier"!==(s=H()).type)throw SyntaxError("Expected identifier following dot operator");t=new P(t,s,l)}return t}function Q(){let t=X();for(;n(o.MultiplicativeBinaryOperator);)t=new A(e[r++],t,X());return t}function X(){let e=function(){let e=function(){let e=U(H());return n(o.OpenParen)?$(e):e}();for(;n(o.Pipe);){++r;let t=H();if(!(t instanceof b))throw SyntaxError("Expected identifier for the filter");n(o.OpenParen)&&(t=$(t)),e=new L(e,t)}return e}();for(;c("is");){++r;let t=c("not");t&&++r;let o=H();if(!(o instanceof b))throw SyntaxError("Expected identifier for the test");e=new z(e,t,o)}return e}function H(){let t=e[r++];switch(t.type){case o.NumericLiteral:{let e=t.value;return e.includes(".")?new y(Number(e)):new k(Number(e))}case o.StringLiteral:{let s=t.value;for(;n(o.StringLiteral);)s+=e[r++].value;return new v(s)}case o.Identifier:return new b(t.value);case o.OpenParen:{let e=d();return a(o.CloseParen,"Expected closing parenthesis, got ${tokens[current].type} instead."),e}case o.OpenSquareBracket:{let e=[];for(;!n(o.CloseSquareBracket);)e.push(u()),n(o.Comma)&&++r;return++r,new C(e)}case o.OpenCurlyBracket:{let e=new Map;for(;!n(o.CloseCurlyBracket);){let t=u();a(o.Colon,"Expected colon between key and value in object literal");let s=u();e.set(t,s),n(o.Comma)&&++r}return++r,new E(e)}default:throw SyntaxError(`Unexpected token: ${t.type}`)}}for(;r<e.length;)t.body.push(function t(){switch(e[r].type){case o.Comment:return new w(e[r++].value);case o.Text:return new v(a(o.Text,"Expected text token").value);case o.OpenStatement:return function(){let s;if(a(o.OpenStatement,"Expected opening statement token"),e[r].type!==o.Identifier)throw SyntaxError(`Unknown statement, got ${e[r].type}`);let m=e[r].value;switch(m){case"set":++r,s=function(){let e=d(),s=null,c=[];if(n(o.Equals))++r,s=d();else{for(a(o.CloseStatement,"Expected %} token");!l("endset");)c.push(t());a(o.OpenStatement,"Expected {% token"),i("endset")}return a(o.CloseStatement,"Expected closing statement token"),new f(e,s,c)}();break;case"if":++r,s=function e(){let s=u();a(o.CloseStatement,"Expected closing statement token");let i=[],n=[];for(;!l("elif","else","endif");)i.push(t());if(l("elif")){++r,++r;let t=e();n.push(t)}else if(l("else"))for(++r,++r,a(o.CloseStatement,"Expected closing statement token");!l("endif");)n.push(t());return new p(s,i,n)}(),a(o.OpenStatement,"Expected {% token"),i("endif"),a(o.CloseStatement,"Expected %} token");break;case"macro":++r,s=function(){let e=H();if("Identifier"!==e.type)throw SyntaxError("Expected identifier following macro statement");let r=W();a(o.CloseStatement,"Expected closing statement token");let s=[];for(;!l("endmacro");)s.push(t());return new M(e,r,s)}(),a(o.OpenStatement,"Expected {% token"),i("endmacro"),a(o.CloseStatement,"Expected %} token");break;case"for":++r,s=function(){let e=d(!0);if(!(e instanceof b||e instanceof S))throw SyntaxError(`Expected identifier/tuple for the loop variable, got ${e.type} instead`);if(!c("in"))throw SyntaxError("Expected `in` keyword following loop variable");++r;let s=u();a(o.CloseStatement,"Expected closing statement token");let i=[];for(;!l("endfor","else");)i.push(t());let n=[];if(l("else"))for(++r,++r,a(o.CloseStatement,"Expected closing statement token");!l("endfor");)n.push(t());return new _(e,s,i,n)}(),a(o.OpenStatement,"Expected {% token"),i("endfor"),a(o.CloseStatement,"Expected %} token");break;case"call":{++r;let e=null;n(o.OpenParen)&&(e=W());let c=H();if("Identifier"!==c.type)throw SyntaxError("Expected identifier following call statement");let d=W();a(o.CloseStatement,"Expected closing statement token");let u=[];for(;!l("endcall");)u.push(t());a(o.OpenStatement,"Expected '{%'"),i("endcall"),a(o.CloseStatement,"Expected closing statement token"),s=new B(new x(c,d),e,u);break}case"break":++r,a(o.CloseStatement,"Expected closing statement token"),s=new h;break;case"continue":++r,a(o.CloseStatement,"Expected closing statement token"),s=new g;break;case"filter":{++r;let e=H();e instanceof b&&n(o.OpenParen)&&(e=$(e)),a(o.CloseStatement,"Expected closing statement token");let c=[];for(;!l("endfilter");)c.push(t());a(o.OpenStatement,"Expected '{%'"),i("endfilter"),a(o.CloseStatement,"Expected '%}'"),s=new I(e,c);break}default:throw SyntaxError(`Unknown statement type: ${m}`)}return s}();case o.OpenExpression:return function(){a(o.OpenExpression,"Expected opening expression token");let e=u();return a(o.CloseExpression,"Expected closing expression token"),e}();default:throw SyntaxError(`Unexpected token type: ${e[r].type}`)}}());return t}function q(e,t,r=1){void 0===t&&(t=e,e=0);let o=[];for(let s=e;s<t;s+=r)o.push(s);return o}function $(e,t,r,o=1){let s=Math.sign(o);s>=0?(t=(t??=0)<0?Math.max(e.length+t,0):Math.min(t,e.length),r=(r??=e.length)<0?Math.max(e.length+r,0):Math.min(r,e.length)):(t=(t??=e.length-1)<0?Math.max(e.length+t,-1):Math.min(t,e.length-1),r=(r??=-1)<-1?Math.max(e.length+r,-1):Math.min(r,e.length-1));let a=[];for(let i=t;s*i<s*r;i+=o)a.push(e[i]);return a}function W(e){return function(e,t){let r=new Intl.DateTimeFormat(void 0,{month:"long"}),o=new Intl.DateTimeFormat(void 0,{month:"short"}),s=e=>e<10?"0"+e:e.toString();return t.replace(/%[YmdbBHM%]/g,t=>{switch(t){case"%Y":return e.getFullYear().toString();case"%m":return s(e.getMonth()+1);case"%d":return s(e.getDate());case"%b":return o.format(e);case"%B":return r.format(e);case"%H":return s(e.getHours());case"%M":return s(e.getMinutes());case"%%":return"%";default:return t}})}(new Date,e)}var U=class extends Error{},Q=class extends Error{},X=class{type="RuntimeValue";value;builtins=new Map;constructor(e){this.value=e}__bool__(){return new K(!!this.value)}toString(){return String(this.value)}},H=class extends X{type="IntegerValue"},J=class extends X{type="FloatValue";toString(){return this.value%1==0?this.value.toFixed(1):this.value.toString()}},Y=class extends X{type="StringValue";builtins=new Map([["upper",new es(()=>new Y(this.value.toUpperCase()))],["lower",new es(()=>new Y(this.value.toLowerCase()))],["strip",new es(()=>new Y(this.value.trim()))],["title",new es(()=>new Y(this.value.replace(/\b\w/g,e=>e.toUpperCase())))],["capitalize",new es(()=>new Y(this.value.charAt(0).toUpperCase()+this.value.slice(1)))],["length",new H(this.value.length)],["rstrip",new es(()=>new Y(this.value.trimEnd()))],["lstrip",new es(()=>new Y(this.value.trimStart()))],["startswith",new es(e=>{if(0===e.length)throw Error("startswith() requires at least one argument");let t=e[0];if(t instanceof Y)return new K(this.value.startsWith(t.value));if(t instanceof er){for(let e of t.value){if(!(e instanceof Y))throw Error("startswith() tuple elements must be strings");if(this.value.startsWith(e.value))return new K(!0)}return new K(!1)}throw Error("startswith() argument must be a string or tuple of strings")})],["endswith",new es(e=>{if(0===e.length)throw Error("endswith() requires at least one argument");let t=e[0];if(t instanceof Y)return new K(this.value.endsWith(t.value));if(t instanceof er){for(let e of t.value){if(!(e instanceof Y))throw Error("endswith() tuple elements must be strings");if(this.value.endsWith(e.value))return new K(!0)}return new K(!1)}throw Error("endswith() argument must be a string or tuple of strings")})],["split",new es(e=>{let t=e[0]??new ea;if(!(t instanceof Y||t instanceof ea))throw Error("sep argument must be a string or null");let r=e[1]??new H(-1);if(!(r instanceof H))throw Error("maxsplit argument must be a number");let o=[];if(t instanceof ea){let e=this.value.trimStart();for(let{0:t,index:s}of e.matchAll(/\S+/g)){if(-1!==r.value&&o.length>=r.value&&void 0!==s){o.push(t+e.slice(s+t.length));break}o.push(t)}}else{if(""===t.value)throw Error("empty separator");o=this.value.split(t.value),-1!==r.value&&o.length>r.value&&o.push(o.splice(r.value).join(t.value))}return new er(o.map(e=>new Y(e)))})],["replace",new es(e=>{let t;if(e.length<2)throw Error("replace() requires at least two arguments");let r=e[0],o=e[1];if(!(r instanceof Y&&o instanceof Y))throw Error("replace() arguments must be strings");if(!((t=e.length>2?"KeywordArgumentsValue"===e[2].type?e[2].value.get("count")??new ea:e[2]:new ea)instanceof H||t instanceof ea))throw Error("replace() count argument must be a number or null");return new Y(function(e,t,r,o){if(0===o)return e;let s=null==o||o<0?1/0:o,a=0===t.length?RegExp("(?=)","gu"):RegExp(t.replace(/[.*+?^${}()|[\]\\]/g,"\\$&"),"gu");return e.replaceAll(a,e=>s>0?(--s,r):e)}(this.value,r.value,o.value,t.value))})]])},K=class extends X{type="BooleanValue"};function Z(e,t,r,o=!0){let s=r??0;switch(e.type){case"NullValue":return"null";case"UndefinedValue":return o?"null":"undefined";case"IntegerValue":case"FloatValue":case"StringValue":case"BooleanValue":return JSON.stringify(e.value);case"ArrayValue":case"ObjectValue":{let r=t?" ".repeat(t):"",a="\n"+r.repeat(s),i=a+r;if("ArrayValue"===e.type){let r=e.value.map(e=>Z(e,t,s+1,o));return t?`[${i}${r.join(`,${i}`)}${a}]`:`[${r.join(", ")}]`}{let r=Array.from(e.value.entries()).map(([e,r])=>{let a=`"${e}": ${Z(r,t,s+1,o)}`;return t?`${i}${a}`:a});return t?`{${r.join(",")}${a}}`:`{${r.join(", ")}}`}}default:throw Error(`Cannot convert to JSON: ${e.type}`)}}var ee=class extends X{type="ObjectValue";__bool__(){return new K(this.value.size>0)}builtins=new Map([["get",new es(([e,t])=>{if(!(e instanceof Y))throw Error(`Object key must be a string: got ${e.type}`);return this.value.get(e.value)??t??new ea})],["items",new es(()=>this.items())],["keys",new es(()=>this.keys())],["values",new es(()=>this.values())],["dictsort",new es(e=>{let t=new Map,r=e.filter(e=>!(e instanceof et)||(t=e.value,!1)),o=r.at(0)??t.get("case_sensitive")??new K(!1);if(!(o instanceof K))throw Error("case_sensitive must be a boolean");let s=r.at(1)??t.get("by")??new Y("key");if(!(s instanceof Y))throw Error("by must be a string");if(!["key","value"].includes(s.value))throw Error("by must be either 'key' or 'value'");let a=r.at(2)??t.get("reverse")??new K(!1);if(!(a instanceof K))throw Error("reverse must be a boolean");let i=Array.from(this.value.entries()).map(([e,t])=>new er([new Y(e),t])).sort((e,t)=>{let r=+("key"!==s.value),i=ec(e.value[r],t.value[r],o.value);return a.value?-i:i});return new er(i)})]]);items(){return new er(Array.from(this.value.entries()).map(([e,t])=>new er([new Y(e),t])))}keys(){return new er(Array.from(this.value.keys()).map(e=>new Y(e)))}values(){return new er(Array.from(this.value.values()))}toString(){return Z(this,null,0,!1)}},et=class extends ee{type="KeywordArgumentsValue"},er=class extends X{type="ArrayValue";builtins=new Map([["length",new H(this.value.length)]]);__bool__(){return new K(this.value.length>0)}toString(){return Z(this,null,0,!1)}},eo=class extends er{type="TupleValue"},es=class extends X{type="FunctionValue"},ea=class extends X{type="NullValue"},ei=class extends X{type="UndefinedValue"},en=class{constructor(e){this.parent=e}variables=new Map([["namespace",new es(e=>{if(0===e.length)return new ee(new Map);if(1!==e.length||!(e[0]instanceof ee))throw Error("`namespace` expects either zero arguments or a single object argument");return e[0]})]]);tests=new Map([["boolean",e=>"BooleanValue"===e.type],["callable",e=>e instanceof es],["odd",e=>{if(!(e instanceof H))throw Error(`cannot odd on ${e.type}`);return e.value%2!=0}],["even",e=>{if(!(e instanceof H))throw Error(`cannot even on ${e.type}`);return e.value%2==0}],["false",e=>"BooleanValue"===e.type&&!e.value],["true",e=>"BooleanValue"===e.type&&e.value],["none",e=>"NullValue"===e.type],["string",e=>"StringValue"===e.type],["number",e=>e instanceof H||e instanceof J],["integer",e=>e instanceof H],["iterable",e=>"ArrayValue"===e.type||"StringValue"===e.type],["mapping",e=>"ObjectValue"===e.type],["lower",e=>{let t=e.value;return"StringValue"===e.type&&t===t.toLowerCase()}],["upper",e=>{let t=e.value;return"StringValue"===e.type&&t===t.toUpperCase()}],["none",e=>"NullValue"===e.type],["defined",e=>"UndefinedValue"!==e.type],["undefined",e=>"UndefinedValue"===e.type],["equalto",(e,t)=>e.value===t.value],["eq",(e,t)=>e.value===t.value]]);set(e,t){return this.declareVariable(e,function e(t){switch(typeof t){case"number":return Number.isInteger(t)?new H(t):new J(t);case"string":return new Y(t);case"boolean":return new K(t);case"undefined":return new ei;case"object":if(null===t)return new ea;if(Array.isArray(t))return new er(t.map(e));return new ee(new Map(Object.entries(t).map(([t,r])=>[t,e(r)])));case"function":return new es((r,o)=>e(t(...r.map(e=>e.value))??null));default:throw Error(`Cannot convert to runtime value: ${t}`)}}(t))}declareVariable(e,t){if(this.variables.has(e))throw SyntaxError(`Variable already declared: ${e}`);return this.variables.set(e,t),t}setVariable(e,t){return this.variables.set(e,t),t}resolve(e){if(this.variables.has(e))return this;if(this.parent)return this.parent.resolve(e);throw Error(`Unknown variable: ${e}`)}lookupVariable(e){try{return this.resolve(e).variables.get(e)??new ei}catch{return new ei}}};function el(e,t){let r=t.split("."),o=e;for(let e of r)if(o instanceof ee)o=o.value.get(e)??new ei;else{if(!(o instanceof er))return new ei;let t=parseInt(e,10);if(isNaN(t)||!(t>=0)||!(t<o.value.length))return new ei;o=o.value[t]}return o}function ec(e,t,r=!1){if(e instanceof ea&&t instanceof ea)return 0;if(e instanceof ea||t instanceof ea)throw Error(`Cannot compare ${e.type} with ${t.type}`);if(e instanceof ei&&t instanceof ei)return 0;if(e instanceof ei||t instanceof ei)throw Error(`Cannot compare ${e.type} with ${t.type}`);let o=e=>e instanceof H||e instanceof J||e instanceof K,s=e=>e instanceof K?+!!e.value:e.value;if(o(e)&&o(t)){let r=s(e),o=s(t);return r<o?-1:+(r>o)}if(e.type!==t.type)throw Error(`Cannot compare different types: ${e.type} and ${t.type}`);if("StringValue"===e.type){let o=e.value,s=t.value;return r||(o=o.toLowerCase(),s=s.toLowerCase()),o<s?-1:+(o>s)}throw Error(`Cannot compare type: ${e.type}`)}var ed=class{global;constructor(e){this.global=e??new en}run(e){return this.evaluate(e,this.global)}evaluateBinaryExpression(e,t){let r=this.evaluate(e.left,t);switch(e.operator.value){case"and":return r.__bool__().value?this.evaluate(e.right,t):r;case"or":return r.__bool__().value?r:this.evaluate(e.right,t)}let o=this.evaluate(e.right,t);switch(e.operator.value){case"==":return new K(r.value==o.value);case"!=":return new K(r.value!=o.value)}if(r instanceof ei||o instanceof ei){if(o instanceof ei&&["in","not in"].includes(e.operator.value))return new K("not in"===e.operator.value);throw Error(`Cannot perform operation ${e.operator.value} on undefined values`)}if(r instanceof ea||o instanceof ea)throw Error("Cannot perform operation on null values");if("~"===e.operator.value)return new Y(r.value.toString()+o.value.toString());if((r instanceof H||r instanceof J)&&(o instanceof H||o instanceof J)){let t=r.value,s=o.value;switch(e.operator.value){case"+":case"-":case"*":{let a="+"===e.operator.value?t+s:"-"===e.operator.value?t-s:t*s;return r instanceof J||o instanceof J?new J(a):new H(a)}case"/":return new J(t/s);case"%":{let e=t%s;return r instanceof J||o instanceof J?new J(e):new H(e)}case"<":return new K(t<s);case">":return new K(t>s);case">=":return new K(t>=s);case"<=":return new K(t<=s)}}else if(r instanceof er&&o instanceof er){if("+"===e.operator.value)return new er(r.value.concat(o.value))}else if(o instanceof er){let t=void 0!==o.value.find(e=>e.value===r.value);switch(e.operator.value){case"in":return new K(t);case"not in":return new K(!t)}}if((r instanceof Y||o instanceof Y)&&"+"===e.operator.value)return new Y(r.value.toString()+o.value.toString());if(r instanceof Y&&o instanceof Y)switch(e.operator.value){case"in":return new K(o.value.includes(r.value));case"not in":return new K(!o.value.includes(r.value))}if(r instanceof Y&&o instanceof ee)switch(e.operator.value){case"in":return new K(o.value.has(r.value));case"not in":return new K(!o.value.has(r.value))}throw SyntaxError(`Unknown operator "${e.operator.value}" between ${r.type} and ${o.type}`)}evaluateArguments(e,t){let r=[],o=new Map;for(let s of e)if("SpreadExpression"===s.type){let e=this.evaluate(s.argument,t);if(!(e instanceof er))throw Error(`Cannot unpack non-iterable type: ${e.type}`);for(let t of e.value)r.push(t)}else if("KeywordArgumentExpression"===s.type)o.set(s.key.value,this.evaluate(s.value,t));else{if(o.size>0)throw Error("Positional arguments must come before keyword arguments");r.push(this.evaluate(s,t))}return[r,o]}applyFilter(e,t,r){if("Identifier"===t.type){if("tojson"===t.value)return new Y(Z(e));if(e instanceof er)switch(t.value){case"list":return e;case"first":return e.value[0];case"last":return e.value[e.value.length-1];case"length":return new H(e.value.length);case"reverse":return new er(e.value.slice().reverse());case"sort":return new er(e.value.slice().sort((e,t)=>ec(e,t,!1)));case"join":return new Y(e.value.map(e=>e.value).join(""));case"string":return new Y(Z(e,null,0,!1));case"unique":{let t=new Set,r=[];for(let o of e.value)t.has(o.value)||(t.add(o.value),r.push(o));return new er(r)}default:throw Error(`Unknown ArrayValue filter: ${t.value}`)}else if(e instanceof Y)switch(t.value){case"length":case"upper":case"lower":case"title":case"capitalize":{let o=e.builtins.get(t.value);if(o instanceof es)return o.value([],r);if(o instanceof H)return o;throw Error(`Unknown StringValue filter: ${t.value}`)}case"trim":return new Y(e.value.trim());case"indent":return new Y(e.value.split("\n").map((e,t)=>0===t||0===e.length?e:"    "+e).join("\n"));case"join":case"string":return e;case"int":{let t=parseInt(e.value,10);return new H(isNaN(t)?0:t)}case"float":{let t=parseFloat(e.value);return new J(isNaN(t)?0:t)}default:throw Error(`Unknown StringValue filter: ${t.value}`)}else if(e instanceof H||e instanceof J)switch(t.value){case"abs":return e instanceof H?new H(Math.abs(e.value)):new J(Math.abs(e.value));case"int":return new H(Math.floor(e.value));case"float":return new J(e.value);default:throw Error(`Unknown NumericValue filter: ${t.value}`)}else if(e instanceof ee)switch(t.value){case"items":return new er(Array.from(e.value.entries()).map(([e,t])=>new er([new Y(e),t])));case"length":return new H(e.value.size);default:{let o=e.builtins.get(t.value);if(o){if(o instanceof es)return o.value([],r);return o}throw Error(`Unknown ObjectValue filter: ${t.value}`)}}else if(e instanceof K)switch(t.value){case"bool":return new K(e.value);case"int":return new H(+!!e.value);case"float":return new J(+!!e.value);case"string":return new Y(e.value?"true":"false");default:throw Error(`Unknown BooleanValue filter: ${t.value}`)}throw Error(`Cannot apply filter "${t.value}" to type: ${e.type}`)}if("CallExpression"===t.type){if("Identifier"!==t.callee.type)throw Error(`Unknown filter: ${t.callee.type}`);let o=t.callee.value;if("tojson"===o){let[,o]=this.evaluateArguments(t.args,r),s=o.get("indent")??new ea;if(!(s instanceof H||s instanceof ea))throw Error("If set, indent must be a number");return new Y(Z(e,s.value))}if("join"===o){let s;if(e instanceof Y)s=Array.from(e.value);else if(e instanceof er)s=e.value.map(e=>e.value);else throw Error(`Cannot apply filter "${o}" to type: ${e.type}`);let[a,i]=this.evaluateArguments(t.args,r),n=a.at(0)??i.get("separator")??new Y("");if(!(n instanceof Y))throw Error("separator must be a string");return new Y(s.join(n.value))}if("int"===o||"float"===o){let[s,a]=this.evaluateArguments(t.args,r),i=s.at(0)??a.get("default")??("int"===o?new H(0):new J(0));if(e instanceof Y){let t="int"===o?parseInt(e.value,10):parseFloat(e.value);return isNaN(t)?i:"int"===o?new H(t):new J(t)}if(e instanceof H||e instanceof J)return e;if(e instanceof K)return"int"===o?new H(+!!e.value):new J(+!!e.value);else throw Error(`Cannot apply filter "${o}" to type: ${e.type}`)}else if("default"===o){let[o,s]=this.evaluateArguments(t.args,r),a=o[0]??new Y(""),i=o[1]??s.get("boolean")??new K(!1);if(!(i instanceof K))throw Error("`default` filter flag must be a boolean");return e instanceof ei||i.value&&!e.__bool__().value?a:e}if(e instanceof er){switch(o){case"sort":{let[o,s]=this.evaluateArguments(t.args,r),a=o.at(0)??s.get("reverse")??new K(!1);if(!(a instanceof K))throw Error("reverse must be a boolean");let i=o.at(1)??s.get("case_sensitive")??new K(!1);if(!(i instanceof K))throw Error("case_sensitive must be a boolean");let n=o.at(2)??s.get("attribute")??new ea;if(!(n instanceof Y||n instanceof H||n instanceof ea))throw Error("attribute must be a string, integer, or null");let l=e=>n instanceof ea?e:el(e,n instanceof H?String(n.value):n.value);return new er(e.value.slice().sort((e,t)=>{let r=ec(l(e),l(t),i.value);return a.value?-r:r}))}case"selectattr":case"rejectattr":{let s;let a="selectattr"===o;if(e.value.some(e=>!(e instanceof ee)))throw Error(`\`${o}\` can only be applied to array of objects`);if(t.args.some(e=>"StringLiteral"!==e.type))throw Error(`arguments of \`${o}\` must be strings`);let[i,n,l]=t.args.map(e=>this.evaluate(e,r));if(n){let e=r.tests.get(n.value);if(!e)throw Error(`Unknown test: ${n.value}`);s=e}else s=(...e)=>e[0].__bool__().value;return new er(e.value.filter(e=>{let t=e.value.get(i.value),r=!!t&&s(t,l);return a?r:!r}))}case"map":{let[,o]=this.evaluateArguments(t.args,r);if(o.has("attribute")){let t=o.get("attribute");if(!(t instanceof Y))throw Error("attribute must be a string");let r=o.get("default");return new er(e.value.map(e=>{if(!(e instanceof ee))throw Error("items in map must be an object");let o=el(e,t.value);return o instanceof ei?r??new ei:o}))}throw Error("`map` expressions without `attribute` set are not currently supported.")}}throw Error(`Unknown ArrayValue filter: ${o}`)}if(e instanceof Y){switch(o){case"indent":{let[o,s]=this.evaluateArguments(t.args,r),a=o.at(0)??s.get("width")??new H(4);if(!(a instanceof H))throw Error("width must be a number");let i=o.at(1)??s.get("first")??new K(!1),n=o.at(2)??s.get("blank")??new K(!1),l=e.value.split("\n"),c=" ".repeat(a.value);return new Y(l.map((e,t)=>(i.value||0!==t)&&(n.value||0!==e.length)?c+e:e).join("\n"))}case"replace":{let o=e.builtins.get("replace");if(!(o instanceof es))throw Error("replace filter not available");let[s,a]=this.evaluateArguments(t.args,r);return o.value([...s,new et(a)],r)}}throw Error(`Unknown StringValue filter: ${o}`)}if(e instanceof ee){let s=e.builtins.get(o);if(s&&s instanceof es){let[e,o]=this.evaluateArguments(t.args,r);return o.size>0&&e.push(new et(o)),s.value(e,r)}throw Error(`Unknown ObjectValue filter: ${o}`)}else throw Error(`Cannot apply filter "${o}" to type: ${e.type}`)}throw Error(`Unknown filter: ${t.type}`)}evaluateFilterExpression(e,t){let r=this.evaluate(e.operand,t);return this.applyFilter(r,e.filter,t)}evaluateTestExpression(e,t){let r=this.evaluate(e.operand,t),o=t.tests.get(e.test.value);if(!o)throw Error(`Unknown test: ${e.test.value}`);let s=o(r);return new K(e.negate?!s:s)}evaluateSelectExpression(e,t){return this.evaluate(e.test,t).__bool__().value?this.evaluate(e.lhs,t):new ei}evaluateUnaryExpression(e,t){let r=this.evaluate(e.argument,t);if("not"===e.operator.value)return new K(!r.value);throw SyntaxError(`Unknown operator: ${e.operator.value}`)}evaluateTernaryExpression(e,t){return this.evaluate(e.condition,t).__bool__().value?this.evaluate(e.trueExpr,t):this.evaluate(e.falseExpr,t)}evalProgram(e,t){return this.evaluateBlock(e.body,t)}evaluateBlock(e,t){let r="";for(let o of e){let e=this.evaluate(o,t);"NullValue"!==e.type&&"UndefinedValue"!==e.type&&(r+=e.toString())}return new Y(r)}evaluateIdentifier(e,t){return t.lookupVariable(e.value)}evaluateCallExpression(e,t){let[r,o]=this.evaluateArguments(e.args,t);o.size>0&&r.push(new et(o));let s=this.evaluate(e.callee,t);if("FunctionValue"!==s.type)throw Error(`Cannot call something that is not a function: got ${s.type}`);return s.value(r,t)}evaluateSliceExpression(e,t,r){if(!(e instanceof er||e instanceof Y))throw Error("Slice object must be an array or string");let o=this.evaluate(t.start,r),s=this.evaluate(t.stop,r),a=this.evaluate(t.step,r);if(!(o instanceof H||o instanceof ei))throw Error("Slice start must be numeric or undefined");if(!(s instanceof H||s instanceof ei))throw Error("Slice stop must be numeric or undefined");if(!(a instanceof H||a instanceof ei))throw Error("Slice step must be numeric or undefined");return e instanceof er?new er($(e.value,o.value,s.value,a.value)):new Y($(Array.from(e.value),o.value,s.value,a.value).join(""))}evaluateMemberExpression(e,t){let r,o;let s=this.evaluate(e.object,t);if(e.computed){if("SliceExpression"===e.property.type)return this.evaluateSliceExpression(s,e.property,t);r=this.evaluate(e.property,t)}else r=new Y(e.property.value);if(s instanceof ee){if(!(r instanceof Y))throw Error(`Cannot access property with non-string: got ${r.type}`);o=s.value.get(r.value)??s.builtins.get(r.value)}else if(s instanceof er||s instanceof Y){if(r instanceof H)o=s.value.at(r.value),s instanceof Y&&(o=new Y(s.value.at(r.value)));else if(r instanceof Y)o=s.builtins.get(r.value);else throw Error(`Cannot access property with non-string/non-number: got ${r.type}`)}else{if(!(r instanceof Y))throw Error(`Cannot access property with non-string: got ${r.type}`);o=s.builtins.get(r.value)}return o instanceof X?o:new ei}evaluateSet(e,t){let r=e.value?this.evaluate(e.value,t):this.evaluateBlock(e.body,t);if("Identifier"===e.assignee.type){let o=e.assignee.value;t.setVariable(o,r)}else if("TupleLiteral"===e.assignee.type){let o=e.assignee;if(!(r instanceof er))throw Error(`Cannot unpack non-iterable type in set: ${r.type}`);let s=r.value;if(s.length!==o.value.length)throw Error(`Too ${o.value.length>s.length?"few":"many"} items to unpack in set`);for(let e=0;e<o.value.length;++e){let r=o.value[e];if("Identifier"!==r.type)throw Error(`Cannot unpack to non-identifier in set: ${r.type}`);t.setVariable(r.value,s[e])}}else if("MemberExpression"===e.assignee.type){let o=e.assignee,s=this.evaluate(o.object,t);if(!(s instanceof ee))throw Error("Cannot assign to member of non-object");if("Identifier"!==o.property.type)throw Error("Cannot assign to member with non-identifier property");s.value.set(o.property.value,r)}else throw Error(`Invalid LHS inside assignment expression: ${JSON.stringify(e.assignee)}`);return new ea}evaluateIf(e,t){let r=this.evaluate(e.test,t);return this.evaluateBlock(r.__bool__().value?e.body:e.alternate,t)}evaluateFor(e,t){let r,o;let s=new en(t);if("SelectExpression"===e.iterable.type){let t=e.iterable;o=this.evaluate(t.lhs,s),r=t.test}else o=this.evaluate(e.iterable,s);if(!(o instanceof er||o instanceof ee))throw Error(`Expected iterable or object type in for loop: got ${o.type}`);o instanceof ee&&(o=o.keys());let a=[],i=[];for(let t=0;t<o.value.length;++t){let n;let l=new en(s),c=o.value[t];if("Identifier"===e.loopvar.type)n=t=>t.setVariable(e.loopvar.value,c);else if("TupleLiteral"===e.loopvar.type){let t=e.loopvar;if("ArrayValue"!==c.type)throw Error(`Cannot unpack non-iterable type: ${c.type}`);if(t.value.length!==c.value.length)throw Error(`Too ${t.value.length>c.value.length?"few":"many"} items to unpack`);n=e=>{for(let r=0;r<t.value.length;++r){if("Identifier"!==t.value[r].type)throw Error(`Cannot unpack non-identifier type: ${t.value[r].type}`);e.setVariable(t.value[r].value,c.value[r])}}}else throw Error(`Invalid loop variable(s): ${e.loopvar.type}`);(!r||(n(l),this.evaluate(r,l).__bool__().value))&&(a.push(c),i.push(n))}let n="",l=!0;for(let t=0;t<a.length;++t){let r=new Map([["index",new H(t+1)],["index0",new H(t)],["revindex",new H(a.length-t)],["revindex0",new H(a.length-t-1)],["first",new K(0===t)],["last",new K(t===a.length-1)],["length",new H(a.length)],["previtem",t>0?a[t-1]:new ei],["nextitem",t<a.length-1?a[t+1]:new ei]]);s.setVariable("loop",new ee(r)),i[t](s);try{let t=this.evaluateBlock(e.body,s);n+=t.value}catch(e){if(e instanceof Q)continue;if(e instanceof U)break;throw e}l=!1}return l&&(n+=this.evaluateBlock(e.defaultBlock,s).value),new Y(n)}evaluateMacro(e,t){return t.setVariable(e.name.value,new es((t,r)=>{let o;let s=new en(r);t=t.slice(),t.at(-1)?.type==="KeywordArgumentsValue"&&(o=t.pop());for(let r=0;r<e.args.length;++r){let a=e.args[r],i=t[r];if("Identifier"===a.type){if(!i)throw Error(`Missing positional argument: ${a.value}`);s.setVariable(a.value,i)}else if("KeywordArgumentExpression"===a.type){let e=i??o?.value.get(a.key.value)??this.evaluate(a.value,s);s.setVariable(a.key.value,e)}else throw Error(`Unknown argument type: ${a.type}`)}return this.evaluateBlock(e.body,s)})),new ea}evaluateCallStatement(e,t){let r=new es((t,r)=>{let o=new en(r);if(e.callerArgs)for(let r=0;r<e.callerArgs.length;++r){let s=e.callerArgs[r];if("Identifier"!==s.type)throw Error(`Caller parameter must be an identifier, got ${s.type}`);o.setVariable(s.value,t[r]??new ei)}return this.evaluateBlock(e.body,o)}),[o,s]=this.evaluateArguments(e.call.args,t);o.push(new et(s));let a=this.evaluate(e.call.callee,t);if("FunctionValue"!==a.type)throw Error(`Cannot call something that is not a function: got ${a.type}`);let i=new en(t);return i.setVariable("caller",r),a.value(o,i)}evaluateFilterStatement(e,t){let r=this.evaluateBlock(e.body,t);return this.applyFilter(r,e.filter,t)}evaluate(e,t){if(!e)return new ei;switch(e.type){case"Program":return this.evalProgram(e,t);case"Set":return this.evaluateSet(e,t);case"If":return this.evaluateIf(e,t);case"For":return this.evaluateFor(e,t);case"Macro":return this.evaluateMacro(e,t);case"CallStatement":return this.evaluateCallStatement(e,t);case"Break":throw new U;case"Continue":throw new Q;case"IntegerLiteral":return new H(e.value);case"FloatLiteral":return new J(e.value);case"StringLiteral":return new Y(e.value);case"ArrayLiteral":return new er(e.value.map(e=>this.evaluate(e,t)));case"TupleLiteral":return new eo(e.value.map(e=>this.evaluate(e,t)));case"ObjectLiteral":{let r=new Map;for(let[o,s]of e.value){let e=this.evaluate(o,t);if(!(e instanceof Y))throw Error(`Object keys must be strings: got ${e.type}`);r.set(e.value,this.evaluate(s,t))}return new ee(r)}case"Identifier":return this.evaluateIdentifier(e,t);case"CallExpression":return this.evaluateCallExpression(e,t);case"MemberExpression":return this.evaluateMemberExpression(e,t);case"UnaryExpression":return this.evaluateUnaryExpression(e,t);case"BinaryExpression":return this.evaluateBinaryExpression(e,t);case"FilterExpression":return this.evaluateFilterExpression(e,t);case"FilterStatement":return this.evaluateFilterStatement(e,t);case"TestExpression":return this.evaluateTestExpression(e,t);case"SelectExpression":return this.evaluateSelectExpression(e,t);case"Ternary":return this.evaluateTernaryExpression(e,t);case"Comment":return new ea;default:throw SyntaxError(`Unknown node type: ${e.type}`)}}};function eu(...e){return"{%- "+e.join(" ")+" -%}"}function em(e,t=-1){switch(e.type){case"SpreadExpression":return`*${em(e.argument)}`;case"Identifier":return e.value;case"IntegerLiteral":case"FloatLiteral":return`${e.value}`;case"StringLiteral":return JSON.stringify(e.value);case"BinaryExpression":{let r=function(e){switch(e.operator.type){case"MultiplicativeBinaryOperator":return 4;case"AdditiveBinaryOperator":return 3;case"ComparisonBinaryOperator":return 2;case"Identifier":if("and"===e.operator.value)return 1;if("in"===e.operator.value||"not in"===e.operator.value)return 2}return 0}(e),o=em(e.left,r),s=em(e.right,r+1),a=`${o} ${e.operator.value} ${s}`;return r<t?`(${a})`:a}case"UnaryExpression":return e.operator.value+("not"===e.operator.value?" ":"")+em(e.argument,1/0);case"CallExpression":{let t=e.args.map(em).join(", ");return`${em(e.callee)}(${t})`}case"MemberExpression":{let t=em(e.object);["Identifier","MemberExpression","CallExpression","StringLiteral","IntegerLiteral","FloatLiteral","ArrayLiteral","TupleLiteral","ObjectLiteral"].includes(e.object.type)||(t=`(${t})`);let r=em(e.property);return e.computed||"Identifier"===e.property.type||(r=`(${r})`),e.computed?`${t}[${r}]`:`${t}.${r}`}case"FilterExpression":{let t=em(e.operand,1/0);if("CallExpression"===e.filter.type)return`${t} | ${em(e.filter)}`;return`${t} | ${e.filter.value}`}case"SelectExpression":return`${em(e.lhs)} if ${em(e.test)}`;case"TestExpression":return`${em(e.operand)} is${e.negate?" not":""} ${e.test.value}`;case"ArrayLiteral":case"TupleLiteral":{let t=e.value.map(em),r="ArrayLiteral"===e.type?"[]":"()";return`${r[0]}${t.join(", ")}${r[1]}`}case"ObjectLiteral":{let t=Array.from(e.value.entries()).map(([e,t])=>`${em(e)}: ${em(t)}`);return`{${t.join(", ")}}`}case"SliceExpression":{let t=e.start?em(e.start):"",r=e.stop?em(e.stop):"",o=e.step?`:${em(e.step)}`:"";return`${t}:${r}${o}`}case"KeywordArgumentExpression":return`${e.key.value}=${em(e.value)}`;case"Ternary":{let r=`${em(e.trueExpr)} if ${em(e.condition,0)} else ${em(e.falseExpr)}`;return t>-1?`(${r})`:r}default:throw Error(`Unknown expression type: ${e.type}`)}}var ep=class{parsed;constructor(e){let t=d(e,{lstrip_blocks:!0,trim_blocks:!0});this.parsed=R(t)}render(e){let t=new en;if(t.set("false",!1),t.set("true",!0),t.set("none",null),t.set("raise_exception",e=>{throw Error(e)}),t.set("range",q),t.set("strftime_now",W),t.set("True",!0),t.set("False",!1),t.set("None",null),e)for(let[r,o]of Object.entries(e))t.set(r,o);return new ed(t).run(this.parsed).value}format(e){return function(e,t="	"){let r="number"==typeof t?" ".repeat(t):t;return(function e(t,r,o){return t.map(t=>(function(t,r,o){let s=o.repeat(r);switch(t.type){case"Program":return e(t.body,r,o);case"If":return function(t,r,o){let s=o.repeat(r),a=[],i=t;for(;i;)if(a.push({test:i.test,body:i.body}),1===i.alternate.length&&"If"===i.alternate[0].type)i=i.alternate[0];else break;let n=s+eu("if",em(a[0].test))+"\n"+e(a[0].body,r+1,o);for(let t=1;t<a.length;++t)n+="\n"+s+eu("elif",em(a[t].test))+"\n"+e(a[t].body,r+1,o);return i&&i.alternate.length>0&&(n+="\n"+s+eu("else")+"\n"+e(i.alternate,r+1,o)),n+="\n"+s+eu("endif")}(t,r,o);case"For":return function(t,r,o){let s=o.repeat(r),a="";if("SelectExpression"===t.iterable.type){let e=t.iterable;a=`${em(e.lhs)} if ${em(e.test)}`}else a=em(t.iterable);let i=s+eu("for",em(t.loopvar),"in",a)+"\n"+e(t.body,r+1,o);return t.defaultBlock.length>0&&(i+="\n"+s+eu("else")+"\n"+e(t.defaultBlock,r+1,o)),i+="\n"+s+eu("endfor")}(t,r,o);case"Set":return function(t,r,o){let s=o.repeat(r),a=em(t.assignee),i=t.value?em(t.value):"",n=s+eu("set",`${a}${t.value?" = "+i:""}`);return 0===t.body.length?n:n+"\n"+e(t.body,r+1,o)+"\n"+s+eu("endset")}(t,r,o);case"Macro":return function(t,r,o){let s=o.repeat(r),a=t.args.map(em).join(", ");return s+eu("macro",`${t.name.value}(${a})`)+"\n"+e(t.body,r+1,o)+"\n"+s+eu("endmacro")}(t,r,o);case"Break":return s+eu("break");case"Continue":return s+eu("continue");case"CallStatement":return function(t,r,o){let s=o.repeat(r),a=t.callerArgs&&t.callerArgs.length>0?`(${t.callerArgs.map(em).join(", ")})`:"",i=s+eu(`call${a}`,em(t.call))+"\n";return i+=e(t.body,r+1,o)+"\n",i+=s+eu("endcall")}(t,r,o);case"FilterStatement":return function(t,r,o){let s=o.repeat(r),a=s+eu("filter","Identifier"===t.filter.type?t.filter.value:em(t.filter))+"\n";return a+=e(t.body,r+1,o)+"\n",a+=s+eu("endfilter")}(t,r,o);case"Comment":return s+"{# "+t.value+" #}";default:return s+"{{- "+em(t)+" -}}"}})(t,r,o)).join("\n")})(e.body,0,r).replace(/\n$/,"")}(this.parsed,e?.indent||"	")}}},"./src/backends/onnx.js":(e,t,r)=>{let o,s;r.r(t),r.d(t,{Tensor:()=>d.Tensor,createInferenceSession:()=>f,deviceToExecutionProviders:()=>h,isONNXProxy:()=>b,isONNXTensor:()=>P,runInferenceSession:()=>T});var i,n=r("./src/env.js"),l=r("?2ce3"),c=r("onnxruntime-web"),d=r("onnxruntime-common");let u=Object.freeze({auto:null,gpu:null,cpu:"cpu",wasm:"wasm",webgpu:"webgpu",cuda:"cuda",dml:"dml",webnn:{name:"webnn",deviceType:"cpu"},"webnn-npu":{name:"webnn",deviceType:"npu"},"webnn-gpu":{name:"webnn",deviceType:"gpu"},"webnn-cpu":{name:"webnn",deviceType:"cpu"}}),m=[],p=Symbol.for("onnxruntime");if(p in globalThis)s=globalThis[p];else if(n.apis.IS_NODE_ENV){switch(s=l??(i||(i=r.t(l,2))),a.platform){case"win32":m.push("dml");break;case"linux":"x64"===a.arch&&m.push("cuda")}m.push("cpu"),o=["cpu"]}else s=c,n.apis.IS_WEBNN_AVAILABLE&&m.push("webnn-npu","webnn-gpu","webnn-cpu","webnn"),n.apis.IS_WEBGPU_AVAILABLE&&m.push("webgpu"),m.push("wasm"),o=["wasm"];let _=s.InferenceSession;function h(e=null){if(!e)return o;switch(e){case"auto":return m;case"gpu":return m.filter(e=>["webgpu","cuda","dml","webnn-gpu"].includes(e))}if(m.includes(e))return[u[e]??e];throw Error(`Unsupported device: "${e}". Should be one of: ${m.join(", ")}.`)}let g=null;async function f(e,t,r){g&&await g;let o=_.create(e,t);g??=o;let s=await o;return s.config=r,s}let M=Promise.resolve(),w=n.apis.IS_BROWSER_ENV||n.apis.IS_WEBWORKER_ENV;async function T(e,t){let r=()=>e.run(t);return await (w?M=M.then(r):r())}function P(e){return e instanceof s.Tensor}let x=s?.env;function b(){return x?.wasm?.proxy}x?.wasm&&("undefined"!=typeof ServiceWorkerGlobalScope&&self instanceof ServiceWorkerGlobalScope||x.wasm.wasmPaths||(x.wasm.wasmPaths=`https://cdn.jsdelivr.net/npm/@huggingface/transformers@${n.env.version}/dist/`),x.wasm.proxy=!1),x?.webgpu&&(x.webgpu.powerPreference="high-performance"),n.env.backends.onnx=x},"./src/base/feature_extraction_utils.js":(e,t,r)=>{r.r(t),r.d(t,{FeatureExtractor:()=>i,validate_audio_inputs:()=>n});var o=r("./src/utils/constants.js"),s=r("./src/utils/generic.js"),a=r("./src/utils/hub.js");class i extends s.Callable{constructor(e){super(),this.config=e}static async from_pretrained(e,t={}){return new this(await (0,a.getModelJSON)(e,o.FEATURE_EXTRACTOR_NAME,!0,t))}}function n(e,t){if(!(e instanceof Float32Array||e instanceof Float64Array))throw Error(`${t} expects input to be a Float32Array or a Float64Array, but got ${e?.constructor?.name??typeof e} instead. If using the feature extractor directly, remember to use \`read_audio(url, sampling_rate)\` to obtain the raw audio data of the file/url.`)}},"./src/base/image_processors_utils.js":(e,t,r)=>{r.r(t),r.d(t,{ImageProcessor:()=>g,center_to_corners_format:()=>u,post_process_instance_segmentation:()=>h,post_process_object_detection:()=>m,post_process_panoptic_segmentation:()=>_,post_process_semantic_segmentation:()=>p});var o=r("./src/utils/generic.js"),s=r("./src/utils/tensor.js"),a=r("./src/utils/maths.js");r("./src/utils/image.js");var i=r("./src/utils/core.js"),n=r("./src/utils/hub.js"),l=r("./src/utils/constants.js");function c(e,t,r=0,o=null){let s=e/t,i=(0,a.bankers_round)(s)*t;return null!==o&&i>o&&(i=Math.floor(s)*t),i<r&&(i=Math.ceil(s)*t),i}function d([e,t],r){return[Math.max(Math.floor(e/r),1)*r,Math.max(Math.floor(t/r),1)*r]}function u([e,t,r,o]){return[e-r/2,t-o/2,e+r/2,t+o/2]}function m(e,t=.5,r=null,o=!1){let s=e.logits,i=e.pred_boxes,[n,l,c]=s.dims;if(null!==r&&r.length!==n)throw Error("Make sure that you pass in as many target sizes as the batch dimension of the logits");let d=[];for(let e=0;e<n;++e){let n=null!==r?r[e]:null,m={boxes:[],classes:[],scores:[]},p=s[e],_=i[e];for(let e=0;e<l;++e){let r,s=p[e],i=[];if(o){r=s.sigmoid().data;for(let e=0;e<r.length;++e)r[e]>t&&i.push(e)}else{let e=(0,a.max)(s.data)[1];if(e===c-1||(r=(0,a.softmax)(s.data))[e]<t)continue;i.push(e)}for(let t of i){let o=_[e].data;o=u(o),null!==n&&(o=o.map((e,t)=>e*n[(t+1)%2])),m.boxes.push(o),m.classes.push(t),m.scores.push(r[t])}}d.push(m)}return d}function p(e,t=null){let r=e.logits,o=r.dims[0];if(null!==t&&t.length!==o)throw Error("Make sure that you pass in as many target sizes as the batch dimension of the logits");let a=[];for(let e=0;e<o;++e){let o=null!==t?t[e]:null,i=r[e];null!==o&&(i=(0,s.interpolate)(i,o,"bilinear",!1));let[n,l]=o??i.dims.slice(-2),c=new s.Tensor("int32",new Int32Array(n*l),[n,l]),d=i[0].data,u=c.data;for(let e=1;e<i.dims[0];++e){let t=i[e].data;for(let r=0;r<t.length;++r)t[r]>d[r]&&(d[r]=t[r],u[r]=e)}let m=Array(i.dims[0]);for(let e=0;e<u.length;++e){let t=u[e];m[t]=t}let p=m.filter(e=>void 0!==e);a.push({segmentation:c,labels:p})}return a}function _(e,t=.5,r=.5,o=.8,i=null,n=null){null===i&&(console.warn("`label_ids_to_fuse` unset. No instance will be fused."),i=new Set);let l=e.class_queries_logits??e.logits,c=(e.masks_queries_logits??e.pred_masks).sigmoid(),[d,u,m]=l.dims;if(m-=1,null!==n&&n.length!==d)throw Error("Make sure that you pass in as many target sizes as the batch dimension of the logits");let p=[];for(let e=0;e<d;++e){let d=null!==n?n[e]:null,u=l[e],_=c[e],[h,g,f]=function(e,t,r,o){let s=[],i=[],n=[];for(let l=0;l<e.dims[0];++l){let c=e[l],d=t[l],u=(0,a.max)(c.data)[1];if(u===o)continue;let m=(0,a.softmax)(c.data)[u];m>r&&(s.push(d),i.push(m),n.push(u))}return[s,i,n]}(u,_,t,m);if(0===f.length){let[e,t]=d??_.dims.slice(-2),r=new s.Tensor("int32",new Int32Array(e*t).fill(-1),[e,t]);p.push({segmentation:r,segments_info:[]});continue}let[M,w]=function(e,t,r,o,a,i=null,n=null){let[l,c]=n??e[0].dims,d=new s.Tensor("int32",new Int32Array(l*c),[l,c]),u=[];if(null!==n)for(let t=0;t<e.length;++t)e[t]=(0,s.interpolate)(e[t],n,"bilinear",!1);let m=new Int32Array(e[0].data.length),p=new Float32Array(e[0].data.length);for(let r=0;r<e.length;++r){let o=t[r],s=e[r].data;for(let e=0;e<s.length;++e)s[e]*=o,s[e]>p[e]&&(m[e]=r,p[e]=s[e])}let _=0,h=d.data;for(let s=0;s<r.length;++s){let i=r[s],[n,l]=function(e,t,r,o=.5,s=.8){let a=[],i=0,n=0,l=t[r].data;for(let t=0;t<e.length;++t)e[t]===r&&(a.push(t),++i),l[t]>=o&&++n;let c=i>0&&n>0;return c&&(c=i/n>s),[c,a]}(m,e,s,o,a);if(n){for(let e of(++_,l))h[e]=_;u.push({id:_,label_id:i,score:t[s]})}}return[d,u]}(h,g,f,r,o,i,d);p.push({segmentation:M,segments_info:w})}return p}function h(e,t=.5,r=null){throw Error("`post_process_instance_segmentation` is not yet implemented.")}class g extends o.Callable{constructor(e){super(),this.image_mean=e.image_mean??e.mean,this.image_std=e.image_std??e.std,this.resample=e.resample??2,this.do_rescale=e.do_rescale??!0,this.rescale_factor=e.rescale_factor??1/255,this.do_normalize=e.do_normalize,this.do_thumbnail=e.do_thumbnail,this.size=e.size??e.image_size,this.do_resize=e.do_resize??void 0!==this.size,this.size_divisibility=e.size_divisibility??e.size_divisor,this.do_center_crop=e.do_center_crop,this.crop_size=e.crop_size,this.do_convert_rgb=e.do_convert_rgb??!0,this.do_crop_margin=e.do_crop_margin,this.pad_size=e.pad_size,this.do_pad=e.do_pad,this.min_pixels=e.min_pixels,this.max_pixels=e.max_pixels,this.do_pad&&!this.pad_size&&this.size&&void 0!==this.size.width&&void 0!==this.size.height&&(this.pad_size=this.size),this.do_flip_channel_order=e.do_flip_channel_order??!1,this.config=e}async thumbnail(e,t,r=2){let o=e.height,s=e.width,a=t.height,i=t.width,n=Math.min(o,a),l=Math.min(s,i);return n===o&&l===s?e:(o>s?l=Math.floor(s*n/o):s>o&&(n=Math.floor(o*l/s)),await e.resize(l,n,{resample:r}))}async crop_margin(e,t=200){let r=e.clone().grayscale(),o=(0,a.min)(r.data)[0],s=(0,a.max)(r.data)[0]-o;if(0===s)return e;let i=t/255,n=r.width,l=r.height,c=0,d=0,u=r.data;for(let e=0;e<r.height;++e){let t=e*r.width;for(let a=0;a<r.width;++a)(u[t+a]-o)/s<i&&(n=Math.min(n,a),l=Math.min(l,e),c=Math.max(c,a),d=Math.max(d,e))}return e=await e.crop([n,l,c,d])}pad_image(e,t,r,{mode:o="constant",center:s=!1,constant_values:a=0}={}){let n,l;let[c,d,u]=t;if("number"==typeof r?(n=r,l=r):"square"===r?n=l=Math.max(c,d):(n=r.width,l=r.height),n!==d||l!==c){let r=new Float32Array(n*l*u);if(Array.isArray(a))for(let e=0;e<r.length;++e)r[e]=a[e%u];else 0!==a&&r.fill(a);let[m,p]=s?[Math.floor((n-d)/2),Math.floor((l-c)/2)]:[0,0];for(let t=0;t<c;++t){let o=(t+p)*n,s=t*d;for(let t=0;t<d;++t){let a=(o+t+m)*u,i=(s+t)*u;for(let t=0;t<u;++t)r[a+t]=e[i+t]}}if("symmetric"===o){if(s)throw Error("`center` padding is not supported when `mode` is set to `symmetric`.");let t=c-1,o=d-1;for(let s=0;s<l;++s){let a=s*n,l=(0,i.calculateReflectOffset)(s,t)*d;for(let t=0;t<n;++t){if(s<c&&t<d)continue;let n=(a+t)*u,m=(l+(0,i.calculateReflectOffset)(t,o))*u;for(let t=0;t<u;++t)r[n+t]=e[m+t]}}}e=r,t=[l,n,u]}return[e,t]}rescale(e){for(let t=0;t<e.length;++t)e[t]=this.rescale_factor*e[t]}get_resize_output_image_size(e,t){let r,o;let[s,a]=e.size;if(this.do_thumbnail){let{height:e,width:o}=t;r=Math.min(e,o)}else Number.isInteger(t)?(r=t,o=this.config.max_size??r):void 0!==t&&(r=t.shortest_edge,o=t.longest_edge);if(void 0!==r||void 0!==o){let e=void 0===r?1:Math.max(r/s,r/a),t=s*e,i=a*e,n=void 0===o?1:Math.min(o/t,o/i),l=Math.floor(Number((t*n).toFixed(2))),c=Math.floor(Number((i*n).toFixed(2)));return void 0!==this.size_divisibility&&([l,c]=d([l,c],this.size_divisibility)),[l,c]}if(void 0!==t&&void 0!==t.width&&void 0!==t.height){let e=t.width,r=t.height;if(this.config.keep_aspect_ratio&&this.config.ensure_multiple_of){let t=r/a,o=e/s;Math.abs(1-o)<Math.abs(1-t)?t=o:o=t,r=c(t*a,this.config.ensure_multiple_of),e=c(o*s,this.config.ensure_multiple_of)}return[e,r]}if(void 0!==this.size_divisibility)return d([s,a],this.size_divisibility);if(void 0!==this.min_pixels&&void 0!==this.max_pixels)return function(e,t,r=28,o=3136,s=1003520){if(e<r||t<r)throw Error(`height:${e} or width:${t} must be larger than factor:${r}`);if(Math.max(e,t)/Math.min(e,t)>200)throw Error(`absolute aspect ratio must be smaller than 200, got ${Math.max(e,t)/Math.min(e,t)}`);let a=Math.round(e/r)*r,i=Math.round(t/r)*r;if(a*i>s){let o=Math.sqrt(e*t/s);a=Math.floor(e/o/r)*r,i=Math.floor(t/o/r)*r}else if(a*i<o){let s=Math.sqrt(o/(e*t));a=Math.ceil(e*s/r)*r,i=Math.ceil(t*s/r)*r}return[a,i]}(a,s,this.config.patch_size*this.config.merge_size,this.min_pixels,this.max_pixels);throw Error(`Could not resize image due to unsupported \`this.size\` option in config: ${JSON.stringify(t)}`)}async resize(e){let[t,r]=this.get_resize_output_image_size(e,this.size);return await e.resize(t,r,{resample:this.resample})}async preprocess(e,{do_normalize:t=null,do_pad:r=null,do_convert_rgb:o=null,do_convert_grayscale:a=null,do_flip_channel_order:i=null}={}){this.do_crop_margin&&(e=await this.crop_margin(e));let[n,l]=e.size;if(o??this.do_convert_rgb?e=e.rgb():a&&(e=e.grayscale()),this.do_resize&&(e=await this.resize(e)),this.do_thumbnail&&(e=await this.thumbnail(e,this.size,this.resample)),this.do_center_crop){let t,r;Number.isInteger(this.crop_size)?(t=this.crop_size,r=this.crop_size):(t=this.crop_size.width,r=this.crop_size.height),e=await e.center_crop(t,r)}let c=[e.height,e.width],u=Float32Array.from(e.data),m=[e.height,e.width,e.channels];if(this.do_rescale&&this.rescale(u),t??this.do_normalize){let t=this.image_mean;Array.isArray(this.image_mean)||(t=Array(e.channels).fill(t));let r=this.image_std;if(Array.isArray(this.image_std)||(r=Array(e.channels).fill(r)),t.length!==e.channels||r.length!==e.channels)throw Error(`When set to arrays, the length of \`image_mean\` (${t.length}) and \`image_std\` (${r.length}) must match the number of channels in the image (${e.channels}).`);for(let o=0;o<u.length;o+=e.channels)for(let s=0;s<e.channels;++s)u[o+s]=(u[o+s]-t[s])/r[s]}if(r??this.do_pad){if(this.pad_size){let t=this.pad_image(u,[e.height,e.width,e.channels],this.pad_size);[u,m]=t}else if(this.size_divisibility){let[e,t]=d([m[1],m[0]],this.size_divisibility);[u,m]=this.pad_image(u,m,{width:e,height:t})}}if(i??this.do_flip_channel_order){if(3!==m[2])throw Error("Flipping channel order is only supported for RGB images.");for(let e=0;e<u.length;e+=3){let t=u[e];u[e]=u[e+2],u[e+2]=t}}return{original_size:[l,n],reshaped_input_size:c,pixel_values:new s.Tensor("float32",u,m).permute(2,0,1)}}async _call(e,...t){Array.isArray(e)||(e=[e]);let r=await Promise.all(e.map(e=>this.preprocess(e)));return{pixel_values:(0,s.stack)(r.map(e=>e.pixel_values),0),original_sizes:r.map(e=>e.original_size),reshaped_input_sizes:r.map(e=>e.reshaped_input_size)}}static async from_pretrained(e,t={}){return new this(await (0,n.getModelJSON)(e,l.IMAGE_PROCESSOR_NAME,!0,t))}}},"./src/base/processing_utils.js":(e,t,r)=>{r.r(t),r.d(t,{Processor:()=>i});var o=r("./src/utils/constants.js"),s=r("./src/utils/generic.js"),a=r("./src/utils/hub.js");class i extends s.Callable{static classes=["image_processor_class","tokenizer_class","feature_extractor_class"];static uses_processor_config=!1;static uses_chat_template_file=!1;constructor(e,t,r){super(),this.config=e,this.components=t,this.chat_template=r}get image_processor(){return this.components.image_processor}get tokenizer(){return this.components.tokenizer}get feature_extractor(){return this.components.feature_extractor}apply_chat_template(e,t={}){if(!this.tokenizer)throw Error("Unable to apply chat template without a tokenizer.");return this.tokenizer.apply_chat_template(e,{tokenize:!1,chat_template:this.chat_template??void 0,...t})}batch_decode(...e){if(!this.tokenizer)throw Error("Unable to decode without a tokenizer.");return this.tokenizer.batch_decode(...e)}decode(...e){if(!this.tokenizer)throw Error("Unable to decode without a tokenizer.");return this.tokenizer.decode(...e)}async _call(e,...t){for(let r of[this.image_processor,this.feature_extractor,this.tokenizer])if(r)return r(e,...t);throw Error("No image processor, feature extractor, or tokenizer found.")}static async from_pretrained(e,t={}){let[r,s,i]=await Promise.all([this.uses_processor_config?(0,a.getModelJSON)(e,o.PROCESSOR_NAME,!0,t):{},Promise.all(this.classes.filter(e=>e in this).map(async r=>{let o=await this[r].from_pretrained(e,t);return[r.replace(/_class$/,""),o]})).then(Object.fromEntries),this.uses_chat_template_file?(0,a.getModelText)(e,o.CHAT_TEMPLATE_NAME,!0,t):null]);return new this(r,s,i)}}},"./src/configs.js":(e,t,r)=>{r.r(t),r.d(t,{AutoConfig:()=>l,PretrainedConfig:()=>n,getCacheShapes:()=>i});var o=r("./src/utils/core.js"),s=r("./src/utils/hub.js");async function a(e,t){return await (0,s.getModelJSON)(e,"config.json",!0,t)}function i(e,t){if("lfm2"===e.model_type){let r=t?.prefix??"past_key_values",o="present"===r?"present":"past",s={},{layer_types:a,num_attention_heads:i,num_key_value_heads:n,hidden_size:l,conv_L_cache:c}=e,d=l/i,u=t?.batch_size??1;for(let e=0;e<a.length;++e)if("full_attention"===a[e])for(let t of["key","value"])s[`${r}.${e}.${t}`]=[u,n,0,d];else if("conv"===a[e])s[`${o}_conv.${e}`]=[u,l,c];else throw Error(`Unsupported layer type: ${a[e]}`);return s}return function(e,{prefix:t="past_key_values",batch_size:r=1}={}){let o={},s=e.normalized_config;if(s.is_encoder_decoder&&"num_encoder_heads"in s&&"num_decoder_heads"in s){let e=s.encoder_dim_kv??s.encoder_hidden_size/s.num_encoder_heads,a=s.decoder_dim_kv??s.decoder_hidden_size/s.num_decoder_heads,i=[r,s.num_encoder_heads,0,e],n=[r,s.num_decoder_heads,0,a];for(let e=0;e<s.num_decoder_layers;++e)o[`${t}.${e}.encoder.key`]=i,o[`${t}.${e}.encoder.value`]=i,o[`${t}.${e}.decoder.key`]=n,o[`${t}.${e}.decoder.value`]=n}else{let e=s.num_heads,a=s.num_layers,i=s.dim_kv??s.hidden_size/(s.num_attention_heads??e);if("falcon"===s.model_type){let s=[r*e,0,i];for(let e=0;e<a;++e)o[`${t}.${e}.key`]=s,o[`${t}.${e}.value`]=s}else if(s.multi_query){let s=[r*e,0,2*i];for(let e=0;e<a;++e)o[`${t}.${e}.key_value`]=s}else if("bloom"===s.model_type){let s=[r*e,i,0],n=[r*e,0,i];for(let e=0;e<a;++e)o[`${t}.${e}.key`]=s,o[`${t}.${e}.value`]=n}else if("openelm"===s.model_type)for(let s=0;s<a;++s){let a=[r,e[s],0,i];o[`${t}.${s}.key`]=a,o[`${t}.${s}.value`]=a}else{let s=[r,e,0,i];for(let e=0;e<a;++e)o[`${t}.${e}.key`]=s,o[`${t}.${e}.value`]=s}}return o}(e,t)}class n{model_type=null;is_encoder_decoder=!1;max_position_embeddings;"transformers.js_config";constructor(e){Object.assign(this,e),this.normalized_config=function e(t){let r={},s={};switch(t.model_type){case"llava":case"paligemma":case"gemma3":case"florence2":case"llava_onevision":case"idefics3":case"ultravox":case"voxtral":case"smolvlm":case"gemma3n":case"mistral3":s=e(t.text_config);break;case"moondream1":s=e(t.phi_config);break;case"musicgen":s=e(t.decoder);break;case"multi_modality":s=e(t.language_config);break;case"gpt2":case"gptj":case"jais":case"codegen":case"gpt_bigcode":r.num_heads="n_head",r.num_layers="n_layer",r.hidden_size="n_embd";break;case"gpt_neox":case"stablelm":case"opt":case"falcon":case"modernbert-decoder":r.num_heads="num_attention_heads",r.num_layers="num_hidden_layers",r.hidden_size="hidden_size";break;case"llama":case"llama4_text":case"nanochat":case"arcee":case"lfm2":case"smollm3":case"olmo":case"olmo2":case"mobilellm":case"granite":case"granitemoehybrid":case"cohere":case"mistral":case"starcoder2":case"qwen2":case"qwen2_vl":case"phi":case"phi3":case"phi3_v":case"llava_qwen2":r.num_heads="num_key_value_heads",r.num_layers="num_hidden_layers",r.hidden_size="hidden_size",r.num_attention_heads="num_attention_heads",r.dim_kv="head_dim";break;case"qwen3":case"gemma":case"gemma2":case"vaultgemma":case"gemma3_text":case"gemma3n_text":case"glm":case"helium":case"ernie4_5":case"ministral":case"ministral3":r.num_heads="num_key_value_heads",r.num_layers="num_hidden_layers",r.dim_kv="head_dim";break;case"openelm":r.num_heads="num_kv_heads",r.num_layers="num_transformer_layers",r.dim_kv="head_dim";break;case"gpt_neo":case"donut-swin":r.num_heads="num_heads",r.num_layers="num_layers",r.hidden_size="hidden_size";break;case"bloom":r.num_heads="n_head",r.num_layers="n_layer",r.hidden_size="hidden_size";break;case"mpt":r.num_heads="n_heads",r.num_layers="n_layers",r.hidden_size="d_model";break;case"exaone":r.num_heads="num_key_value_heads",r.num_layers="num_layers",r.dim_kv="head_dim",r.num_attention_heads="num_attention_heads";break;case"t5":case"mt5":case"longt5":r.num_decoder_layers="num_decoder_layers",r.num_decoder_heads="num_heads",r.decoder_dim_kv="d_kv",r.num_encoder_layers="num_layers",r.num_encoder_heads="num_heads",r.encoder_dim_kv="d_kv";break;case"bart":case"mbart":case"marian":case"whisper":case"lite-whisper":case"m2m_100":case"blenderbot":case"blenderbot-small":case"florence2_language":r.num_decoder_layers="decoder_layers",r.num_decoder_heads="decoder_attention_heads",r.decoder_hidden_size="d_model",r.num_encoder_layers="encoder_layers",r.num_encoder_heads="encoder_attention_heads",r.encoder_hidden_size="d_model";break;case"speecht5":r.num_decoder_layers="decoder_layers",r.num_decoder_heads="decoder_attention_heads",r.decoder_hidden_size="hidden_size",r.num_encoder_layers="encoder_layers",r.num_encoder_heads="encoder_attention_heads",r.encoder_hidden_size="hidden_size";break;case"trocr":r.num_encoder_layers=r.num_decoder_layers="decoder_layers",r.num_encoder_heads=r.num_decoder_heads="decoder_attention_heads",r.encoder_hidden_size=r.decoder_hidden_size="d_model";break;case"musicgen_decoder":r.num_encoder_layers=r.num_decoder_layers="num_hidden_layers",r.num_encoder_heads=r.num_decoder_heads="num_attention_heads",r.encoder_hidden_size=r.decoder_hidden_size="hidden_size";break;case"moonshine":r.num_decoder_layers="decoder_num_hidden_layers",r.num_decoder_heads="decoder_num_key_value_heads",r.num_encoder_layers="encoder_num_hidden_layers",r.num_encoder_heads="encoder_num_key_value_heads",r.encoder_hidden_size=r.decoder_hidden_size="hidden_size";break;case"vision-encoder-decoder":let a=e(t.decoder),i="num_decoder_layers"in a,n=(0,o.pick)(t,["model_type","is_encoder_decoder"]);return i?(n.num_decoder_layers=a.num_decoder_layers,n.num_decoder_heads=a.num_decoder_heads,n.decoder_hidden_size=a.decoder_hidden_size,n.num_encoder_layers=a.num_encoder_layers,n.num_encoder_heads=a.num_encoder_heads,n.encoder_hidden_size=a.encoder_hidden_size):(n.num_layers=a.num_layers,n.num_heads=a.num_heads,n.hidden_size=a.hidden_size),n}let l={...s,...(0,o.pick)(t,["model_type","multi_query","is_encoder_decoder"])};for(let e in r)l[e]=t[r[e]];return l}(this)}static async from_pretrained(e,{progress_callback:t=null,config:r=null,cache_dir:o=null,local_files_only:s=!1,revision:i="main"}={}){return!r||r instanceof n||(r=new n(r)),new this(r??await a(e,{progress_callback:t,config:r,cache_dir:o,local_files_only:s,revision:i}))}}class l{static async from_pretrained(...e){return n.from_pretrained(...e)}}},"./src/env.js":(e,t,r)=>{r.r(t),r.d(t,{apis:()=>f,env:()=>x});var o=r("?db59"),s=r("?383f"),i=r("?fa4b");let n="undefined"!=typeof window&&void 0!==window.document,l="undefined"!=typeof self&&["DedicatedWorkerGlobalScope","ServiceWorkerGlobalScope","SharedWorkerGlobalScope"].includes(self.constructor?.name),c="undefined"!=typeof self&&"caches"in self,d="undefined"!=typeof navigator&&"gpu"in navigator,u="undefined"!=typeof navigator&&"ml"in navigator,m=void 0!==a,p=m&&a?.release?.name==="node",_=!b(o),h=!b(s),g=void 0!==globalThis.Deno;globalThis.Bun;let f=Object.freeze({IS_BROWSER_ENV:n,IS_WEBWORKER_ENV:l,IS_WEB_CACHE_AVAILABLE:c,IS_WEBGPU_AVAILABLE:d,IS_WEBNN_AVAILABLE:u,IS_PROCESS_AVAILABLE:m,IS_NODE_ENV:p,IS_FS_AVAILABLE:_,IS_PATH_AVAILABLE:h}),M=_&&h,w="./";if(M){let e=Object({}).url;e?w=s.dirname(s.dirname(i.fileURLToPath(e))):"undefined"!=typeof __dirname&&(w=s.dirname(__dirname))}let T=M?s.join(w,"/.cache/"):null,P="/models/",x={version:"3.8.1",backends:{onnx:{}},allowRemoteModels:!0,remoteHost:"https://huggingface.co/",remotePathTemplate:"{model}/resolve/{revision}/",allowLocalModels:!(n||l),localModelPath:M?s.join(w,P):P,useFS:_,useBrowserCache:c&&!g,useFSCache:_,cacheDir:T,useCustomCache:!1,customCache:null};function b(e){return 0===Object.keys(e).length}},"./src/generation/configuration_utils.js":(e,t,r)=>{r.r(t),r.d(t,{GenerationConfig:()=>s});var o=r("./src/utils/core.js");class s{max_length=20;max_new_tokens=null;min_length=0;min_new_tokens=null;early_stopping=!1;max_time=null;do_sample=!1;num_beams=1;num_beam_groups=1;penalty_alpha=null;use_cache=!0;temperature=1;top_k=50;top_p=1;typical_p=1;epsilon_cutoff=0;eta_cutoff=0;diversity_penalty=0;repetition_penalty=1;encoder_repetition_penalty=1;length_penalty=1;no_repeat_ngram_size=0;bad_words_ids=null;force_words_ids=null;renormalize_logits=!1;constraints=null;forced_bos_token_id=null;forced_eos_token_id=null;remove_invalid_values=!1;exponential_decay_length_penalty=null;suppress_tokens=null;streamer=null;begin_suppress_tokens=null;forced_decoder_ids=null;guidance_scale=null;num_return_sequences=1;output_attentions=!1;output_hidden_states=!1;output_scores=!1;return_dict_in_generate=!1;pad_token_id=null;bos_token_id=null;eos_token_id=null;encoder_no_repeat_ngram_size=0;decoder_start_token_id=null;generation_kwargs={};constructor(e){Object.assign(this,(0,o.pick)(e,Object.getOwnPropertyNames(this)))}}},"./src/generation/logits_process.js":(e,t,r)=>{r.r(t),r.d(t,{ClassifierFreeGuidanceLogitsProcessor:()=>f,ForcedBOSTokenLogitsProcessor:()=>l,ForcedEOSTokenLogitsProcessor:()=>c,LogitsProcessor:()=>a,LogitsProcessorList:()=>n,LogitsWarper:()=>i,MinLengthLogitsProcessor:()=>_,MinNewTokensLengthLogitsProcessor:()=>h,NoBadWordsLogitsProcessor:()=>g,NoRepeatNGramLogitsProcessor:()=>m,RepetitionPenaltyLogitsProcessor:()=>p,SuppressTokensAtBeginLogitsProcessor:()=>d,TemperatureLogitsWarper:()=>M,TopKLogitsWarper:()=>T,TopPLogitsWarper:()=>w,WhisperTimeStampLogitsProcessor:()=>u});var o=r("./src/utils/generic.js");r("./src/utils/tensor.js");var s=r("./src/utils/maths.js");class a extends o.Callable{_call(e,t){throw Error("`_call` should be implemented in a subclass")}}class i extends o.Callable{_call(e,t){throw Error("`_call` should be implemented in a subclass")}}class n extends o.Callable{constructor(){super(),this.processors=[]}push(e){this.processors.push(e)}extend(e){this.processors.push(...e)}_call(e,t){let r=t;for(let t of this.processors)r=t(e,r);return r}[Symbol.iterator](){return this.processors.values()}}class l extends a{constructor(e){super(),this.bos_token_id=e}_call(e,t){for(let r=0;r<e.length;++r)if(1===e[r].length){let e=t[r].data;e.fill(-1/0),e[this.bos_token_id]=0}return t}}class c extends a{constructor(e,t){super(),this.max_length=e,this.eos_token_id=Array.isArray(t)?t:[t]}_call(e,t){for(let r=0;r<e.length;++r)if(e[r].length===this.max_length-1){let e=t[r].data;for(let t of(e.fill(-1/0),this.eos_token_id))e[t]=0}return t}}class d extends a{constructor(e,t){super(),this.begin_suppress_tokens=e,this.begin_index=t}_call(e,t){for(let r=0;r<e.length;++r)if(e[r].length===this.begin_index){let e=t[r].data;for(let t of this.begin_suppress_tokens)e[t]=-1/0}return t}}class u extends a{constructor(e,t){super(),this.eos_token_id=Array.isArray(e.eos_token_id)?e.eos_token_id[0]:e.eos_token_id,this.no_timestamps_token_id=e.no_timestamps_token_id,this.timestamp_begin=this.no_timestamps_token_id+1,this.begin_index=t.length,t.at(-1)===this.no_timestamps_token_id&&(this.begin_index-=1),this.max_initial_timestamp_index=e.max_initial_timestamp_index}_call(e,t){for(let r=0;r<e.length;++r){let o=t[r].data;if(o[this.no_timestamps_token_id]=-1/0,e[r].length===this.begin_index-1){o.fill(-1/0),o[this.timestamp_begin]=0;continue}let a=e[r].slice(this.begin_index),i=a.length>=1&&a[a.length-1]>=this.timestamp_begin,n=a.length<2||a[a.length-2]>=this.timestamp_begin;if(i&&(n?o.subarray(this.timestamp_begin).fill(-1/0):o.subarray(0,this.eos_token_id).fill(-1/0)),e[r].length===this.begin_index&&null!==this.max_initial_timestamp_index){let e=this.timestamp_begin+this.max_initial_timestamp_index;o.subarray(e+1).fill(-1/0)}let l=(0,s.log_softmax)(o);Math.log(l.subarray(this.timestamp_begin).map(Math.exp).reduce((e,t)=>e+t))>(0,s.max)(l.subarray(0,this.timestamp_begin))[0]&&o.subarray(0,this.timestamp_begin).fill(-1/0)}return t}}class m extends a{constructor(e){super(),this.no_repeat_ngram_size=e}getNgrams(e){let t=e.length,r=[];for(let o=0;o<t+1-this.no_repeat_ngram_size;++o){let t=[];for(let r=0;r<this.no_repeat_ngram_size;++r)t.push(e[o+r]);r.push(t.map(Number))}let o=new Map;for(let e of r){let t=JSON.stringify(e.slice(0,e.length-1)),r=o.get(t)??[];r.push(e[e.length-1]),o.set(t,r)}return o}getGeneratedNgrams(e,t){let r=t.slice(t.length+1-this.no_repeat_ngram_size,t.length);return e.get(JSON.stringify(r.map(Number)))??[]}calcBannedNgramTokens(e){if(e.length+1<this.no_repeat_ngram_size)return[];{let t=this.getNgrams(e);return this.getGeneratedNgrams(t,e)}}_call(e,t){for(let r=0;r<e.length;++r){let o=t[r].data;for(let t of this.calcBannedNgramTokens(e[r]))o[t]=-1/0}return t}}class p extends a{constructor(e){super(),this.penalty=e}_call(e,t){for(let r=0;r<e.length;++r){let o=t[r].data;for(let t of new Set(e[r])){let e=Number(t);o[e]<0?o[e]*=this.penalty:o[e]/=this.penalty}}return t}}class _ extends a{constructor(e,t){super(),this.min_length=e,this.eos_token_id=Array.isArray(t)?t:[t]}_call(e,t){for(let r=0;r<e.length;++r)if(e[r].length<this.min_length){let e=t[r].data;for(let t of this.eos_token_id)e[t]=-1/0}return t}}class h extends a{constructor(e,t,r){super(),this.prompt_length_to_skip=e,this.min_new_tokens=t,this.eos_token_id=Array.isArray(r)?r:[r]}_call(e,t){for(let r=0;r<e.length;++r)if(e[r].length-this.prompt_length_to_skip<this.min_new_tokens){let e=t[r].data;for(let t of this.eos_token_id)e[t]=-1/0}return t}}class g extends a{constructor(e,t){super(),this.bad_words_ids=e,this.eos_token_id=Array.isArray(t)?t:[t]}_call(e,t){for(let r=0;r<e.length;++r){let o=t[r].data,s=e[r];for(let e of this.bad_words_ids){if(s.length<e.length-1)continue;let t=!0;for(let r=1;r<=e.length-1;++r)if(e.at(-r-1)!=s.at(-r)){t=!1;break}t&&(o[e.at(-1)]=-1/0)}}return t}}class f extends a{constructor(e){if(super(),e<=1)throw Error(`Require guidance scale >1 to use the classifier free guidance processor, got guidance scale ${e}.`);this.guidance_scale=e}_call(e,t){if(t.dims[0]!==2*e.length)throw Error(`Logits should have twice the batch size of the input ids, the first half of batches corresponding to the conditional inputs, and the second half of batches corresponding to the unconditional inputs. Got batch size ${t.dims[0]} for the logits and ${e.length} for the input ids.`);let r=e.length,o=t.slice([0,r],null),s=t.slice([r,t.dims[0]],null);for(let e=0;e<s.data.length;++e)s.data[e]+=(o.data[e]-s.data[e])*this.guidance_scale;return s}}class M extends i{constructor(e){super(),this.temperature=e}_call(e,t){let r=t.data;for(let e=0;e<r.length;++e)r[e]/=this.temperature;return t}}class w extends i{constructor(e,{filter_value:t=-1/0,min_tokens_to_keep:r=1}={}){if(super(),e<0||e>1)throw Error(`\`top_p\` must be a float > 0 and < 1, but is ${e}`);if(!Number.isInteger(r)||r<1)throw Error(`\`min_tokens_to_keep\` must be a positive integer, but is ${r}`);this.top_p=e,this.filter_value=t,this.min_tokens_to_keep=r}}class T extends i{constructor(e,{filter_value:t=-1/0,min_tokens_to_keep:r=1}={}){if(super(),!Number.isInteger(e)||e<0)throw Error(`\`top_k\` must be a positive integer, but is ${e}`);this.top_k=Math.max(e,r),this.filter_value=t}}},"./src/generation/logits_sampler.js":(e,t,r)=>{r.r(t),r.d(t,{LogitsSampler:()=>i});var o=r("./src/utils/generic.js"),s=r("./src/utils/tensor.js"),a=r("./src/utils/maths.js");r("./src/generation/configuration_utils.js");class i extends o.Callable{constructor(e){super(),this.generation_config=e}async _call(e){return this.sample(e)}async sample(e){throw Error("sample should be implemented in subclasses.")}getLogits(e,t){let r=e.dims.at(-1),o=e.data;if(-1===t)o=o.slice(-r);else{let e=t*r;o=o.slice(e,e+r)}return o}randomSelect(e){let t=0;for(let r=0;r<e.length;++r)t+=e[r];let r=Math.random()*t;for(let t=0;t<e.length;++t)if((r-=e[t])<=0)return t;return 0}static getSampler(e){if(e.do_sample)return new l(e);if(e.num_beams>1)return new c(e);if(e.num_return_sequences>1)throw Error(`num_return_sequences has to be 1 when doing greedy search, but is ${e.num_return_sequences}.`);return new n(e)}}class n extends i{async sample(e){return[[BigInt((0,a.max)(e.data)[1]),0]]}}class l extends i{async sample(e){let t=e.dims.at(-1);this.generation_config.top_k>0&&(t=Math.min(this.generation_config.top_k,t));let[r,o]=await (0,s.topk)(e,t),i=(0,a.softmax)(r.data);return Array.from({length:this.generation_config.num_beams},()=>{let e=this.randomSelect(i);return[o.data[e],Math.log(i[e])]})}}class c extends i{async sample(e){let t=e.dims.at(-1);this.generation_config.top_k>0&&(t=Math.min(this.generation_config.top_k,t));let[r,o]=await (0,s.topk)(e,t),i=(0,a.softmax)(r.data);return Array.from({length:this.generation_config.num_beams},(e,t)=>[o.data[t],Math.log(i[t])])}}},"./src/generation/stopping_criteria.js":(e,t,r)=>{r.r(t),r.d(t,{EosTokenCriteria:()=>n,InterruptableStoppingCriteria:()=>l,MaxLengthCriteria:()=>i,StoppingCriteria:()=>s,StoppingCriteriaList:()=>a});var o=r("./src/utils/generic.js");class s extends o.Callable{_call(e,t){throw Error("StoppingCriteria needs to be subclassed")}}class a extends o.Callable{constructor(){super(),this.criteria=[]}push(e){this.criteria.push(e)}extend(e){e instanceof a?e=e.criteria:e instanceof s&&(e=[e]),this.criteria.push(...e)}_call(e,t){let r=Array(e.length).fill(!1);for(let o of this.criteria){let s=o(e,t);for(let e=0;e<r.length;++e)r[e]||=s[e]}return r}[Symbol.iterator](){return this.criteria.values()}}class i extends s{constructor(e,t=null){super(),this.max_length=e,this.max_position_embeddings=t}_call(e){return e.map(e=>e.length>=this.max_length)}}class n extends s{constructor(e){super(),Array.isArray(e)||(e=[e]),this.eos_token_id=e}_call(e,t){return e.map(e=>{let t=e.at(-1);return this.eos_token_id.some(e=>t==e)})}}class l extends s{constructor(){super(),this.interrupted=!1}interrupt(){this.interrupted=!0}reset(){this.interrupted=!1}_call(e,t){return Array(e.length).fill(this.interrupted)}}},"./src/generation/streamers.js":(e,t,r)=>{r.r(t),r.d(t,{BaseStreamer:()=>n,TextStreamer:()=>c,WhisperTextStreamer:()=>d});var o=r("./src/utils/core.js"),s=r("./src/tokenizers.js"),i=r("./src/env.js");class n{put(e){throw Error("Not implemented")}end(){throw Error("Not implemented")}}let l=i.apis.IS_PROCESS_AVAILABLE?e=>a.stdout.write(e):e=>console.log(e);class c extends n{constructor(e,{skip_prompt:t=!1,callback_function:r=null,token_callback_function:o=null,skip_special_tokens:s=!0,decode_kwargs:a={},...i}={}){super(),this.tokenizer=e,this.skip_prompt=t,this.callback_function=r??l,this.token_callback_function=o,this.decode_kwargs={skip_special_tokens:s,...a,...i},this.token_cache=[],this.print_len=0,this.next_tokens_are_prompt=!0}put(e){let t;if(e.length>1)throw Error("TextStreamer only supports batch size of 1");let r=this.next_tokens_are_prompt;if(r&&(this.next_tokens_are_prompt=!1,this.skip_prompt))return;let a=e[0];this.token_callback_function?.(a),this.token_cache=(0,o.mergeArrays)(this.token_cache,a);let i=this.tokenizer.decode(this.token_cache,this.decode_kwargs);r||i.endsWith("\n")?(t=i.slice(this.print_len),this.token_cache=[],this.print_len=0):(t=i.length>0&&(0,s.is_chinese_char)(i.charCodeAt(i.length-1))?i.slice(this.print_len):i.slice(this.print_len,i.lastIndexOf(" ")+1),this.print_len+=t.length),this.on_finalized_text(t,!1)}end(){let e;this.token_cache.length>0?(e=this.tokenizer.decode(this.token_cache,this.decode_kwargs).slice(this.print_len),this.token_cache=[],this.print_len=0):e="",this.next_tokens_are_prompt=!0,this.on_finalized_text(e,!0)}on_finalized_text(e,t){e.length>0&&this.callback_function?.(e),t&&this.callback_function===l&&i.apis.IS_PROCESS_AVAILABLE&&this.callback_function?.("\n")}}class d extends c{constructor(e,{skip_prompt:t=!1,callback_function:r=null,token_callback_function:o=null,on_chunk_start:s=null,on_chunk_end:a=null,on_finalize:i=null,time_precision:n=.02,skip_special_tokens:l=!0,decode_kwargs:c={}}={}){super(e,{skip_prompt:t,skip_special_tokens:l,callback_function:r,token_callback_function:o,decode_kwargs:c}),this.timestamp_begin=e.timestamp_begin,this.on_chunk_start=s,this.on_chunk_end=a,this.on_finalize=i,this.time_precision=n,this.waiting_for_timestamp=!1}put(e){if(e.length>1)throw Error("WhisperTextStreamer only supports batch size of 1");let t=e[0];if(1===t.length){let e=Number(t[0])-this.timestamp_begin;if(e>=0){let r=e*this.time_precision;this.waiting_for_timestamp?this.on_chunk_end?.(r):this.on_chunk_start?.(r),this.waiting_for_timestamp=!this.waiting_for_timestamp,this.token_callback_function?.(t);return}}return super.put(e)}end(){super.end(),this.on_finalize?.()}}},"./src/models.js":(e,t,r)=>{r.r(t),r.d(t,{ASTForAudioClassification:()=>re,ASTModel:()=>t7,ASTPreTrainedModel:()=>t9,AlbertForMaskedLM:()=>tw,AlbertForQuestionAnswering:()=>tM,AlbertForSequenceClassification:()=>tf,AlbertModel:()=>tg,AlbertPreTrainedModel:()=>th,ArceeForCausalLM:()=>om,ArceeModel:()=>ou,ArceePreTrainedModel:()=>od,AutoModel:()=>cu,AutoModelForAudioClassification:()=>cE,AutoModelForAudioFrameClassification:()=>cL,AutoModelForAudioTextToText:()=>cG,AutoModelForCTC:()=>cS,AutoModelForCausalLM:()=>cM,AutoModelForDepthEstimation:()=>cj,AutoModelForDocumentQuestionAnswering:()=>cI,AutoModelForImageClassification:()=>cx,AutoModelForImageFeatureExtraction:()=>cN,AutoModelForImageMatting:()=>cD,AutoModelForImageSegmentation:()=>cb,AutoModelForImageTextToText:()=>cB,AutoModelForImageToImage:()=>cz,AutoModelForMaskGeneration:()=>cC,AutoModelForMaskedLM:()=>cw,AutoModelForNormalEstimation:()=>cV,AutoModelForObjectDetection:()=>cy,AutoModelForPoseEstimation:()=>cO,AutoModelForQuestionAnswering:()=>cT,AutoModelForSemanticSegmentation:()=>cF,AutoModelForSeq2SeqLM:()=>c_,AutoModelForSequenceClassification:()=>cm,AutoModelForSpeechSeq2Seq:()=>ch,AutoModelForTextToSpectrogram:()=>cg,AutoModelForTextToWaveform:()=>cf,AutoModelForTokenClassification:()=>cp,AutoModelForUniversalSegmentation:()=>ck,AutoModelForVision2Seq:()=>cP,AutoModelForXVector:()=>cA,AutoModelForZeroShotObjectDetection:()=>cv,BartForConditionalGeneration:()=>tA,BartForSequenceClassification:()=>tL,BartModel:()=>tE,BartPretrainedModel:()=>tS,BaseModelOutput:()=>Q,BeitForImageClassification:()=>s3,BeitModel:()=>s2,BeitPreTrainedModel:()=>s1,BertForMaskedLM:()=>J,BertForQuestionAnswering:()=>Z,BertForSequenceClassification:()=>Y,BertForTokenClassification:()=>K,BertModel:()=>H,BertPreTrainedModel:()=>X,BlenderbotForConditionalGeneration:()=>tB,BlenderbotModel:()=>tN,BlenderbotPreTrainedModel:()=>tO,BlenderbotSmallForConditionalGeneration:()=>tq,BlenderbotSmallModel:()=>tR,BlenderbotSmallPreTrainedModel:()=>tG,BloomForCausalLM:()=>sp,BloomModel:()=>sm,BloomPreTrainedModel:()=>su,CLIPModel:()=>rv,CLIPPreTrainedModel:()=>ry,CLIPSegForImageSegmentation:()=>r$,CLIPSegModel:()=>rq,CLIPSegPreTrainedModel:()=>rR,CLIPTextModel:()=>rC,CLIPTextModelWithProjection:()=>rS,CLIPVisionModel:()=>rE,CLIPVisionModelWithProjection:()=>rA,CamembertForMaskedLM:()=>ej,CamembertForQuestionAnswering:()=>eN,CamembertForSequenceClassification:()=>eV,CamembertForTokenClassification:()=>eO,CamembertModel:()=>ez,CamembertPreTrainedModel:()=>eD,CausalLMOutput:()=>cX,CausalLMOutputWithPast:()=>cH,ChineseCLIPModel:()=>rV,ChineseCLIPPreTrainedModel:()=>rj,ClapAudioModelWithProjection:()=>nz,ClapModel:()=>nI,ClapPreTrainedModel:()=>nL,ClapTextModelWithProjection:()=>nD,CodeGenForCausalLM:()=>ot,CodeGenModel:()=>oe,CodeGenPreTrainedModel:()=>r7,CohereForCausalLM:()=>oW,CohereModel:()=>o$,CoherePreTrainedModel:()=>oq,ConvBertForMaskedLM:()=>eF,ConvBertForQuestionAnswering:()=>ev,ConvBertForSequenceClassification:()=>ek,ConvBertForTokenClassification:()=>ey,ConvBertModel:()=>eb,ConvBertPreTrainedModel:()=>ex,ConvNextForImageClassification:()=>a8,ConvNextModel:()=>a5,ConvNextPreTrainedModel:()=>a4,ConvNextV2ForImageClassification:()=>a7,ConvNextV2Model:()=>a9,ConvNextV2PreTrainedModel:()=>a6,DFineForObjectDetection:()=>a_,DFineModel:()=>ap,DFinePreTrainedModel:()=>am,DINOv3ConvNextModel:()=>id,DINOv3ConvNextPreTrainedModel:()=>ic,DINOv3ViTModel:()=>il,DINOv3ViTPreTrainedModel:()=>ii,DPTForDepthEstimation:()=>aV,DPTModel:()=>aj,DPTPreTrainedModel:()=>az,DacDecoderModel:()=>lA,DacDecoderOutput:()=>lC,DacEncoderModel:()=>lE,DacEncoderOutput:()=>lv,DacModel:()=>lS,DacPreTrainedModel:()=>ly,DebertaForMaskedLM:()=>eR,DebertaForQuestionAnswering:()=>eW,DebertaForSequenceClassification:()=>eq,DebertaForTokenClassification:()=>e$,DebertaModel:()=>eG,DebertaPreTrainedModel:()=>eB,DebertaV2ForMaskedLM:()=>eX,DebertaV2ForQuestionAnswering:()=>eY,DebertaV2ForSequenceClassification:()=>eH,DebertaV2ForTokenClassification:()=>eJ,DebertaV2Model:()=>eQ,DebertaV2PreTrainedModel:()=>eU,DecisionTransformerModel:()=>la,DecisionTransformerPreTrainedModel:()=>ls,DeiTForImageClassification:()=>aP,DeiTModel:()=>aT,DeiTPreTrainedModel:()=>aw,DepthAnythingForDepthEstimation:()=>aN,DepthAnythingPreTrainedModel:()=>aO,DepthProForDepthEstimation:()=>aW,DepthProPreTrainedModel:()=>a$,DetrForObjectDetection:()=>s8,DetrForSegmentation:()=>s6,DetrModel:()=>s5,DetrObjectDetectionOutput:()=>s9,DetrPreTrainedModel:()=>s4,DetrSegmentationOutput:()=>s7,Dinov2ForImageClassification:()=>ir,Dinov2Model:()=>it,Dinov2PreTrainedModel:()=>ie,Dinov2WithRegistersForImageClassification:()=>ia,Dinov2WithRegistersModel:()=>is,Dinov2WithRegistersPreTrainedModel:()=>io,DistilBertForMaskedLM:()=>e3,DistilBertForQuestionAnswering:()=>e2,DistilBertForSequenceClassification:()=>e0,DistilBertForTokenClassification:()=>e1,DistilBertModel:()=>eZ,DistilBertPreTrainedModel:()=>eK,DonutSwinModel:()=>a3,DonutSwinPreTrainedModel:()=>a2,EdgeTamModel:()=>iF,EfficientNetForImageClassification:()=>nQ,EfficientNetModel:()=>nU,EfficientNetPreTrainedModel:()=>nW,ElectraForMaskedLM:()=>eE,ElectraForQuestionAnswering:()=>eI,ElectraForSequenceClassification:()=>eA,ElectraForTokenClassification:()=>eL,ElectraModel:()=>eS,ElectraPreTrainedModel:()=>eC,Ernie4_5ForCausalLM:()=>nk,Ernie4_5Model:()=>nF,Ernie4_5PreTrainedModel:()=>nb,EsmForMaskedLM:()=>e8,EsmForSequenceClassification:()=>e6,EsmForTokenClassification:()=>e9,EsmModel:()=>e5,EsmPreTrainedModel:()=>e4,ExaoneForCausalLM:()=>ov,ExaoneModel:()=>oy,ExaonePreTrainedModel:()=>ok,FalconForCausalLM:()=>nA,FalconModel:()=>nE,FalconPreTrainedModel:()=>nS,FastViTForImageClassification:()=>sB,FastViTModel:()=>sN,FastViTPreTrainedModel:()=>sO,Florence2ForConditionalGeneration:()=>r_,Florence2PreTrainedModel:()=>rp,GLPNForDepthEstimation:()=>a1,GLPNModel:()=>a0,GLPNPreTrainedModel:()=>aZ,GPT2LMHeadModel:()=>rQ,GPT2Model:()=>rU,GPT2PreTrainedModel:()=>rW,GPTBigCodeForCausalLM:()=>r9,GPTBigCodeModel:()=>r6,GPTBigCodePreTrainedModel:()=>r8,GPTJForCausalLM:()=>r5,GPTJModel:()=>r4,GPTJPreTrainedModel:()=>r3,GPTNeoForCausalLM:()=>rZ,GPTNeoModel:()=>rK,GPTNeoPreTrainedModel:()=>rY,GPTNeoXForCausalLM:()=>r2,GPTNeoXModel:()=>r1,GPTNeoXPreTrainedModel:()=>r0,Gemma2ForCausalLM:()=>oY,Gemma2Model:()=>oJ,Gemma2PreTrainedModel:()=>oH,Gemma3ForCausalLM:()=>o3,Gemma3Model:()=>o2,Gemma3PreTrainedModel:()=>o1,Gemma3nForConditionalGeneration:()=>rT,Gemma3nPreTrainedModel:()=>rw,GemmaForCausalLM:()=>oX,GemmaModel:()=>oQ,GemmaPreTrainedModel:()=>oU,GlmForCausalLM:()=>oF,GlmModel:()=>ob,GlmPreTrainedModel:()=>ox,GraniteForCausalLM:()=>oN,GraniteModel:()=>oO,GraniteMoeHybridForCausalLM:()=>oR,GraniteMoeHybridModel:()=>oG,GraniteMoeHybridPreTrainedModel:()=>oB,GranitePreTrainedModel:()=>oV,GroundingDinoForObjectDetection:()=>im,GroundingDinoPreTrainedModel:()=>iu,GroupViTModel:()=>sV,GroupViTPreTrainedModel:()=>sj,HeliumForCausalLM:()=>oP,HeliumModel:()=>oT,HeliumPreTrainedModel:()=>ow,HieraForImageClassification:()=>aF,HieraModel:()=>ab,HieraPreTrainedModel:()=>ax,HubertForCTC:()=>i5,HubertForSequenceClassification:()=>i8,HubertModel:()=>i4,HubertPreTrainedModel:()=>i3,IJepaForImageClassification:()=>sk,IJepaModel:()=>sF,IJepaPreTrainedModel:()=>sb,Idefics3ForConditionalGeneration:()=>rx,Idefics3PreTrainedModel:()=>rP,ImageMattingOutput:()=>cJ,JAISLMHeadModel:()=>rJ,JAISModel:()=>rH,JAISPreTrainedModel:()=>rX,JinaCLIPModel:()=>rN,JinaCLIPPreTrainedModel:()=>rO,JinaCLIPTextModel:()=>rB,JinaCLIPVisionModel:()=>rG,Lfm2ForCausalLM:()=>oh,Lfm2Model:()=>o_,Lfm2PreTrainedModel:()=>op,LiteWhisperForConditionalGeneration:()=>rs,Llama4ForCausalLM:()=>oi,Llama4PreTrainedModel:()=>oa,LlamaForCausalLM:()=>os,LlamaModel:()=>oo,LlamaPreTrainedModel:()=>or,LlavaForConditionalGeneration:()=>rd,LlavaOnevisionForConditionalGeneration:()=>ru,LlavaPreTrainedModel:()=>rc,LlavaQwen2ForCausalLM:()=>rf,LongT5ForConditionalGeneration:()=>tk,LongT5Model:()=>tF,LongT5PreTrainedModel:()=>tb,M2M100ForConditionalGeneration:()=>iA,M2M100Model:()=>iE,M2M100PreTrainedModel:()=>iS,MBartForCausalLM:()=>tV,MBartForConditionalGeneration:()=>tz,MBartForSequenceClassification:()=>tj,MBartModel:()=>tD,MBartPreTrainedModel:()=>tI,MPNetForMaskedLM:()=>ti,MPNetForQuestionAnswering:()=>tc,MPNetForSequenceClassification:()=>tn,MPNetForTokenClassification:()=>tl,MPNetModel:()=>ta,MPNetPreTrainedModel:()=>ts,MT5ForConditionalGeneration:()=>tC,MT5Model:()=>tv,MT5PreTrainedModel:()=>ty,MarianMTModel:()=>iC,MarianModel:()=>iv,MarianPreTrainedModel:()=>iy,MaskFormerForInstanceSegmentation:()=>aK,MaskFormerModel:()=>aY,MaskFormerPreTrainedModel:()=>aJ,MaskedLMOutput:()=>cU,Metric3DForDepthEstimation:()=>aQ,Metric3DPreTrainedModel:()=>aU,Metric3Dv2ForDepthEstimation:()=>aH,Metric3Dv2PreTrainedModel:()=>aX,MgpstrForSceneTextRecognition:()=>ld,MgpstrModelOutput:()=>ll,MgpstrPreTrainedModel:()=>lc,MimiDecoderModel:()=>lk,MimiDecoderOutput:()=>lx,MimiEncoderModel:()=>lF,MimiEncoderOutput:()=>lP,MimiModel:()=>lb,MimiPreTrainedModel:()=>lT,Ministral3ForCausalLM:()=>nx,Ministral3Model:()=>nP,Ministral3PreTrainedModel:()=>nT,MinistralForCausalLM:()=>nw,MinistralModel:()=>nM,MinistralPreTrainedModel:()=>nf,Mistral3ForConditionalGeneration:()=>rM,MistralForCausalLM:()=>ng,MistralModel:()=>nh,MistralPreTrainedModel:()=>n_,MobileBertForMaskedLM:()=>tt,MobileBertForQuestionAnswering:()=>to,MobileBertForSequenceClassification:()=>tr,MobileBertModel:()=>te,MobileBertPreTrainedModel:()=>e7,MobileLLMForCausalLM:()=>oE,MobileLLMModel:()=>oS,MobileLLMPreTrainedModel:()=>oC,MobileNetV1ForImageClassification:()=>n0,MobileNetV1ForSemanticSegmentation:()=>n1,MobileNetV1Model:()=>nZ,MobileNetV1PreTrainedModel:()=>nK,MobileNetV2ForImageClassification:()=>n4,MobileNetV2ForSemanticSegmentation:()=>n5,MobileNetV2Model:()=>n3,MobileNetV2PreTrainedModel:()=>n2,MobileNetV3ForImageClassification:()=>n9,MobileNetV3ForSemanticSegmentation:()=>n7,MobileNetV3Model:()=>n6,MobileNetV3PreTrainedModel:()=>n8,MobileNetV4ForImageClassification:()=>lr,MobileNetV4ForSemanticSegmentation:()=>lo,MobileNetV4Model:()=>lt,MobileNetV4PreTrainedModel:()=>le,MobileViTForImageClassification:()=>sW,MobileViTModel:()=>s$,MobileViTPreTrainedModel:()=>sq,MobileViTV2ForImageClassification:()=>sX,MobileViTV2Model:()=>sQ,MobileViTV2PreTrainedModel:()=>sU,ModelOutput:()=>U,ModernBertDecoderForCausalLM:()=>ep,ModernBertDecoderModel:()=>em,ModernBertDecoderPreTrainedModel:()=>eu,ModernBertForMaskedLM:()=>el,ModernBertForSequenceClassification:()=>ec,ModernBertForTokenClassification:()=>ed,ModernBertModel:()=>en,ModernBertPreTrainedModel:()=>ei,Moondream1ForConditionalGeneration:()=>rm,MoonshineForConditionalGeneration:()=>rn,MoonshineModel:()=>ri,MoonshinePreTrainedModel:()=>ra,MptForCausalLM:()=>sg,MptModel:()=>sh,MptPreTrainedModel:()=>s_,MultiModalityCausalLM:()=>ln,MultiModalityPreTrainedModel:()=>li,MusicgenForCausalLM:()=>nJ,MusicgenForConditionalGeneration:()=>nY,MusicgenModel:()=>nH,MusicgenPreTrainedModel:()=>nX,NanoChatForCausalLM:()=>oc,NanoChatModel:()=>ol,NanoChatPreTrainedModel:()=>on,NeoBertForMaskedLM:()=>er,NeoBertForQuestionAnswering:()=>ea,NeoBertForSequenceClassification:()=>eo,NeoBertForTokenClassification:()=>es,NeoBertModel:()=>et,NeoBertPreTrainedModel:()=>ee,NomicBertModel:()=>eh,NomicBertPreTrainedModel:()=>e_,OPTForCausalLM:()=>sw,OPTModel:()=>sM,OPTPreTrainedModel:()=>sf,Olmo2ForCausalLM:()=>oj,Olmo2Model:()=>oz,Olmo2PreTrainedModel:()=>oD,OlmoForCausalLM:()=>oI,OlmoModel:()=>oL,OlmoPreTrainedModel:()=>oA,OpenELMForCausalLM:()=>o8,OpenELMModel:()=>o5,OpenELMPreTrainedModel:()=>o4,OwlViTForObjectDetection:()=>sY,OwlViTModel:()=>sJ,OwlViTPreTrainedModel:()=>sH,Owlv2ForObjectDetection:()=>s0,Owlv2Model:()=>sZ,Owlv2PreTrainedModel:()=>sK,PaliGemmaForConditionalGeneration:()=>rg,PaliGemmaPreTrainedModel:()=>rh,ParakeetForCTC:()=>iO,ParakeetPreTrainedModel:()=>iV,PatchTSMixerForPrediction:()=>lg,PatchTSMixerModel:()=>lh,PatchTSMixerPreTrainedModel:()=>l_,PatchTSTForPrediction:()=>lp,PatchTSTModel:()=>lm,PatchTSTPreTrainedModel:()=>lu,Phi3ForCausalLM:()=>sd,Phi3Model:()=>sc,Phi3PreTrainedModel:()=>sl,Phi3VForCausalLM:()=>rk,Phi3VPreTrainedModel:()=>rF,PhiForCausalLM:()=>sn,PhiModel:()=>si,PhiPreTrainedModel:()=>sa,PreTrainedModel:()=>W,PretrainedMixin:()=>lj,PvtForImageClassification:()=>sE,PvtModel:()=>sS,PvtPreTrainedModel:()=>sC,PyAnnoteForAudioFrameClassification:()=>iG,PyAnnoteModel:()=>iB,PyAnnotePreTrainedModel:()=>iN,QuestionAnsweringModelOutput:()=>cQ,Qwen2ForCausalLM:()=>o7,Qwen2Model:()=>o9,Qwen2PreTrainedModel:()=>o6,Qwen2VLForConditionalGeneration:()=>ss,Qwen2VLPreTrainedModel:()=>so,Qwen3ForCausalLM:()=>sr,Qwen3Model:()=>st,Qwen3PreTrainedModel:()=>se,RFDetrForObjectDetection:()=>ad,RFDetrModel:()=>ac,RFDetrObjectDetectionOutput:()=>au,RFDetrPreTrainedModel:()=>al,RTDetrForObjectDetection:()=>ar,RTDetrModel:()=>at,RTDetrObjectDetectionOutput:()=>ao,RTDetrPreTrainedModel:()=>ae,RTDetrV2ForObjectDetection:()=>ai,RTDetrV2Model:()=>aa,RTDetrV2ObjectDetectionOutput:()=>an,RTDetrV2PreTrainedModel:()=>as,ResNetForImageClassification:()=>av,ResNetModel:()=>ay,ResNetPreTrainedModel:()=>ak,RoFormerForMaskedLM:()=>eM,RoFormerForQuestionAnswering:()=>eP,RoFormerForSequenceClassification:()=>ew,RoFormerForTokenClassification:()=>eT,RoFormerModel:()=>ef,RoFormerPreTrainedModel:()=>eg,RobertaForMaskedLM:()=>tU,RobertaForQuestionAnswering:()=>tH,RobertaForSequenceClassification:()=>tQ,RobertaForTokenClassification:()=>tX,RobertaModel:()=>tW,RobertaPreTrainedModel:()=>t$,Sam2ImageSegmentationOutput:()=>iP,Sam2Model:()=>ib,Sam2PreTrainedModel:()=>ix,Sam3TrackerModel:()=>ik,SamImageSegmentationOutput:()=>iT,SamModel:()=>iw,SamPreTrainedModel:()=>iM,SapiensForDepthEstimation:()=>aR,SapiensForNormalEstimation:()=>aq,SapiensForSemanticSegmentation:()=>aG,SapiensPreTrainedModel:()=>aB,SegformerForImageClassification:()=>nB,SegformerForSemanticSegmentation:()=>nG,SegformerModel:()=>nN,SegformerPreTrainedModel:()=>nO,Seq2SeqLMOutput:()=>cR,SequenceClassifierOutput:()=>cq,SiglipModel:()=>rI,SiglipPreTrainedModel:()=>rL,SiglipTextModel:()=>rD,SiglipVisionModel:()=>rz,SmolLM3ForCausalLM:()=>oM,SmolLM3Model:()=>of,SmolLM3PreTrainedModel:()=>og,SmolVLMForConditionalGeneration:()=>rb,SnacDecoderModel:()=>lz,SnacEncoderModel:()=>lD,SnacModel:()=>lI,SnacPreTrainedModel:()=>lL,SpeechT5ForSpeechToText:()=>nn,SpeechT5ForTextToSpeech:()=>nl,SpeechT5HifiGan:()=>nc,SpeechT5Model:()=>ni,SpeechT5PreTrainedModel:()=>na,SqueezeBertForMaskedLM:()=>tm,SqueezeBertForQuestionAnswering:()=>t_,SqueezeBertForSequenceClassification:()=>tp,SqueezeBertModel:()=>tu,SqueezeBertPreTrainedModel:()=>td,StableLmForCausalLM:()=>n$,StableLmModel:()=>nq,StableLmPreTrainedModel:()=>nR,Starcoder2ForCausalLM:()=>nC,Starcoder2Model:()=>nv,Starcoder2PreTrainedModel:()=>ny,StyleTextToSpeech2Model:()=>ns,StyleTextToSpeech2PreTrainedModel:()=>no,SupertonicForConditionalGeneration:()=>nu,SupertonicPreTrainedModel:()=>nd,Swin2SRForImageSuperResolution:()=>aD,Swin2SRModel:()=>aI,Swin2SRPreTrainedModel:()=>aL,SwinForImageClassification:()=>aE,SwinForSemanticSegmentation:()=>aA,SwinModel:()=>aS,SwinPreTrainedModel:()=>aC,T5ForConditionalGeneration:()=>tx,T5Model:()=>tP,T5PreTrainedModel:()=>tT,TableTransformerForObjectDetection:()=>af,TableTransformerModel:()=>ag,TableTransformerObjectDetectionOutput:()=>aM,TableTransformerPreTrainedModel:()=>ah,TokenClassifierOutput:()=>cW,TrOCRForCausalLM:()=>np,TrOCRPreTrainedModel:()=>nm,UltravoxModel:()=>lM,UltravoxPreTrainedModel:()=>lf,UniSpeechForCTC:()=>iU,UniSpeechForSequenceClassification:()=>iQ,UniSpeechModel:()=>iW,UniSpeechPreTrainedModel:()=>i$,UniSpeechSatForAudioFrameClassification:()=>iK,UniSpeechSatForCTC:()=>iJ,UniSpeechSatForSequenceClassification:()=>iY,UniSpeechSatModel:()=>iH,UniSpeechSatPreTrainedModel:()=>iX,VaultGemmaForCausalLM:()=>o0,VaultGemmaModel:()=>oZ,VaultGemmaPreTrainedModel:()=>oK,ViTForImageClassification:()=>sx,ViTMAEModel:()=>sL,ViTMAEPreTrainedModel:()=>sA,ViTMSNForImageClassification:()=>sz,ViTMSNModel:()=>sD,ViTMSNPreTrainedModel:()=>sI,ViTModel:()=>sP,ViTPreTrainedModel:()=>sT,VisionEncoderDecoderModel:()=>rl,VitMatteForImageMatting:()=>sR,VitMattePreTrainedModel:()=>sG,VitPoseForPoseEstimation:()=>sv,VitPosePreTrainedModel:()=>sy,VitsModel:()=>nV,VitsModelOutput:()=>cY,VitsPreTrainedModel:()=>nj,VoxtralForConditionalGeneration:()=>lw,Wav2Vec2BertForCTC:()=>i1,Wav2Vec2BertForSequenceClassification:()=>i2,Wav2Vec2BertModel:()=>i0,Wav2Vec2BertPreTrainedModel:()=>iZ,Wav2Vec2ForAudioFrameClassification:()=>ij,Wav2Vec2ForCTC:()=>iD,Wav2Vec2ForSequenceClassification:()=>iz,Wav2Vec2Model:()=>iI,Wav2Vec2PreTrainedModel:()=>iL,WavLMForAudioFrameClassification:()=>nr,WavLMForCTC:()=>i7,WavLMForSequenceClassification:()=>ne,WavLMForXVector:()=>nt,WavLMModel:()=>i9,WavLMPreTrainedModel:()=>i6,WeSpeakerResNetModel:()=>iq,WeSpeakerResNetPreTrainedModel:()=>iR,WhisperForConditionalGeneration:()=>ro,WhisperModel:()=>rr,WhisperPreTrainedModel:()=>rt,XLMForQuestionAnswering:()=>t1,XLMForSequenceClassification:()=>tZ,XLMForTokenClassification:()=>t0,XLMModel:()=>tY,XLMPreTrainedModel:()=>tJ,XLMRobertaForMaskedLM:()=>t4,XLMRobertaForQuestionAnswering:()=>t6,XLMRobertaForSequenceClassification:()=>t5,XLMRobertaForTokenClassification:()=>t8,XLMRobertaModel:()=>t3,XLMRobertaPreTrainedModel:()=>t2,XLMWithLMHeadModel:()=>tK,XVectorOutput:()=>c$,YolosForObjectDetection:()=>ih,YolosModel:()=>i_,YolosObjectDetectionOutput:()=>ig,YolosPreTrainedModel:()=>ip});var o=r("./src/configs.js"),s=r("./src/backends/onnx.js"),a=r("./src/utils/dtypes.js"),i=r("./src/utils/generic.js"),n=r("./src/utils/core.js"),l=r("./src/utils/hub.js"),c=r("./src/utils/constants.js"),d=r("./src/generation/logits_process.js"),u=r("./src/generation/configuration_utils.js"),m=r("./src/utils/tensor.js"),p=r("./src/utils/image.js"),_=r("./src/utils/maths.js"),h=r("./src/generation/stopping_criteria.js"),g=r("./src/generation/logits_sampler.js"),f=r("./src/env.js"),M=r("./src/models/whisper/generation_whisper.js"),w=r("./src/models/whisper/common_whisper.js");let T={EncoderOnly:0,EncoderDecoder:1,Seq2Seq:2,Vision2Seq:3,DecoderOnly:4,MaskGeneration:5,ImageTextToText:6,Musicgen:7,MultiModality:8,Phi3V:9,AudioTextToText:10,AutoEncoder:11,ImageAudioTextToText:12,Supertonic:13},P=new Map,x=new Map,b=new Map;async function F(e,t,r){let i=r.config?.["transformers.js_config"]??{},n=r.device??i.device;n&&"string"!=typeof n&&(n.hasOwnProperty(t)?n=n[t]:(console.warn(`device not specified for "${t}". Using the default device.`),n=null));let c=n??(f.apis.IS_NODE_ENV?"cpu":"wasm"),d=(0,s.deviceToExecutionProviders)(c),u=i.device_config??{};u.hasOwnProperty(c)&&(i={...i,...u[c]});let m=r.dtype??i.dtype;if("string"!=typeof m&&(m&&m.hasOwnProperty(t)?m=m[t]:(m=a.DEFAULT_DEVICE_DTYPE_MAPPING[c]??a.DATA_TYPES.fp32,console.warn(`dtype not specified for "${t}". Using the default dtype (${m}) for this device (${c}).`))),m===a.DATA_TYPES.auto){let e=i.dtype;"string"!=typeof e&&(e=e?.[t]),m=e&&e!==a.DATA_TYPES.auto&&a.DATA_TYPES.hasOwnProperty(e)?e:a.DEFAULT_DEVICE_DTYPE_MAPPING[c]??a.DATA_TYPES.fp32}let p=m;if(a.DEFAULT_DTYPE_SUFFIX_MAPPING.hasOwnProperty(p)){if(p===a.DATA_TYPES.fp16&&"webgpu"===c&&!await (0,a.isWebGpuFp16Supported)())throw Error(`The device (${c}) does not support fp16.`)}else throw Error(`Invalid dtype: ${p}. Should be one of: ${Object.keys(a.DATA_TYPES).join(", ")}`);let _=i.kv_cache_dtype,h=_?"string"==typeof _?_:_[p]??"float32":void 0;if(h&&!["float32","float16"].includes(h))throw Error(`Invalid kv_cache_dtype: ${h}. Should be one of: float32, float16`);let g=a.DEFAULT_DTYPE_SUFFIX_MAPPING[p],M=`${t}${g}.onnx`,w=`${r.subfolder??""}/${M}`,T={...r.session_options};T.executionProviders??=d;let P=i.free_dimension_overrides;P?T.freeDimensionOverrides??=P:c.startsWith("webnn")&&!T.freeDimensionOverrides&&console.warn(`WebNN does not currently support dynamic shapes and requires 'free_dimension_overrides' to be set in config.json, preferably as a field within config["transformers.js_config"]["device_config"]["${c}"]. When 'free_dimension_overrides' is not set, you may experience significant performance degradation.`);let x=f.apis.IS_NODE_ENV&&f.env.useFSCache,b=(0,l.getModelFile)(e,w,!0,r,x),F=r.use_external_data_format??i.use_external_data_format,k=[];if(F){let o;let s=+("object"==typeof F?F.hasOwnProperty(M)?F[M]:!!F.hasOwnProperty(t)&&F[t]:F);if(s>l.MAX_EXTERNAL_DATA_CHUNKS)throw Error(`The number of external data chunks (${s}) exceeds the maximum allowed value (${l.MAX_EXTERNAL_DATA_CHUNKS}).`);for(let t=0;t<s;++t){let o=`${M}_data${0===t?"":"_"+t}`,s=`${r.subfolder??""}/${o}`;k.push(new Promise(async(t,a)=>{let i=await (0,l.getModelFile)(e,s,!0,r,x);t(i instanceof Uint8Array?{path:o,data:i}:o)}))}}else void 0!==T.externalData&&(k=T.externalData.map(async t=>{if("string"==typeof t.data){let o=await (0,l.getModelFile)(e,t.data,!0,r);return{...t,data:o}}return t}));if(k.length>0){let e=await Promise.all(k);f.apis.IS_NODE_ENV||(T.externalData=e)}if("webgpu"===c){let e=(0,o.getCacheShapes)(r.config,{prefix:"present"});if(Object.keys(e).length>0&&!(0,s.isONNXProxy)()){let t={};for(let r in e)t[r]="gpu-buffer";T.preferredOutputLocation=t}}return{buffer_or_path:await b,session_options:T,session_config:{dtype:p,kv_cache_dtype:h,device:c}}}async function k(e,t,r){return Object.fromEntries(await Promise.all(Object.keys(t).map(async o=>{let{buffer_or_path:a,session_options:i,session_config:n}=await F(e,t[o],r);return[o,await (0,s.createInferenceSession)(a,i,n)]})))}async function y(e,t,r){return Object.fromEntries(await Promise.all(Object.keys(t).map(async o=>{let s=await (0,l.getModelJSON)(e,t[o],!1,r);return[o,s]})))}async function v(e,t){let r=function(e,t){let r=Object.create(null),o=[];for(let a of e.inputNames){let e=t[a];if(!(e instanceof m.Tensor)){o.push(a);continue}r[a]=(0,s.isONNXProxy)()?e.clone():e}if(o.length>0)throw Error(`An error occurred during model execution: "Missing the following inputs: ${o.join(", ")}.`);let a=Object.keys(t).length,i=e.inputNames.length;if(a>i){let r=Object.keys(t).filter(t=>!e.inputNames.includes(t));console.warn(`WARNING: Too many inputs were provided (${a} > ${i}). The following inputs will be ignored: "${r.join(", ")}".`)}return r}(e,t);try{let t=Object.fromEntries(Object.entries(r).map(([e,t])=>[e,t.ort_tensor])),o=await (0,s.runInferenceSession)(e,t);return function e(t){for(let r in t)(0,s.isONNXTensor)(t[r])?t[r]=new m.Tensor(t[r]):"object"==typeof t[r]&&e(t[r]);return t}(o)}catch(t){let e=Object.fromEntries(Object.entries(r).map(([e,t])=>{let r={type:t.type,dims:t.dims,location:t.location};return"gpu-buffer"!==r.location&&(r.data=t.data),[e,r]}));throw console.error(`An error occurred during model execution: "${t}".`),console.error("Inputs given to model:",e),t}}function C(e){if(e instanceof m.Tensor)return e;if(0===e.length)throw Error("items must be non-empty");if(!Array.isArray(e[0]))return new m.Tensor("int64",BigInt64Array.from(e.map(e=>BigInt(e))),[1,e.length]);if(e.some(t=>t.length!==e[0].length))throw Error("Unable to create tensor, you should probably activate truncation and/or padding with 'padding=True' and/or 'truncation=True' to have batched tensors with the same length.");return new m.Tensor("int64",BigInt64Array.from(e.flat().map(e=>BigInt(e))),[e.length,e[0].length])}function S(e){return new m.Tensor("bool",[e],[1])}async function E(e,t){let{encoder_outputs:r,input_ids:o,decoder_input_ids:s,...a}=t;if(!r){let o=(0,n.pick)(t,e.sessions.model.inputNames);r=(await A(e,o)).last_hidden_state}return a.input_ids=s,a.encoder_hidden_states=r,e.sessions.decoder_model_merged.inputNames.includes("encoder_attention_mask")&&(a.encoder_attention_mask=t.attention_mask),await I(e,a,!0)}async function A(e,t){let r=e.sessions.model,o=(0,n.pick)(t,r.inputNames);if(r.inputNames.includes("inputs_embeds")&&!o.inputs_embeds){if(!t.input_ids)throw Error("Both `input_ids` and `inputs_embeds` are missing in the model inputs.");o.inputs_embeds=await e.encode_text({input_ids:t.input_ids})}if(r.inputNames.includes("token_type_ids")&&!o.token_type_ids){if(!o.input_ids)throw Error("Both `input_ids` and `token_type_ids` are missing in the model inputs.");o.token_type_ids=(0,m.zeros_like)(o.input_ids)}if(r.inputNames.includes("pixel_mask")&&!o.pixel_mask){if(!o.pixel_values)throw Error("Both `pixel_values` and `pixel_mask` are missing in the model inputs.");let e=o.pixel_values.dims;o.pixel_mask=(0,m.ones)([e[0],e[2],e[3]])}return await v(r,o)}async function L(e,t){let r=await e.encode(t);return await e.decode(r)}async function I(e,t,r=!1){let o=e.sessions[r?"decoder_model_merged":"model"],{past_key_values:s,...a}=t;o.inputNames.includes("use_cache_branch")&&(a.use_cache_branch=S(!!s)),o.inputNames.includes("position_ids")&&a.attention_mask&&!a.position_ids&&(a.position_ids=function(e,t=null,r=0){let{input_ids:o,inputs_embeds:s,attention_mask:a}=e,{data:i,dims:n}=B(a,r),l=new m.Tensor("int64",i,n);if(t){let e=-(o??s).dims.at(1);l=l.slice(null,[e,null])}return l}(a,s,+!!["paligemma","gemma3_text","gemma3"].includes(e.config.model_type))),e.addPastKeyValues(a,s);let i=(0,n.pick)(a,o.inputNames);return await v(o,i)}function D({modality_token_id:e,inputs_embeds:t,modality_features:r,input_ids:o,attention_mask:s}){let a=o.tolist().map(t=>t.reduce((t,r,o)=>(r==e&&t.push(o),t),[])),i=a.reduce((e,t)=>e+t.length,0),n=r.dims[0];if(i!==n)throw Error(`Number of tokens and features do not match: tokens: ${i}, features ${n}`);let l=0;for(let e=0;e<a.length;++e){let o=a[e],s=t[e];for(let e=0;e<o.length;++e)s[o[e]].data.set(r[l++].data)}return{inputs_embeds:t,attention_mask:s}}function z({image_token_id:e,inputs_embeds:t,image_features:r,input_ids:o,attention_mask:s}){return D({modality_token_id:e,inputs_embeds:t,modality_features:r,input_ids:o,attention_mask:s})}function j({audio_token_id:e,inputs_embeds:t,audio_features:r,input_ids:o,attention_mask:s}){return D({modality_token_id:e,inputs_embeds:t,modality_features:r,input_ids:o,attention_mask:s})}async function V(e,{encode_function:t,merge_function:r,modality_input_name:o,modality_output_name:s,input_ids:a=null,attention_mask:i=null,position_ids:n=null,inputs_embeds:l=null,past_key_values:c=null,generation_config:d=null,logits_processor:u=null,...p}){let _=p[o];if(!l){if(l=await e.encode_text({input_ids:a,...p}),_&&1!==a.dims[1]){let e=await t({[o]:_,...p});({inputs_embeds:l,attention_mask:i}=r({[s]:e,inputs_embeds:l,input_ids:a,attention_mask:i}))}else if(c&&_&&1===a.dims[1]){let e=a.dims[1],t=Object.values(c)[0].dims.at(-2);i=(0,m.cat)([(0,m.ones)([a.dims[0],t]),i.slice(null,[i.dims[1]-e,i.dims[1]])],1)}}if(!n&&"qwen2_vl"===e.config.model_type){let{image_grid_thw:t,video_grid_thw:r}=p;[n]=e.get_rope_index(a,t,r,i)}return await I(e,{inputs_embeds:l,past_key_values:c,attention_mask:i,position_ids:n,generation_config:d,logits_processor:u},!0)}async function O(e,t){return await V(e,{...t,modality_input_name:"audio_values",modality_output_name:"audio_features",encode_function:e.encode_audio.bind(e),merge_function:e._merge_input_ids_with_audio_features.bind(e)})}async function N(e,t){return await V(e,{...t,modality_input_name:"pixel_values",modality_output_name:"image_features",encode_function:e.encode_image.bind(e),merge_function:e._merge_input_ids_with_image_features.bind(e)})}function B(e,t=0){let[r,o]=e.dims,s=e.data,a=new BigInt64Array(s.length);for(let e=0;e<r;++e){let r=e*o,i=BigInt(t);for(let e=0;e<o;++e){let t=r+e;0n===s[t]?a[t]=BigInt(1):(a[t]=i,i+=s[t])}}return{data:a,dims:e.dims}}function G(e,t,r,o){let s=r.past_key_values?Object.values(r.past_key_values)[0].dims.at(-2):0;if(!r.attention_mask){let e;for(let t of["input_ids","inputs_embeds","position_ids"])if(r[t]){e=r[t].dims;break}if(!e)throw Error("attention_mask is not provided, and unable to infer its shape from model inputs.");r.attention_mask=(0,m.ones)([e[0],s+e[1]])}if(r.past_key_values){let{input_ids:e,attention_mask:t}=r;t&&t.dims[1]>e.dims[1]||s<e.dims[1]&&(r.input_ids=e.slice(null,[s,null]))}return r}function R(e,t,r,o){return r.past_key_values&&(t=t.map(e=>[e.at(-1)])),{...r,decoder_input_ids:C(t)}}function q(e,...t){return e.config.is_encoder_decoder?R(e,...t):G(e,...t)}function $(e,t,r,o){let s=!!r.past_key_values;return null!==o.guidance_scale&&o.guidance_scale>1&&(s?r.input_ids=(0,m.cat)([r.input_ids,r.input_ids],0):(r.input_ids=(0,m.cat)([r.input_ids,(0,m.full_like)(r.input_ids,BigInt(o.pad_token_id))],0),r.attention_mask=(0,m.cat)([r.attention_mask,(0,m.full_like)(r.attention_mask,0n)],0))),(s||!r.pixel_values)&&(r.pixel_values=(0,m.full)([0,0,3,384,384],1)),s&&(r.images_seq_mask=new m.Tensor("bool",[,].fill(!0).fill(!1,0,1),[1,1]),r.images_emb_mask=new m.Tensor("bool",[].fill(!1),[1,1,0])),r}class W extends i.Callable{main_input_name="input_ids";forward_params=["input_ids","attention_mask"];constructor(e,t,r){super(),this.config=e,this.sessions=t,this.configs=r;let o=b.get(this.constructor),s=P.get(o);switch(this.can_generate=!1,this._forward=null,this._prepare_inputs_for_generation=null,s){case T.DecoderOnly:this.can_generate=!0,this._forward=I,this._prepare_inputs_for_generation=G;break;case T.Seq2Seq:case T.Vision2Seq:case T.Musicgen:this.can_generate=!0,this._forward=E,this._prepare_inputs_for_generation=R;break;case T.EncoderDecoder:this._forward=E;break;case T.ImageTextToText:this.can_generate=!0,this._forward=N,this._prepare_inputs_for_generation=q;break;case T.AudioTextToText:this.can_generate=!0,this._forward=O,this._prepare_inputs_for_generation=q;break;case T.Phi3V:case T.ImageAudioTextToText:this.can_generate=!0,this._prepare_inputs_for_generation=q;break;case T.MultiModality:this.can_generate=!0,this._prepare_inputs_for_generation=$;break;case T.AutoEncoder:this._forward=L;break;default:this._forward=A}this.can_generate&&this.forward_params.push("past_key_values"),this.custom_config=this.config["transformers.js_config"]??{}}async dispose(){let e=[];for(let t of Object.values(this.sessions))t?.handler?.dispose&&e.push(t.handler.dispose());return await Promise.all(e)}static async from_pretrained(e,{progress_callback:t=null,config:r=null,cache_dir:s=null,local_files_only:a=!1,revision:i="main",model_file_name:n=null,subfolder:l="onnx",device:d=null,dtype:u=null,use_external_data_format:m=null,session_options:p={}}={}){let _,h={progress_callback:t,config:r,cache_dir:s,local_files_only:a,revision:i,model_file_name:n,subfolder:l,device:d,dtype:u,use_external_data_format:m,session_options:p},g=b.get(this),f=P.get(g);if(r=h.config=await o.AutoConfig.from_pretrained(e,h),f===T.DecoderOnly)_=await Promise.all([k(e,{model:h.model_file_name??"model"},h),y(e,{generation_config:"generation_config.json"},h)]);else if(f===T.Seq2Seq||f===T.Vision2Seq)_=await Promise.all([k(e,{model:"encoder_model",decoder_model_merged:"decoder_model_merged"},h),y(e,{generation_config:"generation_config.json"},h)]);else if(f===T.MaskGeneration)_=await Promise.all([k(e,{model:"vision_encoder",prompt_encoder_mask_decoder:"prompt_encoder_mask_decoder"},h)]);else if(f===T.EncoderDecoder)_=await Promise.all([k(e,{model:"encoder_model",decoder_model_merged:"decoder_model_merged"},h)]);else if(f===T.ImageTextToText){let t={embed_tokens:"embed_tokens",vision_encoder:"vision_encoder",decoder_model_merged:"decoder_model_merged"};r.is_encoder_decoder&&(t.model="encoder_model"),_=await Promise.all([k(e,t,h),y(e,{generation_config:"generation_config.json"},h)])}else if(f===T.AudioTextToText)_=await Promise.all([k(e,{embed_tokens:"embed_tokens",audio_encoder:"audio_encoder",decoder_model_merged:"decoder_model_merged"},h),y(e,{generation_config:"generation_config.json"},h)]);else if(f===T.ImageAudioTextToText)_=await Promise.all([k(e,{embed_tokens:"embed_tokens",audio_encoder:"audio_encoder",vision_encoder:"vision_encoder",decoder_model_merged:"decoder_model_merged"},h),y(e,{generation_config:"generation_config.json"},h)]);else if(f===T.Musicgen)_=await Promise.all([k(e,{model:"text_encoder",decoder_model_merged:"decoder_model_merged",encodec_decode:"encodec_decode"},h),y(e,{generation_config:"generation_config.json"},h)]);else if(f===T.MultiModality)_=await Promise.all([k(e,{prepare_inputs_embeds:"prepare_inputs_embeds",model:"language_model",lm_head:"lm_head",gen_head:"gen_head",gen_img_embeds:"gen_img_embeds",image_decode:"image_decode"},h),y(e,{generation_config:"generation_config.json"},h)]);else if(f===T.Phi3V)_=await Promise.all([k(e,{prepare_inputs_embeds:"prepare_inputs_embeds",model:"model",vision_encoder:"vision_encoder"},h),y(e,{generation_config:"generation_config.json"},h)]);else if(f===T.AutoEncoder)_=await Promise.all([k(e,{encoder_model:"encoder_model",decoder_model:"decoder_model"},h)]);else if(f===T.Supertonic)_=await Promise.all([k(e,{text_encoder:"text_encoder",latent_denoiser:"latent_denoiser",voice_decoder:"voice_decoder"},h)]);else{if(f!==T.EncoderOnly){let e=g??r?.model_type;"custom"!==e&&console.warn(`Model type for '${e}' not found, assuming encoder-only architecture. Please report this at ${c.GITHUB_ISSUE_URL}.`)}_=await Promise.all([k(e,{model:h.model_file_name??"model"},h)])}return new this(r,..._)}async _call(e){return await this.forward(e)}async forward(e){return await this._forward(this,e)}get generation_config(){return this.configs?.generation_config??null}_get_logits_processor(e,t,r=null){let o=new d.LogitsProcessorList;if(null!==e.repetition_penalty&&1!==e.repetition_penalty&&o.push(new d.RepetitionPenaltyLogitsProcessor(e.repetition_penalty)),null!==e.no_repeat_ngram_size&&e.no_repeat_ngram_size>0&&o.push(new d.NoRepeatNGramLogitsProcessor(e.no_repeat_ngram_size)),null!==e.bad_words_ids&&o.push(new d.NoBadWordsLogitsProcessor(e.bad_words_ids,e.eos_token_id)),null!==e.min_length&&null!==e.eos_token_id&&e.min_length>0&&o.push(new d.MinLengthLogitsProcessor(e.min_length,e.eos_token_id)),null!==e.min_new_tokens&&null!==e.eos_token_id&&e.min_new_tokens>0&&o.push(new d.MinNewTokensLengthLogitsProcessor(t,e.min_new_tokens,e.eos_token_id)),null!==e.forced_bos_token_id&&o.push(new d.ForcedBOSTokenLogitsProcessor(e.forced_bos_token_id)),null!==e.forced_eos_token_id&&o.push(new d.ForcedEOSTokenLogitsProcessor(e.max_length,e.forced_eos_token_id)),null!==e.begin_suppress_tokens){let r=t>1||null===e.forced_bos_token_id?t:t+1;o.push(new d.SuppressTokensAtBeginLogitsProcessor(e.begin_suppress_tokens,r))}return null!==e.guidance_scale&&e.guidance_scale>1&&o.push(new d.ClassifierFreeGuidanceLogitsProcessor(e.guidance_scale)),0===e.temperature&&e.do_sample&&(console.warn("`do_sample` changed to false because `temperature: 0` implies greedy sampling (always selecting the most likely token), which is incompatible with `do_sample: true`."),e.do_sample=!1),e.do_sample&&null!==e.temperature&&1!==e.temperature&&o.push(new d.TemperatureLogitsWarper(e.temperature)),null!==r&&o.extend(r),o}_prepare_generation_config(e,t,r=u.GenerationConfig){let o={...this.config};for(let e of["decoder","generator","text_config"])e in o&&Object.assign(o,o[e]);let s=new r(o);return Object.assign(s,this.generation_config??{}),e&&Object.assign(s,e),t&&Object.assign(s,(0,n.pick)(t,Object.getOwnPropertyNames(s))),s}_get_stopping_criteria(e,t=null){let r=new h.StoppingCriteriaList;return null!==e.max_length&&r.push(new h.MaxLengthCriteria(e.max_length,this.config.max_position_embeddings??null)),null!==e.eos_token_id&&r.push(new h.EosTokenCriteria(e.eos_token_id)),t&&r.extend(t),r}_validate_model_class(){if(!this.can_generate){let e=b.get(this.constructor),t=new Set,r=this.config.model_type;for(let e of[lQ,lY,lU,lG]){let o=e.get(r);o&&t.add(o[0])}let o=`The current model class (${e}) is not compatible with \`.generate()\`, as it doesn't have a language model head.`;throw t.size>0&&(o+=` Please use the following class instead: ${[...t].join(", ")}`),Error(o)}}prepare_inputs_for_generation(...e){return this._prepare_inputs_for_generation(this,...e)}_update_model_kwargs_for_generation({generated_input_ids:e,outputs:t,model_inputs:r,is_encoder_decoder:o}){return r.past_key_values=this.getPastKeyValues(t,r.past_key_values),r.input_ids=new m.Tensor("int64",e.flat(),[e.length,1]),o||(r.attention_mask=(0,m.cat)([r.attention_mask,(0,m.ones)([r.attention_mask.dims[0],1])],1)),r.position_ids=null,r}_prepare_model_inputs({inputs:e,bos_token_id:t,model_kwargs:r}){let o=(0,n.pick)(r,this.forward_params),s=this.main_input_name;if(s in o){if(e)throw Error("`inputs`: {inputs}` were passed alongside {input_name} which is not allowed. Make sure to either pass {inputs} or {input_name}=...")}else o[s]=e;return{inputs_tensor:o[s],model_inputs:o,model_input_name:s}}async _prepare_encoder_decoder_kwargs_for_generation({inputs_tensor:e,model_inputs:t,model_input_name:r,generation_config:o}){if(this.sessions.model.inputNames.includes("inputs_embeds")&&!t.inputs_embeds&&"_prepare_inputs_embeds"in this){let{input_ids:e,pixel_values:r,attention_mask:o,...s}=t,a=await this._prepare_inputs_embeds(t);t={...s,...(0,n.pick)(a,["inputs_embeds","attention_mask"])}}let{last_hidden_state:s}=await A(this,t);if(null!==o.guidance_scale&&o.guidance_scale>1)s=(0,m.cat)([s,(0,m.full_like)(s,0)],0),"attention_mask"in t&&(t.attention_mask=(0,m.cat)([t.attention_mask,(0,m.zeros_like)(t.attention_mask)],0));else if(t.decoder_input_ids){let e=C(t.decoder_input_ids).dims[0];if(e!==s.dims[0]){if(1!==s.dims[0])throw Error(`The encoder outputs have a different batch size (${s.dims[0]}) than the decoder inputs (${e}).`);s=(0,m.cat)(Array.from({length:e},()=>s),0)}}return t.encoder_outputs=s,t}_prepare_decoder_input_ids_for_generation({batch_size:e,model_input_name:t,model_kwargs:r,decoder_start_token_id:o,bos_token_id:s,generation_config:a}){let{decoder_input_ids:i,...n}=r;if(!(i instanceof m.Tensor)){if(i)Array.isArray(i[0])||(i=Array.from({length:e},()=>i));else if(o??=s,"musicgen"===this.config.model_type)i=Array.from({length:e*this.config.decoder.num_codebooks},()=>[o]);else if(Array.isArray(o)){if(o.length!==e)throw Error(`\`decoder_start_token_id\` expcted to have length ${e} but got ${o.length}`);i=o}else i=Array.from({length:e},()=>[o]);i=C(i)}return r.decoder_attention_mask=(0,m.ones_like)(i),{input_ids:i,model_inputs:n}}async generate({inputs:e=null,generation_config:t=null,logits_processor:r=null,stopping_criteria:o=null,streamer:s=null,...a}){let i,n;this._validate_model_class(),t=this._prepare_generation_config(t,a);let{inputs_tensor:l,model_inputs:c,model_input_name:d}=this._prepare_model_inputs({inputs:e,model_kwargs:a}),u=this.config.is_encoder_decoder;u&&("encoder_outputs"in c||(c=await this._prepare_encoder_decoder_kwargs_for_generation({inputs_tensor:l,model_inputs:c,model_input_name:d,generation_config:t}))),u?{input_ids:i,model_inputs:c}=this._prepare_decoder_input_ids_for_generation({batch_size:c[d].dims.at(0),model_input_name:d,model_kwargs:c,decoder_start_token_id:t.decoder_start_token_id,bos_token_id:t.bos_token_id,generation_config:t}):i=c[d];let p=i.dims.at(-1);null!==t.max_new_tokens&&(t.max_length=p+t.max_new_tokens);let _=this._get_logits_processor(t,p,r),h=this._get_stopping_criteria(t,o),f=c[d].dims.at(0),M=g.LogitsSampler.getSampler(t),w=Array(f).fill(0),T=i.tolist();s&&s.put(T);let P={};for(;;){if(c=this.prepare_inputs_for_generation(T,c,t),n=await this.forward(c),t.output_attentions&&t.return_dict_in_generate){let e=this.getAttentions(n);for(let t in e)t in P||(P[t]=[]),P[t].push(e[t])}let e=_(T,n.logits.slice(null,-1,null)),r=[];for(let t=0;t<e.dims.at(0);++t){let o=e[t];for(let[e,s]of(await M(o))){let o=BigInt(e);w[t]+=s,T[t].push(o),r.push([o]);break}}if(s&&s.put(r),h(T).every(e=>e))break;c=this._update_model_kwargs_for_generation({generated_input_ids:r,outputs:n,model_inputs:c,is_encoder_decoder:u})}s&&s.end();let x=this.getPastKeyValues(n,c.past_key_values,!0),b=new m.Tensor("int64",T.flat(),[T.length,T[0].length]);if(t.return_dict_in_generate)return{sequences:b,past_key_values:x,...P};for(let e of Object.values(n))"gpu-buffer"===e.location&&e.dispose();return b}getPastKeyValues(e,t,r=!1){let o=Object.create(null);for(let s in e)if(s.startsWith("present")){let a=s.replace("present_conv","past_conv").replace("present","past_key_values"),i=s.includes("encoder");if(i&&t?o[a]=t[a]:o[a]=e[s],t&&(!i||r)){let e=t[a];"gpu-buffer"===e.location&&e.dispose()}}return o}getAttentions(e){let t={};for(let r of["cross_attentions","encoder_attentions","decoder_attentions"])for(let o in e)o.startsWith(r)&&(r in t||(t[r]=[]),t[r].push(e[o]));return t}addPastKeyValues(e,t){if(t)Object.assign(e,t);else{let t=this.sessions.decoder_model_merged??this.sessions.model,r=(e[this.main_input_name]??e.attention_mask)?.dims?.[0]??1,s=t?.config?.kv_cache_dtype??"float32",a="float16"===s?m.DataTypeMap.float16:m.DataTypeMap.float32,i=(0,o.getCacheShapes)(this.config,{batch_size:r});for(let t in i){let r=i[t].reduce((e,t)=>e*t,1);e[t]=new m.Tensor(s,new a(r),i[t])}}}async encode_image({pixel_values:e}){return(await v(this.sessions.vision_encoder,{pixel_values:e})).image_features}async encode_text({input_ids:e}){return(await v(this.sessions.embed_tokens,{input_ids:e})).inputs_embeds}async encode_audio({audio_values:e}){return(await v(this.sessions.audio_encoder,{audio_values:e})).audio_features}}class U{}class Q extends U{constructor({last_hidden_state:e,hidden_states:t=null,attentions:r=null}){super(),this.last_hidden_state=e,this.hidden_states=t,this.attentions=r}}class X extends W{}class H extends X{}class J extends X{async _call(e){return new cU(await super._call(e))}}class Y extends X{async _call(e){return new cq(await super._call(e))}}class K extends X{async _call(e){return new cW(await super._call(e))}}class Z extends X{async _call(e){return new cQ(await super._call(e))}}class ee extends W{}class et extends ee{}class er extends ee{async _call(e){return new cU(await super._call(e))}}class eo extends ee{async _call(e){return new cq(await super._call(e))}}class es extends ee{async _call(e){return new cW(await super._call(e))}}class ea extends ee{async _call(e){return new cQ(await super._call(e))}}class ei extends W{}class en extends ei{}class el extends ei{async _call(e){return new cU(await super._call(e))}}class ec extends ei{async _call(e){return new cq(await super._call(e))}}class ed extends ei{async _call(e){return new cW(await super._call(e))}}class eu extends W{}class em extends eu{}class ep extends eu{}class e_ extends W{}class eh extends e_{}class eg extends W{}class ef extends eg{}class eM extends eg{async _call(e){return new cU(await super._call(e))}}class ew extends eg{async _call(e){return new cq(await super._call(e))}}class eT extends eg{async _call(e){return new cW(await super._call(e))}}class eP extends eg{async _call(e){return new cQ(await super._call(e))}}class ex extends W{}class eb extends ex{}class eF extends ex{async _call(e){return new cU(await super._call(e))}}class ek extends ex{async _call(e){return new cq(await super._call(e))}}class ey extends ex{async _call(e){return new cW(await super._call(e))}}class ev extends ex{async _call(e){return new cQ(await super._call(e))}}class eC extends W{}class eS extends eC{}class eE extends eC{async _call(e){return new cU(await super._call(e))}}class eA extends eC{async _call(e){return new cq(await super._call(e))}}class eL extends eC{async _call(e){return new cW(await super._call(e))}}class eI extends eC{async _call(e){return new cQ(await super._call(e))}}class eD extends W{}class ez extends eD{}class ej extends eD{async _call(e){return new cU(await super._call(e))}}class eV extends eD{async _call(e){return new cq(await super._call(e))}}class eO extends eD{async _call(e){return new cW(await super._call(e))}}class eN extends eD{async _call(e){return new cQ(await super._call(e))}}class eB extends W{}class eG extends eB{}class eR extends eB{async _call(e){return new cU(await super._call(e))}}class eq extends eB{async _call(e){return new cq(await super._call(e))}}class e$ extends eB{async _call(e){return new cW(await super._call(e))}}class eW extends eB{async _call(e){return new cQ(await super._call(e))}}class eU extends W{}class eQ extends eU{}class eX extends eU{async _call(e){return new cU(await super._call(e))}}class eH extends eU{async _call(e){return new cq(await super._call(e))}}class eJ extends eU{async _call(e){return new cW(await super._call(e))}}class eY extends eU{async _call(e){return new cQ(await super._call(e))}}class eK extends W{}class eZ extends eK{}class e0 extends eK{async _call(e){return new cq(await super._call(e))}}class e1 extends eK{async _call(e){return new cW(await super._call(e))}}class e2 extends eK{async _call(e){return new cQ(await super._call(e))}}class e3 extends eK{async _call(e){return new cU(await super._call(e))}}class e4 extends W{}class e5 extends e4{}class e8 extends e4{async _call(e){return new cU(await super._call(e))}}class e6 extends e4{async _call(e){return new cq(await super._call(e))}}class e9 extends e4{async _call(e){return new cW(await super._call(e))}}class e7 extends W{}class te extends e7{}class tt extends e7{async _call(e){return new cU(await super._call(e))}}class tr extends e7{async _call(e){return new cq(await super._call(e))}}class to extends e7{async _call(e){return new cQ(await super._call(e))}}class ts extends W{}class ta extends ts{}class ti extends ts{async _call(e){return new cU(await super._call(e))}}class tn extends ts{async _call(e){return new cq(await super._call(e))}}class tl extends ts{async _call(e){return new cW(await super._call(e))}}class tc extends ts{async _call(e){return new cQ(await super._call(e))}}class td extends W{}class tu extends td{}class tm extends td{async _call(e){return new cU(await super._call(e))}}class tp extends td{async _call(e){return new cq(await super._call(e))}}class t_ extends td{async _call(e){return new cQ(await super._call(e))}}class th extends W{}class tg extends th{}class tf extends th{async _call(e){return new cq(await super._call(e))}}class tM extends th{async _call(e){return new cQ(await super._call(e))}}class tw extends th{async _call(e){return new cU(await super._call(e))}}class tT extends W{forward_params=["input_ids","attention_mask","encoder_outputs","decoder_input_ids","decoder_attention_mask","past_key_values"]}class tP extends tT{}class tx extends tT{}class tb extends W{}class tF extends tb{}class tk extends tb{}class ty extends W{}class tv extends ty{}class tC extends ty{}class tS extends W{}class tE extends tS{}class tA extends tS{}class tL extends tS{async _call(e){return new cq(await super._call(e))}}class tI extends W{}class tD extends tI{}class tz extends tI{}class tj extends tI{async _call(e){return new cq(await super._call(e))}}class tV extends tI{}class tO extends W{}class tN extends tO{}class tB extends tO{}class tG extends W{}class tR extends tG{}class tq extends tG{}class t$ extends W{}class tW extends t${}class tU extends t${async _call(e){return new cU(await super._call(e))}}class tQ extends t${async _call(e){return new cq(await super._call(e))}}class tX extends t${async _call(e){return new cW(await super._call(e))}}class tH extends t${async _call(e){return new cQ(await super._call(e))}}class tJ extends W{}class tY extends tJ{}class tK extends tJ{async _call(e){return new cU(await super._call(e))}}class tZ extends tJ{async _call(e){return new cq(await super._call(e))}}class t0 extends tJ{async _call(e){return new cW(await super._call(e))}}class t1 extends tJ{async _call(e){return new cQ(await super._call(e))}}class t2 extends W{}class t3 extends t2{}class t4 extends t2{async _call(e){return new cU(await super._call(e))}}class t5 extends t2{async _call(e){return new cq(await super._call(e))}}class t8 extends t2{async _call(e){return new cW(await super._call(e))}}class t6 extends t2{async _call(e){return new cQ(await super._call(e))}}class t9 extends W{}class t7 extends t9{}class re extends t9{}class rt extends W{requires_attention_mask=!1;main_input_name="input_features";forward_params=["input_features","attention_mask","decoder_input_ids","decoder_attention_mask","past_key_values"]}class rr extends rt{}class ro extends rt{_prepare_generation_config(e,t){return super._prepare_generation_config(e,t,M.WhisperGenerationConfig)}_retrieve_init_tokens(e){let t=[e.decoder_start_token_id],r=e.language,o=e.task;if(e.is_multilingual){r||(console.warn("No language specified - defaulting to English (en)."),r="en");let s=(0,w.whisper_language_to_code)(r),a=`<|${s}|>`;t.push(e.lang_to_id[a]),t.push(e.task_to_id[o??"transcribe"])}else if(r||o)throw Error("Cannot specify `task` or `language` for an English-only model. If the model is intended to be multilingual, pass `is_multilingual=true` to generate, or update the generation config.");return!e.return_timestamps&&e.no_timestamps_token_id&&t.at(-1)!==e.no_timestamps_token_id?t.push(e.no_timestamps_token_id):e.return_timestamps&&t.at(-1)===e.no_timestamps_token_id&&(console.warn("<|notimestamps|> prompt token is removed from generation_config since `return_timestamps` is set to `true`."),t.pop()),t.filter(e=>null!=e)}async generate({inputs:e=null,generation_config:t=null,logits_processor:r=null,stopping_criteria:o=null,...s}){t=this._prepare_generation_config(t,s);let a=s.decoder_input_ids??this._retrieve_init_tokens(t);if(t.return_timestamps&&(r??=new d.LogitsProcessorList).push(new d.WhisperTimeStampLogitsProcessor(t,a)),t.begin_suppress_tokens&&(r??=new d.LogitsProcessorList).push(new d.SuppressTokensAtBeginLogitsProcessor(t.begin_suppress_tokens,a.length)),t.return_token_timestamps){if(!t.alignment_heads)throw Error("Model generation config has no `alignment_heads`, token-level timestamps not available. See https://gist.github.com/hollance/42e32852f24243b748ae6bc1f985b13a on how to add this property to the generation config.");"translate"===t.task&&console.warn("Token-level timestamps may not be reliable for task 'translate'."),t.output_attentions=!0,t.return_dict_in_generate=!0}let i=await super.generate({inputs:e,generation_config:t,logits_processor:r,decoder_input_ids:a,...s});return t.return_token_timestamps&&(i.token_timestamps=this._extract_token_timestamps(i,t.alignment_heads,t.num_frames)),i}_extract_token_timestamps(e,t,r=null,o=.02){if(!e.cross_attentions)throw Error("Model outputs must contain cross attentions to extract timestamps. This is most likely because the model was not exported with `output_attentions=True`.");null==r&&console.warn("`num_frames` has not been set, meaning the entire audio will be analyzed. This may lead to inaccurate token-level timestamps for short audios (< 30 seconds).");let s=this.config.median_filter_width;void 0===s&&(console.warn("Model config has no `median_filter_width`, using default value of 7."),s=7);let a=e.cross_attentions,i=Array.from({length:this.config.decoder_layers},(e,t)=>(0,m.cat)(a.map(e=>e[t]),2)),l=(0,m.stack)(t.map(([e,t])=>{if(e>=i.length)throw Error(`Layer index ${e} is out of bounds for cross attentions (length ${i.length}).`);return r?i[e].slice(null,t,null,[0,r]):i[e].slice(null,t)})).transpose(1,0,2,3),[c,d]=(0,m.std_mean)(l,-2,0,!0),u=l.clone();for(let e=0;e<u.dims[0];++e){let t=u[e];for(let r=0;r<t.dims[0];++r){let o=t[r],a=c[e][r][0].data,i=d[e][r][0].data;for(let e=0;e<o.dims[0];++e){let t=o[e].data;for(let e=0;e<t.length;++e)t[e]=(t[e]-i[e])/a[e];t.set((0,_.medianFilter)(t,s))}}}let p=[(0,m.mean)(u,1)],h=e.sequences.dims,g=new m.Tensor("float32",new Float32Array(h[0]*h[1]),h);for(let e=0;e<h[0];++e){let t=p[e].neg().squeeze_(0),[r,s]=(0,_.dynamic_time_warping)(t.tolist()),a=Array.from({length:r.length-1},(e,t)=>r[t+1]-r[t]),i=(0,n.mergeArrays)([1],a).map(e=>!!e),l=[];for(let e=0;e<i.length;++e)i[e]&&l.push(s[e]*o);g[e].data.set(l,1)}return g}}class rs extends ro{}class ra extends W{requires_attention_mask=!1;main_input_name="input_values";forward_params=["input_values","decoder_input_ids","past_key_values"]}class ri extends ra{}class rn extends ra{}class rl extends W{main_input_name="pixel_values";forward_params=["pixel_values","decoder_input_ids","encoder_hidden_states","past_key_values"]}class rc extends W{forward_params=["input_ids","attention_mask","pixel_values","position_ids","past_key_values"]}class rd extends rc{_merge_input_ids_with_image_features(e){let t=e.image_features.dims.at(-1),r=e.image_features.view(-1,t);return z({image_token_id:this.config.image_token_index,...e,image_features:r})}}class ru extends rd{}class rm extends rd{}class rp extends W{forward_params=["input_ids","inputs_embeds","attention_mask","pixel_values","encoder_outputs","decoder_input_ids","decoder_inputs_embeds","decoder_attention_mask","past_key_values"];main_input_name="inputs_embeds"}class r_ extends rp{_merge_input_ids_with_image_features({inputs_embeds:e,image_features:t,input_ids:r,attention_mask:o}){return{inputs_embeds:(0,m.cat)([t,e],1),attention_mask:(0,m.cat)([(0,m.ones)(t.dims.slice(0,2)),o],1)}}async _prepare_inputs_embeds({input_ids:e,pixel_values:t,inputs_embeds:r,attention_mask:o}){let s,a;if(!e&&!t)throw Error("Either `input_ids` or `pixel_values` should be provided.");return e&&(s=await this.encode_text({input_ids:e})),t&&(a=await this.encode_image({pixel_values:t})),s&&a?{inputs_embeds:r,attention_mask:o}=this._merge_input_ids_with_image_features({inputs_embeds:s,image_features:a,input_ids:e,attention_mask:o}):r=s||a,{inputs_embeds:r,attention_mask:o}}async forward({input_ids:e,pixel_values:t,attention_mask:r,decoder_input_ids:o,decoder_attention_mask:s,encoder_outputs:a,past_key_values:i,inputs_embeds:n,decoder_inputs_embeds:l}){if(n||({inputs_embeds:n,attention_mask:r}=await this._prepare_inputs_embeds({input_ids:e,pixel_values:t,inputs_embeds:n,attention_mask:r})),!a){let{last_hidden_state:e}=await A(this,{inputs_embeds:n,attention_mask:r});a=e}if(!l){if(!o)throw Error("Either `decoder_input_ids` or `decoder_inputs_embeds` should be provided.");l=await this.encode_text({input_ids:o})}let c={inputs_embeds:l,attention_mask:s,encoder_attention_mask:r,encoder_hidden_states:a,past_key_values:i};return await I(this,c,!0)}}class rh extends W{forward_params=["input_ids","attention_mask","pixel_values","position_ids","past_key_values"]}class rg extends rh{_merge_input_ids_with_image_features(e){let t=e.image_features.dims.at(-1),r=e.image_features.view(-1,t);return z({image_token_id:this.config.image_token_index,...e,image_features:r})}}class rf extends rc{_merge_input_ids_with_image_features(e){let t=e.image_features.dims.at(-1),r=e.image_features.view(-1,t);return z({image_token_id:this.config.image_token_index,...e,image_features:r})}}class rM extends rf{}class rw extends W{forward_params=["input_ids","attention_mask","inputs_embeds","per_layer_inputs","position_ids","pixel_values","input_features","input_features_mask","past_key_values"]}class rT extends rw{async forward({input_ids:e=null,attention_mask:t=null,pixel_values:r=null,input_features:o=null,input_features_mask:s=null,position_ids:a=null,inputs_embeds:i=null,per_layer_inputs:n=null,past_key_values:l=null,generation_config:c=null,logits_processor:d=null,...u}){if((!i||!n)&&({inputs_embeds:i,per_layer_inputs:n}=await v(this.sessions.embed_tokens,{input_ids:e}),1!==e.dims[1])){if(r){let{image_features:o}=await v(this.sessions.vision_encoder,{pixel_values:r});({inputs_embeds:i,attention_mask:t}=this._merge_input_ids_with_image_features({image_features:o,inputs_embeds:i,input_ids:e,attention_mask:t}))}if(o){let{audio_features:r}=await v(this.sessions.audio_encoder,{input_features:o,input_features_mask:s});({inputs_embeds:i,attention_mask:t}=this._merge_input_ids_with_audio_features({audio_features:r,inputs_embeds:i,input_ids:e,attention_mask:t}))}}return await I(this,{inputs_embeds:i,per_layer_inputs:n,past_key_values:l,attention_mask:t,position_ids:a,generation_config:c,logits_processor:d},!0)}_merge_input_ids_with_image_features(e){let t=e.image_features.dims.at(-1),r=e.image_features.view(-1,t);return z({image_token_id:this.config.image_token_id,...e,image_features:r})}_merge_input_ids_with_audio_features(e){let t=e.audio_features.dims.at(-1),r=e.audio_features.view(-1,t);return j({audio_token_id:this.config.audio_token_id,...e,audio_features:r})}}class rP extends W{forward_params=["input_ids","attention_mask","pixel_values","pixel_attention_mask","position_ids","past_key_values"]}class rx extends rP{async encode_image({pixel_values:e,pixel_attention_mask:t}){return(await v(this.sessions.vision_encoder,{pixel_values:e,pixel_attention_mask:t})).image_features}_merge_input_ids_with_image_features(e){let t=e.image_features.dims.at(-1),r=e.image_features.view(-1,t);return z({image_token_id:this.config.image_token_id,...e,image_features:r})}}class rb extends rx{}class rF extends W{forward_params=["input_ids","inputs_embeds","attention_mask","position_ids","pixel_values","image_sizes","past_key_values"]}class rk extends rF{async forward({input_ids:e=null,attention_mask:t=null,pixel_values:r=null,image_sizes:o=null,position_ids:s=null,inputs_embeds:a=null,past_key_values:i=null,generation_config:n=null,logits_processor:l=null,...c}){if(!a){let t;if(r&&1!==e.dims[1]){if(!o)throw Error("`image_sizes` must be provided when `pixel_values` is provided.");({image_features:t}=await v(this.sessions.vision_encoder,{pixel_values:r,image_sizes:o}))}else{let e=this.config.normalized_config.hidden_size;t=new m.Tensor("float32",[],[0,e])}({inputs_embeds:a}=await v(this.sessions.prepare_inputs_embeds,{input_ids:e,image_features:t}))}return await I(this,{inputs_embeds:a,past_key_values:i,attention_mask:t,position_ids:s,generation_config:n,logits_processor:l},!1)}}class ry extends W{}class rv extends ry{}class rC extends ry{static async from_pretrained(e,t={}){return super.from_pretrained(e,{...t,model_file_name:t.model_file_name??"text_model"})}}class rS extends ry{static async from_pretrained(e,t={}){return super.from_pretrained(e,{...t,model_file_name:t.model_file_name??"text_model"})}}class rE extends ry{static async from_pretrained(e,t={}){return super.from_pretrained(e,{...t,model_file_name:t.model_file_name??"vision_model"})}}class rA extends ry{static async from_pretrained(e,t={}){return super.from_pretrained(e,{...t,model_file_name:t.model_file_name??"vision_model"})}}class rL extends W{}class rI extends rL{}class rD extends rL{static async from_pretrained(e,t={}){return super.from_pretrained(e,{...t,model_file_name:t.model_file_name??"text_model"})}}class rz extends ry{static async from_pretrained(e,t={}){return super.from_pretrained(e,{...t,model_file_name:t.model_file_name??"vision_model"})}}class rj extends W{}class rV extends rj{}class rO extends W{}class rN extends rO{async forward(e){let t=!e.input_ids,r=!e.pixel_values;if(t&&r)throw Error("Either `input_ids` or `pixel_values` should be provided.");if(t&&(e.input_ids=(0,m.ones)([e.pixel_values.dims[0],1])),r){let{image_size:t}=this.config.vision_config;e.pixel_values=(0,m.full)([0,3,t,t],0)}let{text_embeddings:o,image_embeddings:s,l2norm_text_embeddings:a,l2norm_image_embeddings:i}=await super.forward(e),n={};return t||(n.text_embeddings=o,n.l2norm_text_embeddings=a),r||(n.image_embeddings=s,n.l2norm_image_embeddings=i),n}}class rB extends rO{static async from_pretrained(e,t={}){return super.from_pretrained(e,{...t,model_file_name:t.model_file_name??"text_model"})}}class rG extends rO{static async from_pretrained(e,t={}){return super.from_pretrained(e,{...t,model_file_name:t.model_file_name??"vision_model"})}}class rR extends W{}class rq extends rR{}class r$ extends rR{}class rW extends W{}class rU extends rW{}class rQ extends rW{}class rX extends W{}class rH extends rX{}class rJ extends rX{}class rY extends W{}class rK extends rY{}class rZ extends rY{}class r0 extends W{}class r1 extends r0{}class r2 extends r0{}class r3 extends W{}class r4 extends r3{}class r5 extends r3{}class r8 extends W{}class r6 extends r8{}class r9 extends r8{}class r7 extends W{}class oe extends r7{}class ot extends r7{}class or extends W{}class oo extends or{}class os extends or{}class oa extends W{}class oi extends oa{}class on extends W{}class ol extends on{}class oc extends on{}class od extends W{}class ou extends od{}class om extends od{}class op extends W{}class o_ extends op{}class oh extends op{}class og extends W{}class of extends og{}class oM extends og{}class ow extends W{}class oT extends ow{}class oP extends ow{}class ox extends W{}class ob extends ox{}class oF extends ox{}class ok extends W{}class oy extends ok{}class ov extends ok{}class oC extends W{}class oS extends oC{}class oE extends oC{}class oA extends W{}class oL extends oA{}class oI extends oA{}class oD extends W{}class oz extends oD{}class oj extends oD{}class oV extends W{}class oO extends oV{}class oN extends oV{}class oB extends W{}class oG extends oB{}class oR extends oB{}class oq extends W{}class o$ extends oq{}class oW extends oq{}class oU extends W{}class oQ extends oU{}class oX extends oU{}class oH extends W{}class oJ extends oH{}class oY extends oH{}class oK extends W{}class oZ extends oK{}class o0 extends oK{}class o1 extends W{}class o2 extends o1{}class o3 extends o1{}class o4 extends W{}class o5 extends o4{}class o8 extends o4{}class o6 extends W{}class o9 extends o6{}class o7 extends o6{}class se extends W{}class st extends se{}class sr extends se{}class so extends W{forward_params=["input_ids","attention_mask","position_ids","past_key_values","pixel_values","image_grid_thw"]}class ss extends so{get_rope_index(e,t,r,o){let{vision_config:s,image_token_id:a,video_token_id:i,vision_start_token_id:n}=this.config,l=s.spatial_merge_size??2,c=[];if(t||r){let s=e.tolist();o||(o=(0,m.ones_like)(e));let d=o.tolist(),u=Array.from({length:3},t=>Array.from({length:e.dims[0]},t=>Array.from({length:e.dims[1]},e=>1))),p=t?t.tolist():[],h=r?r.tolist():[],g=0,f=0;for(let e=0;e<s.length;++e){let t=s[e].filter((t,r)=>1==d[e][r]),r=t.reduce((e,t,r)=>(t==n&&e.push(r),e),[]).map(e=>t[e+1]),o=r.filter(e=>e==a).length,m=r.filter(e=>e==i).length,M=[],w=0,T=o,P=m;for(let e=0;e<r.length;++e){let e,r,o,s;let n=t.findIndex((e,t)=>t>w&&e==a),c=t.findIndex((e,t)=>t>w&&e==i),d=T>0&&-1!==n?n:t.length+1,u=P>0&&-1!==c?c:t.length+1;d<u?([r,o,s]=p[g],++g,--T,e=d):([r,o,s]=h[f],++f,--P,e=u);let[m,x,b]=[Number(r),Math.floor(Number(o)/l),Math.floor(Number(s)/l)],F=e-w,k=M.length>0?(0,_.max)(M.at(-1))[0]+1:0;M.push(Array.from({length:3*F},(e,t)=>k+t%F));let y=F+k,v=m*x*b,C=Array.from({length:v},(e,t)=>y+Math.floor(t/(x*b))),S=Array.from({length:v},(e,t)=>y+Math.floor(t/b)%x),E=Array.from({length:v},(e,t)=>y+t%b);M.push([C,S,E].flat()),w=e+v}if(w<t.length){let e=M.length>0?(0,_.max)(M.at(-1))[0]+1:0,r=t.length-w;M.push(Array.from({length:3*r},(t,o)=>e+o%r))}let x=M.reduce((e,t)=>e+t.length,0),b=Array(x),F=0;for(let e=0;e<3;++e)for(let t=0;t<M.length;++t){let r=M[t],o=r.length/3;for(let t=e*o;t<(e+1)*o;++t)b[F++]=r[t]}let k=0,y=d[e];for(let t=0;t<y.length;++t)if(1==y[t]){for(let r=0;r<3;++r)u[r][e][t]=b[r*x/3+k];++k}let v=(0,_.max)(b)[0];c.push(v+1-s[e].length)}return[new m.Tensor("int64",u.flat(1/0),[3,e.dims[0],e.dims[1]]),new m.Tensor("int64",c,[c.length,1])]}if(o){let{data:e,dims:t}=B(o),r=BigInt64Array.from({length:3*e.length},(t,r)=>e[r%e.length]),s=Array.from({length:t[0]},(r,o)=>(0,_.max)(e.subarray(t[1]*o,t[1]*(o+1)))[0]+1n+BigInt(t[1]));return[new m.Tensor("int64",r,[3,...t]),new m.Tensor("int64",s,[s.length,1])]}{let[t,r]=e.dims,o=BigInt64Array.from({length:3*t*r},(e,o)=>BigInt(Math.floor(o%r/t)));return[new m.Tensor("int64",o,[3,...e.dims]),(0,m.zeros)([t,1])]}}async encode_image({pixel_values:e,image_grid_thw:t}){return(await v(this.sessions.vision_encoder,{pixel_values:e,grid_thw:t})).image_features}_merge_input_ids_with_image_features(e){return z({image_token_id:this.config.image_token_id,...e})}prepare_inputs_for_generation(e,t,r){if(t.attention_mask&&!t.position_ids){if(t.past_key_values){t.pixel_values=null;let e=BigInt(Object.values(t.past_key_values)[0].dims.at(-2)),r=t.rope_deltas.map(t=>e+t);t.position_ids=(0,m.stack)([r,r,r],0)}else[t.position_ids,t.rope_deltas]=this.get_rope_index(t.input_ids,t.image_grid_thw,t.video_grid_thw,t.attention_mask)}return t}}class sa extends W{}class si extends sa{}class sn extends sa{}class sl extends W{}class sc extends sl{}class sd extends sl{}class su extends W{}class sm extends su{}class sp extends su{}class s_ extends W{}class sh extends s_{}class sg extends s_{}class sf extends W{}class sM extends sf{}class sw extends sf{}class sT extends W{}class sP extends sT{}class sx extends sT{async _call(e){return new cq(await super._call(e))}}class sb extends W{}class sF extends sb{}class sk extends sb{async _call(e){return new cq(await super._call(e))}}class sy extends W{}class sv extends sy{}class sC extends W{}class sS extends sC{}class sE extends sC{async _call(e){return new cq(await super._call(e))}}class sA extends W{}class sL extends sA{}class sI extends W{}class sD extends sI{}class sz extends sI{async _call(e){return new cq(await super._call(e))}}class sj extends W{}class sV extends sj{}class sO extends W{}class sN extends sO{}class sB extends sO{async _call(e){return new cq(await super._call(e))}}class sG extends W{}class sR extends sG{async _call(e){return new cJ(await super._call(e))}}class sq extends W{}class s$ extends sq{}class sW extends sq{async _call(e){return new cq(await super._call(e))}}class sU extends W{}class sQ extends sU{}class sX extends sU{async _call(e){return new cq(await super._call(e))}}class sH extends W{}class sJ extends sH{}class sY extends sH{}class sK extends W{}class sZ extends sK{}class s0 extends sK{}class s1 extends W{}class s2 extends s1{}class s3 extends s1{async _call(e){return new cq(await super._call(e))}}class s4 extends W{}class s5 extends s4{}class s8 extends s4{async _call(e){return new s9(await super._call(e))}}class s6 extends s4{async _call(e){return new s7(await super._call(e))}}class s9 extends U{constructor({logits:e,pred_boxes:t}){super(),this.logits=e,this.pred_boxes=t}}class s7 extends U{constructor({logits:e,pred_boxes:t,pred_masks:r}){super(),this.logits=e,this.pred_boxes=t,this.pred_masks=r}}class ae extends W{}class at extends ae{}class ar extends ae{async _call(e){return new ao(await super._call(e))}}class ao extends U{constructor({logits:e,pred_boxes:t}){super(),this.logits=e,this.pred_boxes=t}}class as extends W{}class aa extends as{}class ai extends as{async _call(e){return new an(await super._call(e))}}class an extends ao{}class al extends W{}class ac extends al{}class ad extends al{async _call(e){return new au(await super._call(e))}}class au extends ao{}class am extends W{}class ap extends am{}class a_ extends am{async _call(e){return new ao(await super._call(e))}}class ah extends W{}class ag extends ah{}class af extends ah{async _call(e){return new aM(await super._call(e))}}class aM extends s9{}class aw extends W{}class aT extends aw{}class aP extends aw{async _call(e){return new cq(await super._call(e))}}class ax extends W{}class ab extends ax{}class aF extends ax{async _call(e){return new cq(await super._call(e))}}class ak extends W{}class ay extends ak{}class av extends ak{async _call(e){return new cq(await super._call(e))}}class aC extends W{}class aS extends aC{}class aE extends aC{async _call(e){return new cq(await super._call(e))}}class aA extends aC{}class aL extends W{}class aI extends aL{}class aD extends aL{}class az extends W{}class aj extends az{}class aV extends az{}class aO extends W{}class aN extends aO{}class aB extends W{}class aG extends aB{}class aR extends aB{}class aq extends aB{}class a$ extends W{}class aW extends a${}class aU extends W{}class aQ extends aU{}class aX extends W{}class aH extends aX{}class aJ extends W{}class aY extends aJ{}class aK extends aJ{}class aZ extends W{}class a0 extends aZ{}class a1 extends aZ{}class a2 extends W{}class a3 extends a2{}class a4 extends W{}class a5 extends a4{}class a8 extends a4{async _call(e){return new cq(await super._call(e))}}class a6 extends W{}class a9 extends a6{}class a7 extends a6{async _call(e){return new cq(await super._call(e))}}class ie extends W{}class it extends ie{}class ir extends ie{async _call(e){return new cq(await super._call(e))}}class io extends W{}class is extends io{}class ia extends io{async _call(e){return new cq(await super._call(e))}}class ii extends W{}class il extends ii{}class ic extends W{}class id extends ic{}class iu extends W{}class im extends iu{}class ip extends W{}class i_ extends ip{}class ih extends ip{async _call(e){return new ig(await super._call(e))}}class ig extends U{constructor({logits:e,pred_boxes:t}){super(),this.logits=e,this.pred_boxes=t}}class iM extends W{}class iw extends iM{async get_image_embeddings({pixel_values:e}){return await A(this,{pixel_values:e})}async forward(e){e=e.image_embeddings&&e.image_positional_embeddings?{...e}:{...e,...await this.get_image_embeddings(e)},e.input_labels??=(0,m.ones)(e.input_points.dims.slice(0,-1));let t={image_embeddings:e.image_embeddings,image_positional_embeddings:e.image_positional_embeddings};return e.input_points&&(t.input_points=e.input_points),e.input_labels&&(t.input_labels=e.input_labels),e.input_boxes&&(t.input_boxes=e.input_boxes),await v(this.sessions.prompt_encoder_mask_decoder,t)}async _call(e){return new iT(await super._call(e))}}class iT extends U{constructor({iou_scores:e,pred_masks:t}){super(),this.iou_scores=e,this.pred_masks=t}}class iP extends U{constructor({iou_scores:e,pred_masks:t,object_score_logits:r}){super(),this.iou_scores=e,this.pred_masks=t,this.object_score_logits=r}}class ix extends W{}class ib extends ix{async get_image_embeddings({pixel_values:e}){return await A(this,{pixel_values:e})}async forward(e){let{num_feature_levels:t}=this.config.vision_config;if((e=Array.from({length:t},(e,t)=>`image_embeddings.${t}`).some(t=>!e[t])?{...e,...await this.get_image_embeddings(e)}:{...e}).input_points){if(e.input_boxes&&1!==e.input_boxes.dims[1])throw Error("When both `input_points` and `input_boxes` are provided, the number of boxes per image must be 1.");let t=e.input_points.dims;e.input_labels??=(0,m.ones)(t.slice(0,-1)),e.input_boxes??=(0,m.full)([t[0],0,4],0)}else if(e.input_boxes){let t=e.input_boxes.dims;e.input_labels=(0,m.full)([t[0],t[1],0],-1n),e.input_points=(0,m.full)([t[0],1,0,2],0)}else throw Error("At least one of `input_points` or `input_boxes` must be provided.");let r=this.sessions.prompt_encoder_mask_decoder,o=(0,n.pick)(e,r.inputNames);return await v(r,o)}async _call(e){return new iP(await super._call(e))}}class iF extends ib{}class ik extends ib{}class iy extends W{}class iv extends iy{}class iC extends iy{}class iS extends W{}class iE extends iS{}class iA extends iS{}class iL extends W{}class iI extends iL{}class iD extends iL{async _call(e){return new cX(await super._call(e))}}class iz extends iL{async _call(e){return new cq(await super._call(e))}}class ij extends iL{async _call(e){return new cW(await super._call(e))}}class iV extends W{}class iO extends iV{async _call(e){return new cX(await super._call(e))}}class iN extends W{}class iB extends iN{}class iG extends iN{async _call(e){return new cW(await super._call(e))}}class iR extends W{}class iq extends iR{}class i$ extends W{}class iW extends i${}class iU extends i${async _call(e){return new cX(await super._call(e))}}class iQ extends i${async _call(e){return new cq(await super._call(e))}}class iX extends W{}class iH extends iX{}class iJ extends iX{async _call(e){return new cX(await super._call(e))}}class iY extends iX{async _call(e){return new cq(await super._call(e))}}class iK extends iX{async _call(e){return new cW(await super._call(e))}}class iZ extends W{}class i0 extends iZ{}class i1 extends iZ{async _call(e){return new cX(await super._call(e))}}class i2 extends iZ{async _call(e){return new cq(await super._call(e))}}class i3 extends W{}class i4 extends iL{}class i5 extends iL{async _call(e){return new cX(await super._call(e))}}class i8 extends iL{async _call(e){return new cq(await super._call(e))}}class i6 extends W{}class i9 extends i6{}class i7 extends i6{async _call(e){return new cX(await super._call(e))}}class ne extends i6{async _call(e){return new cq(await super._call(e))}}class nt extends i6{async _call(e){return new c$(await super._call(e))}}class nr extends i6{async _call(e){return new cW(await super._call(e))}}class no extends W{}class ns extends no{}class na extends W{}class ni extends na{}class nn extends na{}class nl extends na{async generate_speech(e,t,{threshold:r=.5,minlenratio:o=0,maxlenratio:s=20,vocoder:a=null}={}){let{encoder_outputs:i,encoder_attention_mask:n}=await A(this,{input_ids:e}),l=i.dims[1]/this.config.reduction_factor,c=Math.floor(l*s),d=Math.floor(l*o),u=this.config.num_mel_bins,p=[],_=null,h=null,g=0;for(;;){let e;++g;let o={use_cache_branch:S(!!h),output_sequence:h?h.output_sequence_out:new m.Tensor("float32",new Float32Array(u),[1,1,u]),encoder_attention_mask:n,speaker_embeddings:t,encoder_hidden_states:i};this.addPastKeyValues(o,_),h=await v(this.sessions.decoder_model_merged,o),_=this.getPastKeyValues(h,_);let{prob:s,spectrum:a}=h;if(p.push(a),g>=d&&(Array.from(s.data).filter(e=>e>=r).length>0||g>=c))break}let f=(0,m.cat)(p),{waveform:M}=await v(a.sessions.model,{spectrogram:f});return{spectrogram:f,waveform:M}}}class nc extends W{main_input_name="spectrogram"}class nd extends W{}class nu extends nd{async generate_speech({input_ids:e,attention_mask:t,style:r,num_inference_steps:o=5,speed:s=1.05}){let{sampling_rate:a,chunk_compress_factor:i,base_chunk_size:n,latent_dim:l}=this.config,{last_hidden_state:c,durations:d}=await v(this.sessions.text_encoder,{input_ids:e,attention_mask:t,style:r});d.div_(s);let u=d.max().item()*a,p=n*i,_=Math.floor((u+p-1)/p),h=e.dims[0],g=(0,m.ones)([h,_]),f=(0,m.full)([h],o),M=(0,m.randn)([h,l*i,_]);for(let e=0;e<o;++e){let o=(0,m.full)([h],e);({denoised_latents:M}=await v(this.sessions.latent_denoiser,{style:r,noisy_latents:M,latent_mask:g,encoder_outputs:c,attention_mask:t,timestep:o,num_inference_steps:f}))}let{waveform:w}=await v(this.sessions.voice_decoder,{latents:M});return{waveform:w,durations:d}}}class nm extends W{}class np extends nm{}class n_ extends W{}class nh extends n_{}class ng extends n_{}class nf extends W{}class nM extends nf{}class nw extends nf{}class nT extends W{}class nP extends nT{}class nx extends nT{}class nb extends W{}class nF extends nb{}class nk extends nb{}class ny extends W{}class nv extends ny{}class nC extends ny{}class nS extends W{}class nE extends nS{}class nA extends nS{}class nL extends W{}class nI extends nL{}class nD extends nL{static async from_pretrained(e,t={}){return super.from_pretrained(e,{...t,model_file_name:t.model_file_name??"text_model"})}}class nz extends nL{static async from_pretrained(e,t={}){return super.from_pretrained(e,{...t,model_file_name:t.model_file_name??"audio_model"})}}class nj extends W{}class nV extends nj{async _call(e){return new cY(await super._call(e))}}class nO extends W{}class nN extends nO{}class nB extends nO{}class nG extends nO{}class nR extends W{}class nq extends nR{}class n$ extends nR{}class nW extends W{}class nU extends nW{}class nQ extends nW{async _call(e){return new cq(await super._call(e))}}class nX extends W{}class nH extends nX{}class nJ extends nX{}class nY extends W{forward_params=["input_ids","attention_mask","encoder_outputs","decoder_input_ids","decoder_attention_mask","past_key_values"];_apply_and_filter_by_delay_pattern_mask(e){let[t,r]=e.dims,o=this.config.decoder.num_codebooks,s=r-o,a=0;for(let t=0;t<e.size;++t){if(e.data[t]===this.config.decoder.pad_token_id)continue;let i=t%r-Math.floor(t/r)%o;i>0&&i<=s&&(e.data[a++]=e.data[t])}let i=Math.floor(t/o),n=a/(i*o);return new m.Tensor(e.type,e.data.slice(0,a),[i,o,n])}prepare_inputs_for_generation(e,t,r){let o=structuredClone(e);for(let e=0;e<o.length;++e)for(let t=0;t<o[e].length;++t)e%this.config.decoder.num_codebooks>=t&&(o[e][t]=BigInt(this.config.decoder.pad_token_id));return null!==r.guidance_scale&&r.guidance_scale>1&&(o=o.concat(o)),super.prepare_inputs_for_generation(o,t,r)}async generate(e){let t=await super.generate(e),r=this._apply_and_filter_by_delay_pattern_mask(t).unsqueeze_(0),{audio_values:o}=await v(this.sessions.encodec_decode,{audio_codes:r});return o}}class nK extends W{}class nZ extends nK{}class n0 extends nK{async _call(e){return new cq(await super._call(e))}}class n1 extends nK{}class n2 extends W{}class n3 extends n2{}class n4 extends n2{async _call(e){return new cq(await super._call(e))}}class n5 extends n2{}class n8 extends W{}class n6 extends n8{}class n9 extends n8{async _call(e){return new cq(await super._call(e))}}class n7 extends n8{}class le extends W{}class lt extends le{}class lr extends le{async _call(e){return new cq(await super._call(e))}}class lo extends le{}class ls extends W{}class la extends ls{}class li extends W{}class ln extends li{forward_params=["input_ids","pixel_values","images_seq_mask","images_emb_mask","attention_mask","position_ids","past_key_values"];constructor(...e){super(...e),this._generation_mode="text"}async forward(e){let t;let r=this._generation_mode??"text";if("text"!==r&&e.past_key_values){let r=this.sessions.gen_img_embeds,o=(0,n.pick)({image_ids:e.input_ids},r.inputNames);t=await v(r,o)}else{let r=this.sessions.prepare_inputs_embeds,o=(0,n.pick)(e,r.inputNames);t=await v(r,o)}let o={...e,...t},s=await I(this,o),a=this.sessions["text"===r?"lm_head":"gen_head"];if(!a)throw Error(`Unable to find "${a}" generation head`);let i=await v(a,(0,n.pick)(s,a.inputNames));return{...t,...s,...i}}async generate(e){return this._generation_mode="text",super.generate(e)}async generate_images(e){this._generation_mode="image";let t=(e.inputs??e[this.main_input_name]).dims[1],r=(await super.generate(e)).slice(null,[t,null]),o=this.sessions.image_decode,{decoded_image:s}=await v(o,{generated_tokens:r}),a=s.add_(1).mul_(127.5).clamp_(0,255).to("uint8"),i=[];for(let e of a){let t=p.RawImage.fromTensor(e);i.push(t)}return i}}class ll extends U{constructor({char_logits:e,bpe_logits:t,wp_logits:r}){super(),this.char_logits=e,this.bpe_logits=t,this.wp_logits=r}get logits(){return[this.char_logits,this.bpe_logits,this.wp_logits]}}class lc extends W{}class ld extends lc{async _call(e){return new ll(await super._call(e))}}class lu extends W{}class lm extends lu{}class lp extends lu{}class l_ extends W{}class lh extends l_{}class lg extends l_{}class lf extends W{forward_params=["input_ids","attention_mask","position_ids","audio_values","past_key_values"]}class lM extends lf{_merge_input_ids_with_audio_features(e){let t=e.audio_features.dims.at(-1),r=e.audio_features.view(-1,t);return j({audio_token_id:this.config.ignore_index??this.config.audio_token_id,...e,audio_features:r})}}class lw extends lM{}class lT extends W{main_input_name="input_values";forward_params=["input_values"]}class lP extends U{constructor({audio_codes:e}){super(),this.audio_codes=e}}class lx extends U{constructor({audio_values:e}){super(),this.audio_values=e}}class lb extends lT{async encode(e){return new lP(await v(this.sessions.encoder_model,e))}async decode(e){return new lx(await v(this.sessions.decoder_model,e))}}class lF extends lT{static async from_pretrained(e,t={}){return super.from_pretrained(e,{...t,model_file_name:t.model_file_name??"encoder_model"})}}class lk extends lT{static async from_pretrained(e,t={}){return super.from_pretrained(e,{...t,model_file_name:t.model_file_name??"decoder_model"})}}class ly extends W{main_input_name="input_values";forward_params=["input_values"]}class lv extends U{constructor({audio_codes:e}){super(),this.audio_codes=e}}class lC extends U{constructor({audio_values:e}){super(),this.audio_values=e}}class lS extends ly{async encode(e){return new lv(await v(this.sessions.encoder_model,e))}async decode(e){return new lC(await v(this.sessions.decoder_model,e))}}class lE extends ly{static async from_pretrained(e,t={}){return super.from_pretrained(e,{...t,model_file_name:t.model_file_name??"encoder_model"})}}class lA extends ly{static async from_pretrained(e,t={}){return super.from_pretrained(e,{...t,model_file_name:t.model_file_name??"decoder_model"})}}class lL extends W{main_input_name="input_values";forward_params=["input_values"]}class lI extends lL{async encode(e){return await v(this.sessions.encoder_model,e)}async decode(e){return await v(this.sessions.decoder_model,e)}}class lD extends lL{static async from_pretrained(e,t={}){return super.from_pretrained(e,{...t,model_file_name:t.model_file_name??"encoder_model"})}}class lz extends lL{static async from_pretrained(e,t={}){return super.from_pretrained(e,{...t,model_file_name:t.model_file_name??"decoder_model"})}}class lj{static MODEL_CLASS_MAPPINGS=null;static BASE_IF_FAIL=!1;static async from_pretrained(e,{progress_callback:t=null,config:r=null,cache_dir:s=null,local_files_only:a=!1,revision:i="main",model_file_name:n=null,subfolder:l="onnx",device:c=null,dtype:d=null,use_external_data_format:u=null,session_options:m={}}={}){let p={progress_callback:t,config:r,cache_dir:s,local_files_only:a,revision:i,model_file_name:n,subfolder:l,device:c,dtype:d,use_external_data_format:u,session_options:m};if(p.config=await o.AutoConfig.from_pretrained(e,p),!this.MODEL_CLASS_MAPPINGS)throw Error("`MODEL_CLASS_MAPPINGS` not implemented for this type of `AutoClass`: "+this.name);let _=p.config.model_type;for(let t of this.MODEL_CLASS_MAPPINGS){let r=t.get(_);if(!r){for(let e of t.values())if(e[0]===_){r=e;break}if(!r)continue}return await r[1].from_pretrained(e,p)}if(this.BASE_IF_FAIL)return cd.has(_)||console.warn(`Unknown model class "${_}", attempting to construct from base class.`),await W.from_pretrained(e,p);throw Error(`Unsupported model type: ${_}`)}}let lV=new Map([["bert",["BertModel",H]],["neobert",["NeoBertModel",et]],["modernbert",["ModernBertModel",en]],["nomic_bert",["NomicBertModel",eh]],["roformer",["RoFormerModel",ef]],["electra",["ElectraModel",eS]],["esm",["EsmModel",e5]],["convbert",["ConvBertModel",eb]],["camembert",["CamembertModel",ez]],["deberta",["DebertaModel",eG]],["deberta-v2",["DebertaV2Model",eQ]],["mpnet",["MPNetModel",ta]],["albert",["AlbertModel",tg]],["distilbert",["DistilBertModel",eZ]],["roberta",["RobertaModel",tW]],["xlm",["XLMModel",tY]],["xlm-roberta",["XLMRobertaModel",t3]],["clap",["ClapModel",nI]],["clip",["CLIPModel",rv]],["clipseg",["CLIPSegModel",rq]],["chinese_clip",["ChineseCLIPModel",rV]],["siglip",["SiglipModel",rI]],["jina_clip",["JinaCLIPModel",rN]],["mobilebert",["MobileBertModel",te]],["squeezebert",["SqueezeBertModel",tu]],["wav2vec2",["Wav2Vec2Model",iI]],["wav2vec2-bert",["Wav2Vec2BertModel",i0]],["unispeech",["UniSpeechModel",iW]],["unispeech-sat",["UniSpeechSatModel",iH]],["hubert",["HubertModel",i4]],["wavlm",["WavLMModel",i9]],["audio-spectrogram-transformer",["ASTModel",t7]],["vits",["VitsModel",nV]],["pyannote",["PyAnnoteModel",iB]],["wespeaker-resnet",["WeSpeakerResNetModel",iq]],["detr",["DetrModel",s5]],["rt_detr",["RTDetrModel",at]],["rt_detr_v2",["RTDetrV2Model",aa]],["rf_detr",["RFDetrModel",ac]],["d_fine",["DFineModel",ap]],["table-transformer",["TableTransformerModel",ag]],["vit",["ViTModel",sP]],["ijepa",["IJepaModel",sF]],["pvt",["PvtModel",sS]],["vit_msn",["ViTMSNModel",sD]],["vit_mae",["ViTMAEModel",sL]],["groupvit",["GroupViTModel",sV]],["fastvit",["FastViTModel",sN]],["mobilevit",["MobileViTModel",s$]],["mobilevitv2",["MobileViTV2Model",sQ]],["owlvit",["OwlViTModel",sJ]],["owlv2",["Owlv2Model",sZ]],["beit",["BeitModel",s2]],["deit",["DeiTModel",aT]],["hiera",["HieraModel",ab]],["convnext",["ConvNextModel",a5]],["convnextv2",["ConvNextV2Model",a9]],["dinov2",["Dinov2Model",it]],["dinov2_with_registers",["Dinov2WithRegistersModel",is]],["dinov3_vit",["DINOv3ViTModel",il]],["dinov3_convnext",["DINOv3ConvNextModel",id]],["resnet",["ResNetModel",ay]],["swin",["SwinModel",aS]],["swin2sr",["Swin2SRModel",aI]],["donut-swin",["DonutSwinModel",a3]],["yolos",["YolosModel",i_]],["dpt",["DPTModel",aj]],["glpn",["GLPNModel",a0]],["hifigan",["SpeechT5HifiGan",nc]],["efficientnet",["EfficientNetModel",nU]],["decision_transformer",["DecisionTransformerModel",la]],["patchtst",["PatchTSTForPrediction",lm]],["patchtsmixer",["PatchTSMixerForPrediction",lh]],["mobilenet_v1",["MobileNetV1Model",nZ]],["mobilenet_v2",["MobileNetV2Model",n3]],["mobilenet_v3",["MobileNetV3Model",n6]],["mobilenet_v4",["MobileNetV4Model",lt]],["maskformer",["MaskFormerModel",aY]],["mgp-str",["MgpstrForSceneTextRecognition",ld]],["style_text_to_speech_2",["StyleTextToSpeech2Model",ns]]]),lO=new Map([["t5",["T5Model",tP]],["longt5",["LongT5Model",tF]],["mt5",["MT5Model",tv]],["bart",["BartModel",tE]],["mbart",["MBartModel",tD]],["marian",["MarianModel",iv]],["whisper",["WhisperModel",rr]],["m2m_100",["M2M100Model",iE]],["blenderbot",["BlenderbotModel",tN]],["blenderbot-small",["BlenderbotSmallModel",tR]]]),lN=new Map([["mimi",["MimiModel",lb]],["dac",["DacModel",lS]],["snac",["SnacModel",lI]]]),lB=new Map([["bloom",["BloomModel",sm]],["jais",["JAISModel",rH]],["gpt2",["GPT2Model",rU]],["gptj",["GPTJModel",r4]],["gpt_bigcode",["GPTBigCodeModel",r6]],["gpt_neo",["GPTNeoModel",rK]],["gpt_neox",["GPTNeoXModel",r1]],["codegen",["CodeGenModel",oe]],["llama",["LlamaModel",oo]],["nanochat",["NanoChatModel",ol]],["arcee",["ArceeModel",ou]],["lfm2",["Lfm2Model",o_]],["smollm3",["SmolLM3Model",of]],["exaone",["ExaoneModel",oy]],["olmo",["OlmoModel",oL]],["olmo2",["Olmo2Model",oz]],["mobilellm",["MobileLLMModel",oS]],["granite",["GraniteModel",oO]],["granitemoehybrid",["GraniteMoeHybridModel",oG]],["cohere",["CohereModel",o$]],["gemma",["GemmaModel",oQ]],["gemma2",["Gemma2Model",oJ]],["vaultgemma",["VaultGemmaModel",oZ]],["gemma3_text",["Gemma3Model",o2]],["helium",["HeliumModel",oT]],["glm",["GlmModel",ob]],["openelm",["OpenELMModel",o5]],["qwen2",["Qwen2Model",o9]],["qwen3",["Qwen3Model",st]],["phi",["PhiModel",si]],["phi3",["Phi3Model",sc]],["mpt",["MptModel",sh]],["opt",["OPTModel",sM]],["mistral",["MistralModel",nh]],["ministral",["MinistralModel",nM]],["ministral3",["Ministral3Model",nP]],["ernie4_5",["Ernie4_5Model",nF]],["starcoder2",["Starcoder2Model",nv]],["falcon",["FalconModel",nE]],["stablelm",["StableLmModel",nq]],["modernbert-decoder",["ModernBertDecoderModel",em]]]),lG=new Map([["speecht5",["SpeechT5ForSpeechToText",nn]],["whisper",["WhisperForConditionalGeneration",ro]],["lite-whisper",["LiteWhisperForConditionalGeneration",rs]],["moonshine",["MoonshineForConditionalGeneration",rn]]]),lR=new Map([["speecht5",["SpeechT5ForTextToSpeech",nl]]]),lq=new Map([["vits",["VitsModel",nV]],["musicgen",["MusicgenForConditionalGeneration",nY]],["supertonic",["SupertonicForConditionalGeneration",nu]]]),l$=new Map([["bert",["BertForSequenceClassification",Y]],["neobert",["NeoBertForSequenceClassification",eo]],["modernbert",["ModernBertForSequenceClassification",ec]],["roformer",["RoFormerForSequenceClassification",ew]],["electra",["ElectraForSequenceClassification",eA]],["esm",["EsmForSequenceClassification",e6]],["convbert",["ConvBertForSequenceClassification",ek]],["camembert",["CamembertForSequenceClassification",eV]],["deberta",["DebertaForSequenceClassification",eq]],["deberta-v2",["DebertaV2ForSequenceClassification",eH]],["mpnet",["MPNetForSequenceClassification",tn]],["albert",["AlbertForSequenceClassification",tf]],["distilbert",["DistilBertForSequenceClassification",e0]],["roberta",["RobertaForSequenceClassification",tQ]],["xlm",["XLMForSequenceClassification",tZ]],["xlm-roberta",["XLMRobertaForSequenceClassification",t5]],["bart",["BartForSequenceClassification",tL]],["mbart",["MBartForSequenceClassification",tj]],["mobilebert",["MobileBertForSequenceClassification",tr]],["squeezebert",["SqueezeBertForSequenceClassification",tp]]]),lW=new Map([["bert",["BertForTokenClassification",K]],["neobert",["NeoBertForTokenClassification",es]],["modernbert",["ModernBertForTokenClassification",ed]],["roformer",["RoFormerForTokenClassification",eT]],["electra",["ElectraForTokenClassification",eL]],["esm",["EsmForTokenClassification",e9]],["convbert",["ConvBertForTokenClassification",ey]],["camembert",["CamembertForTokenClassification",eO]],["deberta",["DebertaForTokenClassification",e$]],["deberta-v2",["DebertaV2ForTokenClassification",eJ]],["mpnet",["MPNetForTokenClassification",tl]],["distilbert",["DistilBertForTokenClassification",e1]],["roberta",["RobertaForTokenClassification",tX]],["xlm",["XLMForTokenClassification",t0]],["xlm-roberta",["XLMRobertaForTokenClassification",t8]]]),lU=new Map([["t5",["T5ForConditionalGeneration",tx]],["longt5",["LongT5ForConditionalGeneration",tk]],["mt5",["MT5ForConditionalGeneration",tC]],["bart",["BartForConditionalGeneration",tA]],["mbart",["MBartForConditionalGeneration",tz]],["marian",["MarianMTModel",iC]],["m2m_100",["M2M100ForConditionalGeneration",iA]],["blenderbot",["BlenderbotForConditionalGeneration",tB]],["blenderbot-small",["BlenderbotSmallForConditionalGeneration",tq]]]),lQ=new Map([["bloom",["BloomForCausalLM",sp]],["gpt2",["GPT2LMHeadModel",rQ]],["jais",["JAISLMHeadModel",rJ]],["gptj",["GPTJForCausalLM",r5]],["gpt_bigcode",["GPTBigCodeForCausalLM",r9]],["gpt_neo",["GPTNeoForCausalLM",rZ]],["gpt_neox",["GPTNeoXForCausalLM",r2]],["codegen",["CodeGenForCausalLM",ot]],["llama",["LlamaForCausalLM",os]],["nanochat",["NanoChatForCausalLM",oc]],["llama4_text",["Llama4ForCausalLM",oi]],["arcee",["ArceeForCausalLM",om]],["lfm2",["Lfm2ForCausalLM",oh]],["smollm3",["SmolLM3ForCausalLM",oM]],["exaone",["ExaoneForCausalLM",ov]],["olmo",["OlmoForCausalLM",oI]],["olmo2",["Olmo2ForCausalLM",oj]],["mobilellm",["MobileLLMForCausalLM",oE]],["granite",["GraniteForCausalLM",oN]],["granitemoehybrid",["GraniteMoeHybridForCausalLM",oR]],["cohere",["CohereForCausalLM",oW]],["gemma",["GemmaForCausalLM",oX]],["gemma2",["Gemma2ForCausalLM",oY]],["vaultgemma",["VaultGemmaForCausalLM",o0]],["gemma3_text",["Gemma3ForCausalLM",o3]],["helium",["HeliumForCausalLM",oP]],["glm",["GlmForCausalLM",oF]],["openelm",["OpenELMForCausalLM",o8]],["qwen2",["Qwen2ForCausalLM",o7]],["qwen3",["Qwen3ForCausalLM",sr]],["phi",["PhiForCausalLM",sn]],["phi3",["Phi3ForCausalLM",sd]],["mpt",["MptForCausalLM",sg]],["opt",["OPTForCausalLM",sw]],["mbart",["MBartForCausalLM",tV]],["mistral",["MistralForCausalLM",ng]],["ministral",["MinistralForCausalLM",nw]],["ministral3",["Ministral3ForCausalLM",nx]],["ernie4_5",["Ernie4_5ForCausalLM",nk]],["starcoder2",["Starcoder2ForCausalLM",nC]],["falcon",["FalconForCausalLM",nA]],["trocr",["TrOCRForCausalLM",np]],["stablelm",["StableLmForCausalLM",n$]],["modernbert-decoder",["ModernBertDecoderForCausalLM",ep]],["phi3_v",["Phi3VForCausalLM",rk]]]),lX=new Map([["multi_modality",["MultiModalityCausalLM",ln]]]),lH=new Map([["bert",["BertForMaskedLM",J]],["neobert",["NeoBertForMaskedLM",er]],["modernbert",["ModernBertForMaskedLM",el]],["roformer",["RoFormerForMaskedLM",eM]],["electra",["ElectraForMaskedLM",eE]],["esm",["EsmForMaskedLM",e8]],["convbert",["ConvBertForMaskedLM",eF]],["camembert",["CamembertForMaskedLM",ej]],["deberta",["DebertaForMaskedLM",eR]],["deberta-v2",["DebertaV2ForMaskedLM",eX]],["mpnet",["MPNetForMaskedLM",ti]],["albert",["AlbertForMaskedLM",tw]],["distilbert",["DistilBertForMaskedLM",e3]],["roberta",["RobertaForMaskedLM",tU]],["xlm",["XLMWithLMHeadModel",tK]],["xlm-roberta",["XLMRobertaForMaskedLM",t4]],["mobilebert",["MobileBertForMaskedLM",tt]],["squeezebert",["SqueezeBertForMaskedLM",tm]]]),lJ=new Map([["bert",["BertForQuestionAnswering",Z]],["neobert",["NeoBertForQuestionAnswering",ea]],["roformer",["RoFormerForQuestionAnswering",eP]],["electra",["ElectraForQuestionAnswering",eI]],["convbert",["ConvBertForQuestionAnswering",ev]],["camembert",["CamembertForQuestionAnswering",eN]],["deberta",["DebertaForQuestionAnswering",eW]],["deberta-v2",["DebertaV2ForQuestionAnswering",eY]],["mpnet",["MPNetForQuestionAnswering",tc]],["albert",["AlbertForQuestionAnswering",tM]],["distilbert",["DistilBertForQuestionAnswering",e2]],["roberta",["RobertaForQuestionAnswering",tH]],["xlm",["XLMForQuestionAnswering",t1]],["xlm-roberta",["XLMRobertaForQuestionAnswering",t6]],["mobilebert",["MobileBertForQuestionAnswering",to]],["squeezebert",["SqueezeBertForQuestionAnswering",t_]]]),lY=new Map([["vision-encoder-decoder",["VisionEncoderDecoderModel",rl]],["idefics3",["Idefics3ForConditionalGeneration",rx]],["smolvlm",["SmolVLMForConditionalGeneration",rb]]]),lK=new Map([["llava",["LlavaForConditionalGeneration",rd]],["llava_onevision",["LlavaOnevisionForConditionalGeneration",ru]],["moondream1",["Moondream1ForConditionalGeneration",rm]],["florence2",["Florence2ForConditionalGeneration",r_]],["qwen2-vl",["Qwen2VLForConditionalGeneration",ss]],["idefics3",["Idefics3ForConditionalGeneration",rx]],["smolvlm",["SmolVLMForConditionalGeneration",rb]],["paligemma",["PaliGemmaForConditionalGeneration",rg]],["llava_qwen2",["LlavaQwen2ForCausalLM",rf]],["gemma3n",["Gemma3nForConditionalGeneration",rT]],["mistral3",["Mistral3ForConditionalGeneration",rM]]]),lZ=new Map([["ultravox",["UltravoxModel",lM]],["voxtral",["VoxtralForConditionalGeneration",lw]]]),l0=new Map([["vision-encoder-decoder",["VisionEncoderDecoderModel",rl]]]),l1=new Map([["vit",["ViTForImageClassification",sx]],["ijepa",["IJepaForImageClassification",sk]],["pvt",["PvtForImageClassification",sE]],["vit_msn",["ViTMSNForImageClassification",sz]],["fastvit",["FastViTForImageClassification",sB]],["mobilevit",["MobileViTForImageClassification",sW]],["mobilevitv2",["MobileViTV2ForImageClassification",sX]],["beit",["BeitForImageClassification",s3]],["deit",["DeiTForImageClassification",aP]],["hiera",["HieraForImageClassification",aF]],["convnext",["ConvNextForImageClassification",a8]],["convnextv2",["ConvNextV2ForImageClassification",a7]],["dinov2",["Dinov2ForImageClassification",ir]],["dinov2_with_registers",["Dinov2WithRegistersForImageClassification",ia]],["resnet",["ResNetForImageClassification",av]],["swin",["SwinForImageClassification",aE]],["segformer",["SegformerForImageClassification",nB]],["efficientnet",["EfficientNetForImageClassification",nQ]],["mobilenet_v1",["MobileNetV1ForImageClassification",n0]],["mobilenet_v2",["MobileNetV2ForImageClassification",n4]],["mobilenet_v3",["MobileNetV3ForImageClassification",n9]],["mobilenet_v4",["MobileNetV4ForImageClassification",lr]]]),l2=new Map([["detr",["DetrForObjectDetection",s8]],["rt_detr",["RTDetrForObjectDetection",ar]],["rt_detr_v2",["RTDetrV2ForObjectDetection",ai]],["rf_detr",["RFDetrForObjectDetection",ad]],["d_fine",["DFineForObjectDetection",a_]],["table-transformer",["TableTransformerForObjectDetection",af]],["yolos",["YolosForObjectDetection",ih]]]),l3=new Map([["owlvit",["OwlViTForObjectDetection",sY]],["owlv2",["Owlv2ForObjectDetection",s0]],["grounding-dino",["GroundingDinoForObjectDetection",im]]]),l4=new Map([["detr",["DetrForSegmentation",s6]],["clipseg",["CLIPSegForImageSegmentation",r$]]]),l5=new Map([["segformer",["SegformerForSemanticSegmentation",nG]],["sapiens",["SapiensForSemanticSegmentation",aG]],["swin",["SwinForSemanticSegmentation",aA]],["mobilenet_v1",["MobileNetV1ForSemanticSegmentation",n1]],["mobilenet_v2",["MobileNetV2ForSemanticSegmentation",n5]],["mobilenet_v3",["MobileNetV3ForSemanticSegmentation",n7]],["mobilenet_v4",["MobileNetV4ForSemanticSegmentation",lo]]]),l8=new Map([["detr",["DetrForSegmentation",s6]],["maskformer",["MaskFormerForInstanceSegmentation",aK]]]),l6=new Map([["sam",["SamModel",iw]],["sam2",["Sam2Model",ib]],["edgetam",["EdgeTamModel",iF]],["sam3_tracker",["Sam3TrackerModel",ik]]]),l9=new Map([["wav2vec2",["Wav2Vec2ForCTC",iD]],["wav2vec2-bert",["Wav2Vec2BertForCTC",i1]],["unispeech",["UniSpeechForCTC",iU]],["unispeech-sat",["UniSpeechSatForCTC",iJ]],["wavlm",["WavLMForCTC",i7]],["hubert",["HubertForCTC",i5]],["parakeet_ctc",["ParakeetForCTC",iO]]]),l7=new Map([["wav2vec2",["Wav2Vec2ForSequenceClassification",iz]],["wav2vec2-bert",["Wav2Vec2BertForSequenceClassification",i2]],["unispeech",["UniSpeechForSequenceClassification",iQ]],["unispeech-sat",["UniSpeechSatForSequenceClassification",iY]],["wavlm",["WavLMForSequenceClassification",ne]],["hubert",["HubertForSequenceClassification",i8]],["audio-spectrogram-transformer",["ASTForAudioClassification",re]]]),ce=new Map([["wavlm",["WavLMForXVector",nt]]]),ct=new Map([["unispeech-sat",["UniSpeechSatForAudioFrameClassification",iK]],["wavlm",["WavLMForAudioFrameClassification",nr]],["wav2vec2",["Wav2Vec2ForAudioFrameClassification",ij]],["pyannote",["PyAnnoteForAudioFrameClassification",iG]]]),cr=new Map([["vitmatte",["VitMatteForImageMatting",sR]]]),co=new Map([["patchtst",["PatchTSTForPrediction",lp]],["patchtsmixer",["PatchTSMixerForPrediction",lg]]]),cs=new Map([["swin2sr",["Swin2SRForImageSuperResolution",aD]]]),ca=new Map([["dpt",["DPTForDepthEstimation",aV]],["depth_anything",["DepthAnythingForDepthEstimation",aN]],["glpn",["GLPNForDepthEstimation",a1]],["sapiens",["SapiensForDepthEstimation",aR]],["depth_pro",["DepthProForDepthEstimation",aW]],["metric3d",["Metric3DForDepthEstimation",aQ]],["metric3dv2",["Metric3Dv2ForDepthEstimation",aH]]]),ci=new Map([["sapiens",["SapiensForNormalEstimation",aq]]]),cn=new Map([["vitpose",["VitPoseForPoseEstimation",sv]]]),cl=new Map([["clip",["CLIPVisionModelWithProjection",rA]],["siglip",["SiglipVisionModel",rz]],["jina_clip",["JinaCLIPVisionModel",rG]]]),cc=[[lV,T.EncoderOnly],[lO,T.EncoderDecoder],[lB,T.DecoderOnly],[lN,T.AutoEncoder],[l$,T.EncoderOnly],[lW,T.EncoderOnly],[lU,T.Seq2Seq],[lG,T.Seq2Seq],[lQ,T.DecoderOnly],[lX,T.MultiModality],[lH,T.EncoderOnly],[lJ,T.EncoderOnly],[lY,T.Vision2Seq],[lK,T.ImageTextToText],[lZ,T.AudioTextToText],[l1,T.EncoderOnly],[l4,T.EncoderOnly],[l8,T.EncoderOnly],[l5,T.EncoderOnly],[cr,T.EncoderOnly],[co,T.EncoderOnly],[cs,T.EncoderOnly],[ca,T.EncoderOnly],[ci,T.EncoderOnly],[cn,T.EncoderOnly],[l2,T.EncoderOnly],[l3,T.EncoderOnly],[l6,T.MaskGeneration],[l9,T.EncoderOnly],[l7,T.EncoderOnly],[lR,T.Seq2Seq],[lq,T.EncoderOnly],[ce,T.EncoderOnly],[ct,T.EncoderOnly],[cl,T.EncoderOnly]];for(let[e,t]of cc)for(let[r,o]of e.values())P.set(r,t),b.set(o,r),x.set(r,o);for(let[e,t,r]of[["MusicgenForConditionalGeneration",nY,T.Musicgen],["Phi3VForCausalLM",rk,T.Phi3V],["CLIPTextModelWithProjection",rS,T.EncoderOnly],["SiglipTextModel",rD,T.EncoderOnly],["JinaCLIPTextModel",rB,T.EncoderOnly],["ClapTextModelWithProjection",nD,T.EncoderOnly],["ClapAudioModelWithProjection",nz,T.EncoderOnly],["DacEncoderModel",lE,T.EncoderOnly],["DacDecoderModel",lA,T.EncoderOnly],["MimiEncoderModel",lF,T.EncoderOnly],["MimiDecoderModel",lk,T.EncoderOnly],["SnacEncoderModel",lD,T.EncoderOnly],["SnacDecoderModel",lz,T.EncoderOnly],["Gemma3nForConditionalGeneration",rT,T.ImageAudioTextToText],["SupertonicForConditionalGeneration",nu,T.Supertonic]])P.set(e,r),b.set(t,e),x.set(e,t);let cd=new Map([["modnet",l4],["birefnet",l4],["isnet",l4],["ben",l4]]);for(let[e,t]of cd.entries())t.set(e,["PreTrainedModel",W]),P.set(e,T.EncoderOnly),b.set(W,e),x.set(e,W);class cu extends lj{static MODEL_CLASS_MAPPINGS=cc.map(e=>e[0]);static BASE_IF_FAIL=!0}class cm extends lj{static MODEL_CLASS_MAPPINGS=[l$]}class cp extends lj{static MODEL_CLASS_MAPPINGS=[lW]}class c_ extends lj{static MODEL_CLASS_MAPPINGS=[lU]}class ch extends lj{static MODEL_CLASS_MAPPINGS=[lG]}class cg extends lj{static MODEL_CLASS_MAPPINGS=[lR]}class cf extends lj{static MODEL_CLASS_MAPPINGS=[lq]}class cM extends lj{static MODEL_CLASS_MAPPINGS=[lQ]}class cw extends lj{static MODEL_CLASS_MAPPINGS=[lH]}class cT extends lj{static MODEL_CLASS_MAPPINGS=[lJ]}class cP extends lj{static MODEL_CLASS_MAPPINGS=[lY]}class cx extends lj{static MODEL_CLASS_MAPPINGS=[l1]}class cb extends lj{static MODEL_CLASS_MAPPINGS=[l4]}class cF extends lj{static MODEL_CLASS_MAPPINGS=[l5]}class ck extends lj{static MODEL_CLASS_MAPPINGS=[l8]}class cy extends lj{static MODEL_CLASS_MAPPINGS=[l2]}class cv extends lj{static MODEL_CLASS_MAPPINGS=[l3]}class cC extends lj{static MODEL_CLASS_MAPPINGS=[l6]}class cS extends lj{static MODEL_CLASS_MAPPINGS=[l9]}class cE extends lj{static MODEL_CLASS_MAPPINGS=[l7]}class cA extends lj{static MODEL_CLASS_MAPPINGS=[ce]}class cL extends lj{static MODEL_CLASS_MAPPINGS=[ct]}class cI extends lj{static MODEL_CLASS_MAPPINGS=[l0]}class cD extends lj{static MODEL_CLASS_MAPPINGS=[cr]}class cz extends lj{static MODEL_CLASS_MAPPINGS=[cs]}class cj extends lj{static MODEL_CLASS_MAPPINGS=[ca]}class cV extends lj{static MODEL_CLASS_MAPPINGS=[ci]}class cO extends lj{static MODEL_CLASS_MAPPINGS=[cn]}class cN extends lj{static MODEL_CLASS_MAPPINGS=[cl]}class cB extends lj{static MODEL_CLASS_MAPPINGS=[lK]}class cG extends lj{static MODEL_CLASS_MAPPINGS=[lZ]}class cR extends U{constructor({logits:e,past_key_values:t,encoder_outputs:r,decoder_attentions:o=null,cross_attentions:s=null}){super(),this.logits=e,this.past_key_values=t,this.encoder_outputs=r,this.decoder_attentions=o,this.cross_attentions=s}}class cq extends U{constructor({logits:e,...t}){super(),this.logits=e;let r=Object.values(t);r.length>0&&(this.attentions=r)}}class c$ extends U{constructor({logits:e,embeddings:t}){super(),this.logits=e,this.embeddings=t}}class cW extends U{constructor({logits:e}){super(),this.logits=e}}class cU extends U{constructor({logits:e}){super(),this.logits=e}}class cQ extends U{constructor({start_logits:e,end_logits:t}){super(),this.start_logits=e,this.end_logits=t}}class cX extends U{constructor({logits:e}){super(),this.logits=e}}class cH extends U{constructor({logits:e,past_key_values:t}){super(),this.logits=e,this.past_key_values=t}}class cJ extends U{constructor({alphas:e}){super(),this.alphas=e}}class cY extends U{constructor({waveform:e,spectrogram:t}){super(),this.waveform=e,this.spectrogram=t}}},"./src/models/audio_spectrogram_transformer/feature_extraction_audio_spectrogram_transformer.js":(e,t,r)=>{r.r(t),r.d(t,{ASTFeatureExtractor:()=>a});var o=r("./src/base/feature_extraction_utils.js");r("./src/utils/tensor.js");var s=r("./src/utils/audio.js");class a extends o.FeatureExtractor{constructor(e){super(e);let t=this.config.sampling_rate,r=(0,s.mel_filter_bank)(257,this.config.num_mel_bins,20,Math.floor(t/2),t,null,"kaldi",!0);this.mel_filters=r,this.window=(0,s.window_function)(400,"hann",{periodic:!1}),this.mean=this.config.mean,this.std=this.config.std}async _extract_fbank_features(e,t){return(0,s.spectrogram)(e,this.window,400,160,{fft_length:512,power:2,center:!1,preemphasis:.97,mel_filters:this.mel_filters,log_mel:"log",mel_floor:1192092955078125e-22,remove_dc_offset:!0,max_num_frames:t,transpose:!0})}async _call(e){(0,o.validate_audio_inputs)(e,"ASTFeatureExtractor");let t=await this._extract_fbank_features(e,this.config.max_length);if(this.config.do_normalize){let e=2*this.std,r=t.data;for(let t=0;t<r.length;++t)r[t]=(r[t]-this.mean)/e}return{input_values:t.unsqueeze_(0)}}}},"./src/models/auto/feature_extraction_auto.js":(e,t,r)=>{r.r(t),r.d(t,{AutoFeatureExtractor:()=>i});var o=r("./src/utils/constants.js"),s=r("./src/utils/hub.js");r("./src/base/feature_extraction_utils.js");var a=r("./src/models/feature_extractors.js");class i{static async from_pretrained(e,t={}){let r=await (0,s.getModelJSON)(e,o.FEATURE_EXTRACTOR_NAME,!0,t),i=r.feature_extractor_type,n=a[i];if(!n)throw Error(`Unknown feature_extractor_type: '${i}'. Please report this at ${o.GITHUB_ISSUE_URL}.`);return new n(r)}}},"./src/models/auto/image_processing_auto.js":(e,t,r)=>{r.r(t),r.d(t,{AutoImageProcessor:()=>n});var o=r("./src/utils/constants.js"),s=r("./src/utils/hub.js"),a=r("./src/base/image_processors_utils.js"),i=r("./src/models/image_processors.js");class n{static async from_pretrained(e,t={}){let r=await (0,s.getModelJSON)(e,o.IMAGE_PROCESSOR_NAME,!0,t),n=r.image_processor_type??r.feature_extractor_type,l=i[n?.replace(/Fast$/,"")];return l||(void 0!==n&&console.warn(`Image processor type '${n}' not found, assuming base ImageProcessor. Please report this at ${o.GITHUB_ISSUE_URL}.`),l=a.ImageProcessor),new l(r)}}},"./src/models/auto/processing_auto.js":(e,t,r)=>{r.r(t),r.d(t,{AutoProcessor:()=>c});var o=r("./src/utils/constants.js"),s=r("./src/utils/hub.js"),a=r("./src/base/processing_utils.js"),i=r("./src/models/processors.js"),n=r("./src/models/image_processors.js"),l=r("./src/models/feature_extractors.js");class c{static async from_pretrained(e,t={}){let r=await (0,s.getModelJSON)(e,o.IMAGE_PROCESSOR_NAME,!0,t),{image_processor_type:c,feature_extractor_type:d,processor_class:u}=r;if(u&&i[u])return i[u].from_pretrained(e,t);if(!c&&!d)throw Error("No `image_processor_type` or `feature_extractor_type` found in the config.");let m={};if(c){let e=n[c.replace(/Fast$/,"")];if(!e)throw Error(`Unknown image_processor_type: '${c}'.`);m.image_processor=new e(r)}if(d){let e=n[d];if(e)m.image_processor=new e(r);else{let e=l[d];if(!e)throw Error(`Unknown feature_extractor_type: '${d}'.`);m.feature_extractor=new e(r)}}return new a.Processor({},m,null)}}},"./src/models/beit/image_processing_beit.js":(e,t,r)=>{r.r(t),r.d(t,{BeitFeatureExtractor:()=>s});var o=r("./src/base/image_processors_utils.js");class s extends o.ImageProcessor{}},"./src/models/bit/image_processing_bit.js":(e,t,r)=>{r.r(t),r.d(t,{BitImageProcessor:()=>s});var o=r("./src/base/image_processors_utils.js");class s extends o.ImageProcessor{}},"./src/models/chinese_clip/image_processing_chinese_clip.js":(e,t,r)=>{r.r(t),r.d(t,{ChineseCLIPFeatureExtractor:()=>s});var o=r("./src/base/image_processors_utils.js");class s extends o.ImageProcessor{}},"./src/models/clap/feature_extraction_clap.js":(e,t,r)=>{r.r(t),r.d(t,{ClapFeatureExtractor:()=>a});var o=r("./src/base/feature_extraction_utils.js");r("./src/utils/tensor.js");var s=r("./src/utils/audio.js");class a extends o.FeatureExtractor{constructor(e){super(e),this.mel_filters=(0,s.mel_filter_bank)(this.config.nb_frequency_bins,this.config.feature_size,this.config.frequency_min,this.config.frequency_max,this.config.sampling_rate,null,"htk"),this.mel_filters_slaney=(0,s.mel_filter_bank)(this.config.nb_frequency_bins,this.config.feature_size,this.config.frequency_min,this.config.frequency_max,this.config.sampling_rate,"slaney","slaney"),this.window=(0,s.window_function)(this.config.fft_window_size,"hann")}async _get_input_mel(e,t,r,o){let s;let a=e.length-t;if(a>0){if("rand_trunc"===r){let r=Math.floor(Math.random()*(a+1));e=e.subarray(r,r+t),s=await this._extract_fbank_features(e,this.mel_filters_slaney,this.config.nb_max_samples)}else throw Error(`Truncation strategy "${r}" not implemented`)}else{if(a<0){let r=new Float64Array(t);if(r.set(e),"repeat"===o)for(let o=e.length;o<t;o+=e.length)r.set(e.subarray(0,Math.min(e.length,t-o)),o);else if("repeatpad"===o)for(let t=e.length;t<-a;t+=e.length)r.set(e,t);e=r}if("fusion"===r)throw Error(`Truncation strategy "${r}" not implemented`);s=await this._extract_fbank_features(e,this.mel_filters_slaney,this.config.nb_max_samples)}return s.unsqueeze_(0)}async _extract_fbank_features(e,t,r=null){return(0,s.spectrogram)(e,this.window,this.config.fft_window_size,this.config.hop_length,{power:2,mel_filters:t,log_mel:"dB",max_num_frames:r,do_pad:!1,transpose:!0})}async _call(e,{max_length:t=null}={}){return(0,o.validate_audio_inputs)(e,"ClapFeatureExtractor"),{input_features:(await this._get_input_mel(e,t??this.config.nb_max_samples,this.config.truncation,this.config.padding)).unsqueeze_(0)}}}},"./src/models/clip/image_processing_clip.js":(e,t,r)=>{r.r(t),r.d(t,{CLIPFeatureExtractor:()=>a,CLIPImageProcessor:()=>s});var o=r("./src/base/image_processors_utils.js");class s extends o.ImageProcessor{}class a extends s{}},"./src/models/convnext/image_processing_convnext.js":(e,t,r)=>{r.r(t),r.d(t,{ConvNextFeatureExtractor:()=>a,ConvNextImageProcessor:()=>s});var o=r("./src/base/image_processors_utils.js");class s extends o.ImageProcessor{constructor(e){super(e),this.crop_pct=this.config.crop_pct??.875}async resize(e){let t=this.size?.shortest_edge;if(void 0===t)throw Error("Size dictionary must contain 'shortest_edge' key.");if(t<384){let r=Math.floor(t/this.crop_pct),[o,s]=this.get_resize_output_image_size(e,{shortest_edge:r});e=await e.resize(o,s,{resample:this.resample}),e=await e.center_crop(t,t)}else e=await e.resize(t,t,{resample:this.resample});return e}}class a extends s{}},"./src/models/dac/feature_extraction_dac.js":(e,t,r)=>{r.r(t),r.d(t,{DacFeatureExtractor:()=>s});var o=r("./src/models/encodec/feature_extraction_encodec.js");class s extends o.EncodecFeatureExtractor{}},"./src/models/deit/image_processing_deit.js":(e,t,r)=>{r.r(t),r.d(t,{DeiTFeatureExtractor:()=>a,DeiTImageProcessor:()=>s});var o=r("./src/base/image_processors_utils.js");class s extends o.ImageProcessor{}class a extends s{}},"./src/models/detr/image_processing_detr.js":(e,t,r)=>{r.r(t),r.d(t,{DetrFeatureExtractor:()=>i,DetrImageProcessor:()=>a});var o=r("./src/base/image_processors_utils.js"),s=r("./src/utils/tensor.js");class a extends o.ImageProcessor{async _call(e){let t=await super._call(e),r=[t.pixel_values.dims[0],64,64],o=(0,s.full)(r,1n);return{...t,pixel_mask:o}}post_process_object_detection(...e){return(0,o.post_process_object_detection)(...e)}post_process_panoptic_segmentation(...e){return(0,o.post_process_panoptic_segmentation)(...e)}post_process_instance_segmentation(...e){return(0,o.post_process_instance_segmentation)(...e)}}class i extends a{}},"./src/models/dinov3_vit/image_processing_dinov3_vit.js":(e,t,r)=>{r.r(t),r.d(t,{DINOv3ViTImageProcessor:()=>s});var o=r("./src/base/image_processors_utils.js");class s extends o.ImageProcessor{}},"./src/models/donut/image_processing_donut.js":(e,t,r)=>{r.r(t),r.d(t,{DonutFeatureExtractor:()=>a,DonutImageProcessor:()=>s});var o=r("./src/base/image_processors_utils.js");class s extends o.ImageProcessor{pad_image(e,t,r,o={}){let[s,a,i]=t,n=this.image_mean;Array.isArray(this.image_mean)||(n=Array(i).fill(n));let l=this.image_std;Array.isArray(l)||(l=Array(i).fill(n));let c=n.map((e,t)=>-e/l[t]);return super.pad_image(e,t,r,{center:!0,constant_values:c,...o})}}class a extends s{}},"./src/models/dpt/image_processing_dpt.js":(e,t,r)=>{r.r(t),r.d(t,{DPTFeatureExtractor:()=>a,DPTImageProcessor:()=>s});var o=r("./src/base/image_processors_utils.js");class s extends o.ImageProcessor{}class a extends s{}},"./src/models/efficientnet/image_processing_efficientnet.js":(e,t,r)=>{r.r(t),r.d(t,{EfficientNetImageProcessor:()=>s});var o=r("./src/base/image_processors_utils.js");class s extends o.ImageProcessor{constructor(e){super(e),this.include_top=this.config.include_top??!0,this.include_top&&(this.image_std=this.image_std.map(e=>e*e))}}},"./src/models/encodec/feature_extraction_encodec.js":(e,t,r)=>{r.r(t),r.d(t,{EncodecFeatureExtractor:()=>a});var o=r("./src/base/feature_extraction_utils.js"),s=r("./src/utils/tensor.js");class a extends o.FeatureExtractor{async _call(e){(0,o.validate_audio_inputs)(e,"EncodecFeatureExtractor"),e instanceof Float64Array&&(e=new Float32Array(e));let t=this.config.feature_size;if(e.length%t!=0)throw Error(`The length of the audio data must be a multiple of the number of channels (${t}).`);let r=[1,t,e.length/t];return{input_values:new s.Tensor("float32",e,r)}}}},"./src/models/feature_extractors.js":(e,t,r)=>{r.r(t),r.d(t,{ASTFeatureExtractor:()=>o.ASTFeatureExtractor,ClapFeatureExtractor:()=>a.ClapFeatureExtractor,DacFeatureExtractor:()=>i.DacFeatureExtractor,EncodecFeatureExtractor:()=>s.EncodecFeatureExtractor,Gemma3nAudioFeatureExtractor:()=>n.Gemma3nAudioFeatureExtractor,ImageFeatureExtractor:()=>f.ImageProcessor,MoonshineFeatureExtractor:()=>l.MoonshineFeatureExtractor,ParakeetFeatureExtractor:()=>c.ParakeetFeatureExtractor,PyAnnoteFeatureExtractor:()=>d.PyAnnoteFeatureExtractor,SeamlessM4TFeatureExtractor:()=>u.SeamlessM4TFeatureExtractor,SnacFeatureExtractor:()=>m.SnacFeatureExtractor,SpeechT5FeatureExtractor:()=>p.SpeechT5FeatureExtractor,Wav2Vec2FeatureExtractor:()=>_.Wav2Vec2FeatureExtractor,WeSpeakerFeatureExtractor:()=>h.WeSpeakerFeatureExtractor,WhisperFeatureExtractor:()=>g.WhisperFeatureExtractor});var o=r("./src/models/audio_spectrogram_transformer/feature_extraction_audio_spectrogram_transformer.js"),s=r("./src/models/encodec/feature_extraction_encodec.js"),a=r("./src/models/clap/feature_extraction_clap.js"),i=r("./src/models/dac/feature_extraction_dac.js"),n=r("./src/models/gemma3n/feature_extraction_gemma3n.js"),l=r("./src/models/moonshine/feature_extraction_moonshine.js"),c=r("./src/models/parakeet/feature_extraction_parakeet.js"),d=r("./src/models/pyannote/feature_extraction_pyannote.js"),u=r("./src/models/seamless_m4t/feature_extraction_seamless_m4t.js"),m=r("./src/models/snac/feature_extraction_snac.js"),p=r("./src/models/speecht5/feature_extraction_speecht5.js"),_=r("./src/models/wav2vec2/feature_extraction_wav2vec2.js"),h=r("./src/models/wespeaker/feature_extraction_wespeaker.js"),g=r("./src/models/whisper/feature_extraction_whisper.js"),f=r("./src/base/image_processors_utils.js")},"./src/models/florence2/processing_florence2.js":(e,t,r)=>{r.r(t),r.d(t,{Florence2Processor:()=>i});var o=r("./src/base/processing_utils.js"),s=r("./src/models/auto/image_processing_auto.js"),a=r("./src/tokenizers.js");class i extends o.Processor{static tokenizer_class=a.AutoTokenizer;static image_processor_class=s.AutoImageProcessor;constructor(e,t,r){super(e,t,r);let{tasks_answer_post_processing_type:o,task_prompts_without_inputs:s,task_prompts_with_input:a}=this.image_processor.config;this.tasks_answer_post_processing_type=new Map(Object.entries(o??{})),this.task_prompts_without_inputs=new Map(Object.entries(s??{})),this.task_prompts_with_input=new Map(Object.entries(a??{})),this.regexes={quad_boxes:/(.+?)<loc_(\d+)><loc_(\d+)><loc_(\d+)><loc_(\d+)><loc_(\d+)><loc_(\d+)><loc_(\d+)><loc_(\d+)>/gm,bboxes:/([^<]+)?<loc_(\d+)><loc_(\d+)><loc_(\d+)><loc_(\d+)>/gm},this.size_per_bin=1e3}construct_prompts(e){"string"==typeof e&&(e=[e]);let t=[];for(let r of e)if(this.task_prompts_without_inputs.has(r))t.push(this.task_prompts_without_inputs.get(r));else{for(let[e,o]of this.task_prompts_with_input)if(r.includes(e)){t.push(o.replaceAll("{input}",r).replaceAll(e,""));break}t.length!==e.length&&t.push(r)}return t}post_process_generation(e,t,r){let o;let s=this.tasks_answer_post_processing_type.get(t)??"pure_text";switch(e=e.replaceAll("<s>","").replaceAll("</s>",""),s){case"pure_text":o=e;break;case"description_with_bboxes":case"bboxes":case"phrase_grounding":case"ocr":let a="ocr"===s?"quad_boxes":"bboxes",i=e.matchAll(this.regexes[a]),n=[],l=[];for(let[e,t,...o]of i)n.push(t?t.trim():n.at(-1)??""),l.push(o.map((e,t)=>(Number(e)+.5)/this.size_per_bin*r[t%2]));o={labels:n,[a]:l};break;default:throw Error(`Task "${t}" (of type "${s}") not yet implemented.`)}return{[t]:o}}async _call(e,t=null,r={}){if(!e&&!t)throw Error("Either text or images must be provided");let o=await this.image_processor(e,r),s=t?this.tokenizer(this.construct_prompts(t),r):{};return{...o,...s}}}},"./src/models/gemma3n/feature_extraction_gemma3n.js":(e,t,r)=>{r.r(t),r.d(t,{Gemma3nAudioFeatureExtractor:()=>i});var o=r("./src/base/feature_extraction_utils.js"),s=r("./src/utils/tensor.js"),a=r("./src/utils/audio.js");class i extends o.FeatureExtractor{constructor(e){super(e);let{fft_length:t,feature_size:r,min_frequency:o,max_frequency:s,sampling_rate:i,frame_length:n}=this.config,l=(0,a.mel_filter_bank)(Math.floor(1+t/2),r,o,s,i,null,"htk",!1);this.mel_filters=l,this.window=(0,a.window_function)(n,"hann")}async _extract_fbank_features(e,t){return(0,a.spectrogram)(e,this.window,this.config.frame_length,this.config.hop_length,{fft_length:this.config.fft_length,center:!1,onesided:!0,preemphasis:this.config.preemphasis,preemphasis_htk_flavor:this.config.preemphasis_htk_flavor,mel_filters:this.mel_filters,log_mel:"log",mel_floor:this.config.mel_floor,remove_dc_offset:!1,transpose:!0})}async _call(e,{max_length:t=48e4,truncation:r=!0,padding:a=!0,pad_to_multiple_of:i=128}={}){if((0,o.validate_audio_inputs)(e,"Gemma3nAudioFeatureExtractor"),r&&e.length>t&&(e=e.slice(0,t)),a&&e.length%i!=0){let t=i-e.length%i,r=new Float64Array(e.length+t);r.set(e),0!==this.config.padding_value&&r.fill(this.config.padding_value,e.length),e=r}let n=await this._extract_fbank_features(e,this.config.max_length),l=(0,s.full)([1,n.dims[0]],!0);return{input_features:n.unsqueeze_(0),input_features_mask:l}}}},"./src/models/gemma3n/processing_gemma3n.js":(e,t,r)=>{r.r(t),r.d(t,{Gemma3nProcessor:()=>n});var o=r("./src/base/processing_utils.js"),s=r("./src/models/auto/image_processing_auto.js"),a=r("./src/models/auto/feature_extraction_auto.js"),i=r("./src/tokenizers.js");r("./src/utils/image.js"),r("./src/utils/audio.js");class n extends o.Processor{static image_processor_class=s.AutoImageProcessor;static feature_extractor_class=a.AutoFeatureExtractor;static tokenizer_class=i.AutoTokenizer;static uses_processor_config=!0;static uses_chat_template_file=!0;constructor(e,t,r){super(e,t,r),this.audio_seq_length=this.config.audio_seq_length,this.image_seq_length=this.config.image_seq_length;let{audio_token_id:o,boa_token:s,audio_token:a,eoa_token:i,image_token_id:n,boi_token:l,image_token:c,eoi_token:d}=this.tokenizer.config;this.audio_token_id=o,this.boa_token=s,this.audio_token=a;let u=a.repeat(this.audio_seq_length);this.full_audio_sequence=`

${s}${u}${i}

`,this.image_token_id=n,this.boi_token=l,this.image_token=c;let m=c.repeat(this.image_seq_length);this.full_image_sequence=`

${l}${m}${d}

`}async _call(e,t=null,r=null,o={}){let s,a;return"string"==typeof e&&(e=[e]),r&&(s=await this.feature_extractor(r,o),e=e.map(e=>e.replaceAll(this.audio_token,this.full_audio_sequence))),t&&(a=await this.image_processor(t,o),e=e.map(e=>e.replaceAll(this.image_token,this.full_image_sequence))),{...this.tokenizer(e,o),...a,...s}}}},"./src/models/glpn/image_processing_glpn.js":(e,t,r)=>{r.r(t),r.d(t,{GLPNFeatureExtractor:()=>s});var o=r("./src/base/image_processors_utils.js");class s extends o.ImageProcessor{}},"./src/models/grounding_dino/image_processing_grounding_dino.js":(e,t,r)=>{r.r(t),r.d(t,{GroundingDinoImageProcessor:()=>a});var o=r("./src/base/image_processors_utils.js"),s=r("./src/utils/tensor.js");class a extends o.ImageProcessor{async _call(e){let t=await super._call(e),r=t.pixel_values.dims,o=(0,s.ones)([r[0],r[2],r[3]]);return{...t,pixel_mask:o}}}},"./src/models/grounding_dino/processing_grounding_dino.js":(e,t,r)=>{r.r(t),r.d(t,{GroundingDinoProcessor:()=>n});var o=r("./src/base/processing_utils.js"),s=r("./src/models/auto/image_processing_auto.js"),a=r("./src/tokenizers.js"),i=r("./src/base/image_processors_utils.js");class n extends o.Processor{static tokenizer_class=a.AutoTokenizer;static image_processor_class=s.AutoImageProcessor;async _call(e,t,r={}){let o=e?await this.image_processor(e,r):{};return{...t?this.tokenizer(t,r):{},...o}}post_process_grounded_object_detection(e,t,{box_threshold:r=.25,text_threshold:o=.25,target_sizes:s=null}={}){let{logits:a,pred_boxes:n}=e,l=a.dims[0];if(null!==s&&s.length!==l)throw Error("Make sure that you pass in as many target sizes as the batch dimension of the logits");let c=a.dims.at(1),d=a.sigmoid(),u=d.max(-1).tolist(),m=n.tolist().map(e=>e.map(e=>(0,i.center_to_corners_format)(e))),p=[];for(let e=0;e<l;++e){let a=null!==s?s[e]:null;null!==a&&(m[e]=m[e].map(e=>e.map((e,t)=>e*a[(t+1)%2])));let i=u[e],n=[],l=[],_=[];for(let s=0;s<c;++s){let a=i[s];if(a<=r)continue;let c=m[e][s],u=d[e][s];n.push(a),_.push(c);let p=function(e,t){let r=e.dims.at(-1)-1,o=e.tolist();o.fill(!1,0,1),o.fill(!1,r);let s=t.tolist();return o.map((e,t)=>e?t:null).filter(e=>null!==e).map(e=>s[e])}(u.gt(o),t[e]);l.push(p)}p.push({scores:n,boxes:_,labels:this.batch_decode(l)})}return p}}},"./src/models/idefics3/image_processing_idefics3.js":(e,t,r)=>{r.r(t),r.d(t,{Idefics3ImageProcessor:()=>a});var o=r("./src/base/image_processors_utils.js"),s=r("./src/utils/tensor.js");class a extends o.ImageProcessor{constructor(e){super(e),this.do_image_splitting=e.do_image_splitting??!0,this.max_image_size=e.max_image_size}get_resize_for_vision_encoder(e,t){let[r,o]=e.dims.slice(-2),s=o/r;return o>=r?r=Math.ceil((r=Math.floor((o=Math.ceil(o/t)*t)/s))/t)*t:o=Math.ceil((o=Math.floor((r=Math.ceil(r/t)*t)*s))/t)*t,{height:r,width:o}}async _call(e,{do_image_splitting:t=null,return_row_col_info:r=!1}={}){let o,a,i;if(Array.isArray(e)){if(0===e.length||!e[0])throw Error("No images provided.");o=Array.isArray(e[0])?e:[e]}else o=[[e]];let n=[],l=[],c=[],d=[],u=[];for(let e of o){let r,o=await Promise.all(e.map(e=>this.preprocess(e)));d.push(...o.map(e=>e.original_size)),u.push(...o.map(e=>e.reshaped_input_size)),o.forEach(e=>e.pixel_values.unsqueeze_(0));let{longest_edge:a}=this.max_image_size;if(t??this.do_image_splitting){let e=Array(o.length),t=Array(o.length);r=await Promise.all(o.map(async(r,o)=>{let i=this.get_resize_for_vision_encoder(r.pixel_values,a),n=await (0,s.interpolate_4d)(r.pixel_values,{size:[i.height,i.width]}),{frames:l,num_splits_h:c,num_splits_w:d}=await this.split_image(n,this.max_image_size);return e[o]=c,t[o]=d,(0,s.cat)(l,0)})),l.push(e),c.push(t)}else{let e=[a,a];r=await Promise.all(o.map(t=>(0,s.interpolate_4d)(t.pixel_values,{size:e}))),l.push(Array(o.length).fill(0)),c.push(Array(o.length).fill(0))}n.push((0,s.cat)(r,0))}let m=n.length,[p,_,h,g]=n[0].dims;if(1===m)a=n[0].unsqueeze_(0),i=(0,s.full)([m,p,h,g],!0);else{let e=Math.max(...n.map(e=>e.dims.at(0))),t=(i=(0,s.full)([m,e,h,g],!0)).data,r=e*h*g;for(let o=0;o<m;++o){let a=n[o].dims[0];if(a<e){n[o]=(0,s.cat)([n[o],(0,s.full)([e-a,_,h,g],0)],0);let i=o*r+a*h*g,l=(o+1)*r;t.fill(!1,i,l)}}a=(0,s.stack)(n,0)}return{pixel_values:a,pixel_attention_mask:i,original_sizes:d,reshaped_input_sizes:u,...r?{rows:l,cols:c}:{}}}async split_image(e,{longest_edge:t}){let r=[],[o,a]=e.dims.slice(-2),i=0,n=0;if(o>t||a>t){i=Math.ceil(o/t),n=Math.ceil(a/t);let l=Math.ceil(o/i),c=Math.ceil(a/n);for(let t=0;t<i;++t)for(let d=0;d<n;++d){let u,m,p,_;t===i-1?(m=o-l,_=o):(m=t*l,_=(t+1)*l),d===n-1?(u=a-c,p=a):(u=d*c,p=(d+1)*c);let h=[m,u],g=[_,p],f=await (0,s.slice)(e,h,g,[2,3]);r.push(f)}(o!==t||a!==t)&&(e=await (0,s.interpolate_4d)(e,{size:[t,t]}))}return r.push(e),{frames:r,num_splits_h:i,num_splits_w:n}}}},"./src/models/idefics3/processing_idefics3.js":(e,t,r)=>{r.r(t),r.d(t,{Idefics3Processor:()=>n});var o=r("./src/base/processing_utils.js"),s=r("./src/models/auto/image_processing_auto.js"),a=r("./src/tokenizers.js");r("./src/utils/image.js");var i=r("./src/utils/core.js");class n extends o.Processor{static image_processor_class=s.AutoImageProcessor;static tokenizer_class=a.AutoTokenizer;static uses_processor_config=!0;fake_image_token="<fake_token_around_image>";image_token="<image>";global_img_token="<global-img>";async _call(e,t=null,r={}){let o;r.return_row_col_info??=!0,t&&(o=await this.image_processor(t,r)),Array.isArray(e)||(e=[e]);let s=o.rows??[Array(e.length).fill(0)],a=o.cols??[Array(e.length).fill(0)],n=this.config.image_seq_len,l=[],c=[];for(let t=0;t<e.length;++t){let r=e[t],o=s[t],d=a[t];l.push((0,i.count)(r,this.image_token));let u=o.map((e,t)=>(function(e,t,r,o,s,a){if(0===e&&0===t)return`${o}${a}`+s.repeat(r)+`${o}`;return function(e,t,r,o,s,a){let i="";for(let a=0;a<t;++a){for(let t=0;t<r;++t)i+=o+`<row_${a+1}_col_${t+1}>`+s.repeat(e);i+="\n"}return i+(`
${o}${a}`+s.repeat(e)+`${o}`)}(r,e,t,o,s,a)})(e,d[t],n,this.fake_image_token,this.image_token,this.global_img_token)),m=r.split(this.image_token);if(0===m.length)throw Error("The image token should be present in the text.");let p=m[0];for(let e=0;e<u.length;++e)p+=u[e]+m[e+1];c.push(p)}return{...this.tokenizer(c),...o}}}},"./src/models/image_processors.js":(e,t,r)=>{r.r(t),r.d(t,{BeitFeatureExtractor:()=>o.BeitFeatureExtractor,BitImageProcessor:()=>s.BitImageProcessor,CLIPFeatureExtractor:()=>i.CLIPFeatureExtractor,CLIPImageProcessor:()=>i.CLIPImageProcessor,ChineseCLIPFeatureExtractor:()=>a.ChineseCLIPFeatureExtractor,ConvNextFeatureExtractor:()=>n.ConvNextFeatureExtractor,ConvNextImageProcessor:()=>n.ConvNextImageProcessor,DINOv3ViTImageProcessor:()=>d.DINOv3ViTImageProcessor,DPTFeatureExtractor:()=>m.DPTFeatureExtractor,DPTImageProcessor:()=>m.DPTImageProcessor,DeiTFeatureExtractor:()=>l.DeiTFeatureExtractor,DeiTImageProcessor:()=>l.DeiTImageProcessor,DetrFeatureExtractor:()=>c.DetrFeatureExtractor,DetrImageProcessor:()=>c.DetrImageProcessor,DonutFeatureExtractor:()=>u.DonutFeatureExtractor,DonutImageProcessor:()=>u.DonutImageProcessor,EfficientNetImageProcessor:()=>p.EfficientNetImageProcessor,GLPNFeatureExtractor:()=>_.GLPNFeatureExtractor,GroundingDinoImageProcessor:()=>h.GroundingDinoImageProcessor,Idefics3ImageProcessor:()=>g.Idefics3ImageProcessor,JinaCLIPImageProcessor:()=>M.JinaCLIPImageProcessor,LlavaOnevisionImageProcessor:()=>w.LlavaOnevisionImageProcessor,Mask2FormerImageProcessor:()=>T.Mask2FormerImageProcessor,MaskFormerFeatureExtractor:()=>P.MaskFormerFeatureExtractor,MaskFormerImageProcessor:()=>P.MaskFormerImageProcessor,MobileNetV1FeatureExtractor:()=>x.MobileNetV1FeatureExtractor,MobileNetV1ImageProcessor:()=>x.MobileNetV1ImageProcessor,MobileNetV2FeatureExtractor:()=>b.MobileNetV2FeatureExtractor,MobileNetV2ImageProcessor:()=>b.MobileNetV2ImageProcessor,MobileNetV3FeatureExtractor:()=>F.MobileNetV3FeatureExtractor,MobileNetV3ImageProcessor:()=>F.MobileNetV3ImageProcessor,MobileNetV4FeatureExtractor:()=>k.MobileNetV4FeatureExtractor,MobileNetV4ImageProcessor:()=>k.MobileNetV4ImageProcessor,MobileViTFeatureExtractor:()=>y.MobileViTFeatureExtractor,MobileViTImageProcessor:()=>y.MobileViTImageProcessor,NougatImageProcessor:()=>v.NougatImageProcessor,OwlViTFeatureExtractor:()=>S.OwlViTFeatureExtractor,OwlViTImageProcessor:()=>S.OwlViTImageProcessor,Owlv2ImageProcessor:()=>C.Owlv2ImageProcessor,Phi3VImageProcessor:()=>E.Phi3VImageProcessor,PixtralImageProcessor:()=>A.PixtralImageProcessor,PvtImageProcessor:()=>L.PvtImageProcessor,Qwen2VLImageProcessor:()=>I.Qwen2VLImageProcessor,RTDetrImageProcessor:()=>D.RTDetrImageProcessor,Sam2ImageProcessor:()=>j.Sam2ImageProcessor,Sam3ImageProcessor:()=>V.Sam3ImageProcessor,SamImageProcessor:()=>z.SamImageProcessor,SegformerFeatureExtractor:()=>O.SegformerFeatureExtractor,SegformerImageProcessor:()=>O.SegformerImageProcessor,SiglipImageProcessor:()=>N.SiglipImageProcessor,SmolVLMImageProcessor:()=>B.SmolVLMImageProcessor,Swin2SRImageProcessor:()=>G.Swin2SRImageProcessor,VLMImageProcessor:()=>f.VLMImageProcessor,ViTFeatureExtractor:()=>R.ViTFeatureExtractor,ViTImageProcessor:()=>R.ViTImageProcessor,VitMatteImageProcessor:()=>q.VitMatteImageProcessor,VitPoseImageProcessor:()=>$.VitPoseImageProcessor,YolosFeatureExtractor:()=>W.YolosFeatureExtractor,YolosImageProcessor:()=>W.YolosImageProcessor});var o=r("./src/models/beit/image_processing_beit.js"),s=r("./src/models/bit/image_processing_bit.js"),a=r("./src/models/chinese_clip/image_processing_chinese_clip.js"),i=r("./src/models/clip/image_processing_clip.js"),n=r("./src/models/convnext/image_processing_convnext.js"),l=r("./src/models/deit/image_processing_deit.js"),c=r("./src/models/detr/image_processing_detr.js"),d=r("./src/models/dinov3_vit/image_processing_dinov3_vit.js"),u=r("./src/models/donut/image_processing_donut.js"),m=r("./src/models/dpt/image_processing_dpt.js"),p=r("./src/models/efficientnet/image_processing_efficientnet.js"),_=r("./src/models/glpn/image_processing_glpn.js"),h=r("./src/models/grounding_dino/image_processing_grounding_dino.js"),g=r("./src/models/idefics3/image_processing_idefics3.js"),f=r("./src/models/janus/image_processing_janus.js"),M=r("./src/models/jina_clip/image_processing_jina_clip.js"),w=r("./src/models/llava_onevision/image_processing_llava_onevision.js"),T=r("./src/models/mask2former/image_processing_mask2former.js"),P=r("./src/models/maskformer/image_processing_maskformer.js"),x=r("./src/models/mobilenet_v1/image_processing_mobilenet_v1.js"),b=r("./src/models/mobilenet_v2/image_processing_mobilenet_v2.js"),F=r("./src/models/mobilenet_v3/image_processing_mobilenet_v3.js"),k=r("./src/models/mobilenet_v4/image_processing_mobilenet_v4.js"),y=r("./src/models/mobilevit/image_processing_mobilevit.js"),v=r("./src/models/nougat/image_processing_nougat.js"),C=r("./src/models/owlv2/image_processing_owlv2.js"),S=r("./src/models/owlvit/image_processing_owlvit.js"),E=r("./src/models/phi3_v/image_processing_phi3_v.js"),A=r("./src/models/pixtral/image_processing_pixtral.js"),L=r("./src/models/pvt/image_processing_pvt.js"),I=r("./src/models/qwen2_vl/image_processing_qwen2_vl.js"),D=r("./src/models/rt_detr/image_processing_rt_detr.js"),z=r("./src/models/sam/image_processing_sam.js"),j=r("./src/models/sam2/image_processing_sam2.js"),V=r("./src/models/sam3/image_processing_sam3.js"),O=r("./src/models/segformer/image_processing_segformer.js"),N=r("./src/models/siglip/image_processing_siglip.js"),B=r("./src/models/smolvlm/image_processing_smolvlm.js"),G=r("./src/models/swin2sr/image_processing_swin2sr.js"),R=r("./src/models/vit/image_processing_vit.js"),q=r("./src/models/vitmatte/image_processing_vitmatte.js"),$=r("./src/models/vitpose/image_processing_vitpose.js"),W=r("./src/models/yolos/image_processing_yolos.js")},"./src/models/janus/image_processing_janus.js":(e,t,r)=>{r.r(t),r.d(t,{VLMImageProcessor:()=>s});var o=r("./src/base/image_processors_utils.js");class s extends o.ImageProcessor{constructor(e){super({do_pad:!0,pad_size:{width:e.image_size,height:e.image_size},...e}),this.constant_values=this.config.background_color.map(e=>e*this.rescale_factor)}pad_image(e,t,r,o){return super.pad_image(e,t,r,{constant_values:this.constant_values,center:!0,...o})}}},"./src/models/janus/processing_janus.js":(e,t,r)=>{r.r(t),r.d(t,{VLChatProcessor:()=>c});var o=r("./src/base/processing_utils.js"),s=r("./src/models/auto/image_processing_auto.js"),a=r("./src/tokenizers.js"),i=r("./src/utils/core.js"),n=r("./src/utils/tensor.js"),l=r("./src/utils/image.js");class c extends o.Processor{static image_processor_class=s.AutoImageProcessor;static tokenizer_class=a.AutoTokenizer;static uses_processor_config=!0;constructor(e,t,r){super(e,t,r),this.image_tag=this.config.image_tag,this.image_start_tag=this.config.image_start_tag,this.image_end_tag=this.config.image_end_tag,this.num_image_tokens=this.config.num_image_tokens}async _call(e,{images:t=null,chat_template:r="default"}={}){t?Array.isArray(t)||(t=[t]):t=await Promise.all(e.filter(e=>e.images).flatMap(e=>e.images).map(e=>l.RawImage.read(e)));let o=this.tokenizer,s=o.apply_chat_template(e,{tokenize:!1,add_generation_prompt:!0,chat_template:r}),a=e=>o.encode(e,{add_special_tokens:!1}),c=s.split(this.image_tag),d=c.length-1;if(t.length!==d)throw Error(`Number of images provided (${t.length}) does not match number of "${this.image_tag}" image tags (${d})`);let[u,m,p]=o.model.convert_tokens_to_ids([this.image_tag,this.image_start_tag,this.image_end_tag]),_=a(c[0]),h=Array(_.length).fill(!1);for(let e=1;e<c.length;++e){let t=Array(this.num_image_tokens).fill(u),r=a(c[e]);_=(0,i.mergeArrays)(_,[m],t,[p],r);let o=Array(this.num_image_tokens).fill(!0);h=(0,i.mergeArrays)(h,[!1],o,[!1],Array(r.length).fill(!1))}let g=[1,_.length],f={input_ids:new n.Tensor("int64",_,g),attention_mask:new n.Tensor("int64",Array(_.length).fill(1),g),images_seq_mask:new n.Tensor("bool",h,g),images_emb_mask:new n.Tensor("bool",Array(d*this.num_image_tokens).fill(!0),[1,d,this.num_image_tokens])};if(t&&t.length>0){let e=await this.image_processor(t);return e.pixel_values.unsqueeze_(0),{...f,...e}}return f}}},"./src/models/jina_clip/image_processing_jina_clip.js":(e,t,r)=>{r.r(t),r.d(t,{JinaCLIPImageProcessor:()=>s});var o=r("./src/base/image_processors_utils.js");class s extends o.ImageProcessor{constructor(e){let{resize_mode:t,fill_color:r,interpolation:o,size:s,...a}=e;super({...a,size:"squash"===t?{width:s,height:s}:"shortest"===t?{shortest_edge:s}:{longest_edge:s},resample:"bicubic"===o?3:2,do_center_crop:!0,crop_size:s,do_normalize:!0})}}},"./src/models/jina_clip/processing_jina_clip.js":(e,t,r)=>{r.r(t),r.d(t,{JinaCLIPProcessor:()=>i});var o=r("./src/base/processing_utils.js"),s=r("./src/models/auto/image_processing_auto.js"),a=r("./src/tokenizers.js");class i extends o.Processor{static tokenizer_class=a.AutoTokenizer;static image_processor_class=s.AutoImageProcessor;async _call(e=null,t=null,r={}){if(!e&&!t)throw Error("Either text or images must be provided");let o=e?this.tokenizer(e,r):{},s=t?await this.image_processor(t,r):{};return{...o,...s}}}},"./src/models/llava/processing_llava.js":(e,t,r)=>{r.r(t),r.d(t,{LlavaProcessor:()=>i});var o=r("./src/base/processing_utils.js"),s=r("./src/models/auto/image_processing_auto.js"),a=r("./src/tokenizers.js");class i extends o.Processor{static tokenizer_class=a.AutoTokenizer;static image_processor_class=s.AutoImageProcessor;static uses_processor_config=!0;async _call(e,t=null,r={}){let o=await this.image_processor(e,r);if(t){let[e,r]=o.pixel_values.dims.slice(-2),{image_token:s,patch_size:a,num_additional_image_tokens:i}=this.config,n=Math.floor(e/a)*Math.floor(r/a)+i;Array.isArray(t=structuredClone(t))||(t=[t]);for(let e=0;e<t.length;++e)t[e]=t[e].replace(s,s.repeat(n))}let s=t?this.tokenizer(t,r):{};return{...o,...s}}}},"./src/models/llava_onevision/image_processing_llava_onevision.js":(e,t,r)=>{r.r(t),r.d(t,{LlavaOnevisionImageProcessor:()=>s});var o=r("./src/base/image_processors_utils.js");class s extends o.ImageProcessor{}},"./src/models/mask2former/image_processing_mask2former.js":(e,t,r)=>{r.r(t),r.d(t,{Mask2FormerImageProcessor:()=>s});var o=r("./src/models/maskformer/image_processing_maskformer.js");class s extends o.MaskFormerImageProcessor{}},"./src/models/maskformer/image_processing_maskformer.js":(e,t,r)=>{r.r(t),r.d(t,{MaskFormerFeatureExtractor:()=>a,MaskFormerImageProcessor:()=>s});var o=r("./src/base/image_processors_utils.js");class s extends o.ImageProcessor{post_process_panoptic_segmentation(...e){return(0,o.post_process_panoptic_segmentation)(...e)}post_process_instance_segmentation(...e){return(0,o.post_process_instance_segmentation)(...e)}}class a extends s{}},"./src/models/mgp_str/processing_mgp_str.js":(e,t,r)=>{r.r(t),r.d(t,{MgpstrProcessor:()=>l});var o=r("./src/base/processing_utils.js"),s=r("./src/models/auto/image_processing_auto.js"),a=r("./src/tokenizers.js"),i=r("./src/utils/maths.js");let n={char:["char_decode",1],bpe:["bpe_decode",2],wp:["wp_decode",102]};class l extends o.Processor{static tokenizer_class=a.AutoTokenizer;static image_processor_class=s.AutoImageProcessor;get char_tokenizer(){return this.components.char_tokenizer}get bpe_tokenizer(){return this.components.bpe_tokenizer}get wp_tokenizer(){return this.components.wp_tokenizer}_decode_helper(e,t){if(!n.hasOwnProperty(t))throw Error(`Format ${t} is not supported.`);let[r,o]=n[t],s=this[r].bind(this),[a,l]=e.dims,c=[],d=[],u=e.tolist();for(let e=0;e<a;++e){let t=u[e],r=[],s=[];for(let e=1;e<l;++e){let[a,n]=(0,i.max)((0,i.softmax)(t[e]));if(s.push(a),n==o)break;r.push(n)}let a=s.length>0?s.reduce((e,t)=>e*t,1):0;d.push(r),c.push(a)}return[s(d),c]}char_decode(e){return this.char_tokenizer.batch_decode(e).map(e=>e.replaceAll(" ",""))}bpe_decode(e){return this.bpe_tokenizer.batch_decode(e)}wp_decode(e){return this.wp_tokenizer.batch_decode(e).map(e=>e.replaceAll(" ",""))}batch_decode([e,t,r]){let[o,s]=this._decode_helper(e,"char"),[a,n]=this._decode_helper(t,"bpe"),[l,c]=this._decode_helper(r,"wp"),d=[],u=[];for(let e=0;e<o.length;++e){let[t,r]=(0,i.max)([s[e],n[e],c[e]]);d.push([o[e],a[e],l[e]][r]),u.push(t)}return{generated_text:d,scores:u,char_preds:o,bpe_preds:a,wp_preds:l}}static async from_pretrained(...e){let t=await super.from_pretrained(...e),r=await a.AutoTokenizer.from_pretrained("Xenova/gpt2"),o=await a.AutoTokenizer.from_pretrained("Xenova/bert-base-uncased");return t.components={image_processor:t.image_processor,char_tokenizer:t.tokenizer,bpe_tokenizer:r,wp_tokenizer:o},t}async _call(e,t=null){let r=await this.image_processor(e);return t&&(r.labels=this.tokenizer(t).input_ids),r}}},"./src/models/mobilenet_v1/image_processing_mobilenet_v1.js":(e,t,r)=>{r.r(t),r.d(t,{MobileNetV1FeatureExtractor:()=>a,MobileNetV1ImageProcessor:()=>s});var o=r("./src/base/image_processors_utils.js");class s extends o.ImageProcessor{}class a extends s{}},"./src/models/mobilenet_v2/image_processing_mobilenet_v2.js":(e,t,r)=>{r.r(t),r.d(t,{MobileNetV2FeatureExtractor:()=>a,MobileNetV2ImageProcessor:()=>s});var o=r("./src/base/image_processors_utils.js");class s extends o.ImageProcessor{}class a extends s{}},"./src/models/mobilenet_v3/image_processing_mobilenet_v3.js":(e,t,r)=>{r.r(t),r.d(t,{MobileNetV3FeatureExtractor:()=>a,MobileNetV3ImageProcessor:()=>s});var o=r("./src/base/image_processors_utils.js");class s extends o.ImageProcessor{}class a extends s{}},"./src/models/mobilenet_v4/image_processing_mobilenet_v4.js":(e,t,r)=>{r.r(t),r.d(t,{MobileNetV4FeatureExtractor:()=>a,MobileNetV4ImageProcessor:()=>s});var o=r("./src/base/image_processors_utils.js");class s extends o.ImageProcessor{}class a extends s{}},"./src/models/mobilevit/image_processing_mobilevit.js":(e,t,r)=>{r.r(t),r.d(t,{MobileViTFeatureExtractor:()=>a,MobileViTImageProcessor:()=>s});var o=r("./src/base/image_processors_utils.js");class s extends o.ImageProcessor{}class a extends s{}},"./src/models/moonshine/feature_extraction_moonshine.js":(e,t,r)=>{r.r(t),r.d(t,{MoonshineFeatureExtractor:()=>a});var o=r("./src/base/feature_extraction_utils.js"),s=r("./src/utils/tensor.js");class a extends o.FeatureExtractor{async _call(e){(0,o.validate_audio_inputs)(e,"MoonshineFeatureExtractor"),e instanceof Float64Array&&(e=new Float32Array(e));let t=[1,e.length];return{input_values:new s.Tensor("float32",e,t)}}}},"./src/models/moonshine/processing_moonshine.js":(e,t,r)=>{r.r(t),r.d(t,{MoonshineProcessor:()=>i});var o=r("./src/models/auto/feature_extraction_auto.js"),s=r("./src/tokenizers.js"),a=r("./src/base/processing_utils.js");class i extends a.Processor{static tokenizer_class=s.AutoTokenizer;static feature_extractor_class=o.AutoFeatureExtractor;async _call(e){return await this.feature_extractor(e)}}},"./src/models/nougat/image_processing_nougat.js":(e,t,r)=>{r.r(t),r.d(t,{NougatImageProcessor:()=>s});var o=r("./src/models/donut/image_processing_donut.js");class s extends o.DonutImageProcessor{}},"./src/models/owlv2/image_processing_owlv2.js":(e,t,r)=>{r.r(t),r.d(t,{Owlv2ImageProcessor:()=>s});var o=r("./src/models/owlvit/image_processing_owlvit.js");class s extends o.OwlViTImageProcessor{}},"./src/models/owlvit/image_processing_owlvit.js":(e,t,r)=>{r.r(t),r.d(t,{OwlViTFeatureExtractor:()=>a,OwlViTImageProcessor:()=>s});var o=r("./src/base/image_processors_utils.js");class s extends o.ImageProcessor{post_process_object_detection(...e){return(0,o.post_process_object_detection)(...e)}}class a extends s{}},"./src/models/owlvit/processing_owlvit.js":(e,t,r)=>{r.r(t),r.d(t,{OwlViTProcessor:()=>i});var o=r("./src/base/processing_utils.js"),s=r("./src/models/auto/image_processing_auto.js"),a=r("./src/tokenizers.js");class i extends o.Processor{static tokenizer_class=a.AutoTokenizer;static image_processor_class=s.AutoImageProcessor}},"./src/models/paligemma/processing_paligemma.js":(e,t,r)=>{r.r(t),r.d(t,{PaliGemmaProcessor:()=>n});var o=r("./src/base/processing_utils.js"),s=r("./src/models/auto/image_processing_auto.js"),a=r("./src/tokenizers.js");let i="<image>";class n extends o.Processor{static tokenizer_class=a.AutoTokenizer;static image_processor_class=s.AutoImageProcessor;static uses_processor_config=!1;async _call(e,t=null,r={}){let o;t||(console.warn("You are using PaliGemma without a text prefix. It will perform as a picture-captioning model."),t=""),Array.isArray(e)||(e=[e]),Array.isArray(t)||(t=[t]);let s=this.tokenizer.bos_token,a=this.image_processor.config.image_seq_length;t.some(e=>e.includes(i))?o=t.map(e=>{let t=e.replaceAll(i,i.repeat(a)),r=t.lastIndexOf(i),o=-1===r?0:r+i.length;return t.slice(0,o)+s+t.slice(o)+"\n"}):(console.warn("You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens."),o=t.map(t=>{var r;return r=e.length,`${i.repeat(a*r)}${s}${t}
`}));let n=this.tokenizer(o,r);return{...await this.image_processor(e,r),...n}}}},"./src/models/parakeet/feature_extraction_parakeet.js":(e,t,r)=>{r.r(t),r.d(t,{ParakeetFeatureExtractor:()=>i});var o=r("./src/base/feature_extraction_utils.js"),s=r("./src/utils/tensor.js"),a=r("./src/utils/audio.js");class i extends o.FeatureExtractor{constructor(e){super(e),this.config.mel_filters??=(0,a.mel_filter_bank)(Math.floor(1+this.config.n_fft/2),this.config.feature_size,0,this.config.sampling_rate/2,this.config.sampling_rate,"slaney","slaney");let t=(0,a.window_function)(this.config.win_length,"hann",{periodic:!1});this.window=new Float64Array(this.config.n_fft);let r=Math.floor((this.config.n_fft-this.config.win_length)/2);this.window.set(t,r)}async _extract_fbank_features(e){let t=this.config.preemphasis;e=new Float64Array(e);for(let r=e.length-1;r>=1;--r)e[r]-=t*e[r-1];return await (0,a.spectrogram)(e,this.window,this.window.length,this.config.hop_length,{fft_length:this.config.n_fft,power:2,mel_filters:this.config.mel_filters,log_mel:"log",mel_floor:-1/0,pad_mode:"constant",center:!0,transpose:!0,mel_offset:5960464477539063e-23})}async _call(e){(0,o.validate_audio_inputs)(e,"ParakeetFeatureExtractor");let t=await this._extract_fbank_features(e),r=Math.floor((e.length+2*Math.floor(this.config.n_fft/2)-this.config.n_fft)/this.config.hop_length),a=t.data;a.fill(0,r*t.dims[1]);let[i,n]=t.dims,l=new Float64Array(n),c=new Float64Array(n);for(let e=0;e<r;++e){let t=e*n;for(let e=0;e<n;++e){let r=a[t+e];l[e]+=r,c[e]+=r*r}}let d=r>1?r-1:1;for(let e=0;e<n;++e){let t=l[e]/r,o=1/(Math.sqrt((c[e]-r*t*t)/d)+1e-5);for(let s=0;s<r;++s){let r=s*n+e;a[r]=(a[r]-t)*o}}let u=new BigInt64Array(i);return u.fill(1n,0,r),{input_features:t.unsqueeze_(0),attention_mask:new s.Tensor("int64",u,[1,i])}}}},"./src/models/phi3_v/image_processing_phi3_v.js":(e,t,r)=>{r.r(t),r.d(t,{Phi3VImageProcessor:()=>c});var o=r("./src/base/image_processors_utils.js"),s=r("./src/utils/tensor.js");let a=[2,3],{ceil:i,floor:n,sqrt:l}=Math;class c extends o.ImageProcessor{constructor(e){super({...e,do_normalize:!0,do_pad:!0,pad_size:"custom",do_convert_rgb:!0,do_resize:!0}),this._num_crops=e.num_crops}calc_num_image_tokens_from_image_size(e,t){let{num_img_tokens:r}=this.config;return n((n(t/336)*n(e/336)+1)*r+1+(n(t/336)+1)*l(r))}get_resize_output_image_size(e,t){let r=this._num_crops,[o,s]=e.size,a=o/s,i=1;for(;i*Math.ceil(i/a)<=r;)i+=1;let n=Math.floor(336*(i-=1)),l=Math.floor(n/a);return[n,l]}pad_image(e,t,r,o={}){let[s,a]=t,n=336*i(s/336),l=336*i(a/336),c=[1,1,1].map((e,t)=>(e-this.image_mean[t])/this.image_std[t]);return super.pad_image(e,t,{width:l,height:n},{center:!0,constant_values:c,...o})}async _call(e,{num_crops:t=null}={}){if(this._num_crops=t??=this.config.num_crops,t<4||l(t)%1!=0)throw Error("num_crops must be a square number >= 4");Array.isArray(e)||(e=[e]);let r=e.length,o=await Promise.all(e.map(e=>this.preprocess(e))),c=o.map(e=>e.original_size),d=o.map(e=>e.reshaped_input_size),u=[];for(let{pixel_values:e}of o){e.unsqueeze_(0);let[r,o]=e.dims.slice(-2),i=await (0,s.interpolate_4d)(e,{size:[336,336],mode:"bicubic"});if(t>0){let c=[],d=l(t),m=n(o/d),p=n(r/d);for(let t=0;t<d;++t)for(let i=0;i<d;++i){let n,l,u,_;t===d-1?(l=r-p,_=r):(l=t*p,_=(t+1)*p),i===d-1?(n=o-m,u=o):(n=i*m,u=(i+1)*m);let h=[l,n],g=[_,u],f=await (0,s.slice)(e,h,g,a);c.push(f)}let _=await (0,s.interpolate_4d)((0,s.cat)(c,0),{size:[336,336],mode:"bicubic"});u.push((0,s.cat)([i,_],0))}else u.push(i)}let m=(0,s.stack)(u,0),p=d.map(e=>e.map(e=>336*i(e/336)));return{pixel_values:m,original_sizes:c,reshaped_input_sizes:d,image_sizes:new s.Tensor("int64",p.flat(),[r,2]),num_img_tokens:p.map(([e,t])=>this.calc_num_image_tokens_from_image_size(t,e))}}}},"./src/models/phi3_v/processing_phi3_v.js":(e,t,r)=>{r.r(t),r.d(t,{Phi3VProcessor:()=>l});var o=r("./src/base/processing_utils.js"),s=r("./src/models/auto/image_processing_auto.js"),a=r("./src/tokenizers.js");r("./src/utils/image.js");let i="<|image|>",n=/<\|image_\d+\|>/g;class l extends o.Processor{static image_processor_class=s.AutoImageProcessor;static tokenizer_class=a.AutoTokenizer;async _call(e,t=null,{padding:r=!0,truncation:o=!0,num_crops:s=null}={}){let a,l;if(Array.isArray(e)||(e=[e]),t){let{num_img_tokens:c}=l=await this.image_processor(t,{num_crops:s}),d=e.map((e,t)=>e.split(n).join(i.repeat(c[t])));a=this.tokenizer(d,{padding:r,truncation:o});let u=this.tokenizer.model.convert_tokens_to_ids([i])[0];a.input_ids.map_(e=>e==u?-e:e)}else a=this.tokenizer(e);return{...a,...l}}}},"./src/models/pixtral/image_processing_pixtral.js":(e,t,r)=>{r.r(t),r.d(t,{PixtralImageProcessor:()=>s});var o=r("./src/base/image_processors_utils.js");class s extends o.ImageProcessor{get_resize_output_image_size(e,t){let{longest_edge:r}=t;if(void 0===r)throw Error("size must contain 'longest_edge'");let[o,s]=e.size,a=Math.max(o,s)/r,i=o,n=s;a>1&&(i=Math.floor(o/a),n=Math.floor(s/a));let{patch_size:l,spatial_merge_size:c}=this.config;if(!c)throw Error("config must contain 'spatial_merge_size'");let d=l*c,u=Math.floor((i-1)/d)+1,m=Math.floor((n-1)/d)+1;return[u*d,m*d]}}},"./src/models/pixtral/processing_pixtral.js":(e,t,r)=>{r.r(t),r.d(t,{PixtralProcessor:()=>i});var o=r("./src/base/processing_utils.js"),s=r("./src/models/auto/image_processing_auto.js"),a=r("./src/tokenizers.js");class i extends o.Processor{static tokenizer_class=a.AutoTokenizer;static image_processor_class=s.AutoImageProcessor;static uses_processor_config=!0;async _call(e,t=null,r={}){let o=await this.image_processor(e,r);if(t){let[e,r]=o.pixel_values.dims.slice(-2),{image_token:s,image_break_token:a,image_end_token:i,patch_size:n,spatial_merge_size:l}=this.config,c=n*l,d=Math.floor(e/c),u=Math.floor(r/c);Array.isArray(t=structuredClone(t))||(t=[t]);for(let e=0;e<t.length;++e){let r=s.repeat(u),o=r+a,n=r+i,l=o.repeat(d-1)+n;t[e]=t[e].replace(s,l)}}let s=t?this.tokenizer(t,r):{};return{...o,...s}}}},"./src/models/processors.js":(e,t,r)=>{r.r(t),r.d(t,{Florence2Processor:()=>o.Florence2Processor,Gemma3nProcessor:()=>s.Gemma3nProcessor,GroundingDinoProcessor:()=>a.GroundingDinoProcessor,Idefics3Processor:()=>i.Idefics3Processor,JinaCLIPProcessor:()=>l.JinaCLIPProcessor,LlavaProcessor:()=>c.LlavaProcessor,MgpstrProcessor:()=>d.MgpstrProcessor,MoonshineProcessor:()=>u.MoonshineProcessor,OwlViTProcessor:()=>m.OwlViTProcessor,PaliGemmaProcessor:()=>p.PaliGemmaProcessor,Phi3VProcessor:()=>_.Phi3VProcessor,PixtralProcessor:()=>h.PixtralProcessor,PyAnnoteProcessor:()=>g.PyAnnoteProcessor,Qwen2VLProcessor:()=>f.Qwen2VLProcessor,Sam2Processor:()=>w.Sam2Processor,Sam2VideoProcessor:()=>w.Sam2VideoProcessor,SamProcessor:()=>M.SamProcessor,SmolVLMProcessor:()=>T.SmolVLMProcessor,SpeechT5Processor:()=>P.SpeechT5Processor,UltravoxProcessor:()=>x.UltravoxProcessor,VLChatProcessor:()=>n.VLChatProcessor,VoxtralProcessor:()=>b.VoxtralProcessor,Wav2Vec2Processor:()=>F.Wav2Vec2Processor,Wav2Vec2ProcessorWithLM:()=>k.Wav2Vec2ProcessorWithLM,WhisperProcessor:()=>y.WhisperProcessor});var o=r("./src/models/florence2/processing_florence2.js"),s=r("./src/models/gemma3n/processing_gemma3n.js"),a=r("./src/models/grounding_dino/processing_grounding_dino.js"),i=r("./src/models/idefics3/processing_idefics3.js"),n=r("./src/models/janus/processing_janus.js"),l=r("./src/models/jina_clip/processing_jina_clip.js"),c=r("./src/models/llava/processing_llava.js"),d=r("./src/models/mgp_str/processing_mgp_str.js"),u=r("./src/models/moonshine/processing_moonshine.js"),m=r("./src/models/owlvit/processing_owlvit.js"),p=r("./src/models/paligemma/processing_paligemma.js"),_=r("./src/models/phi3_v/processing_phi3_v.js"),h=r("./src/models/pixtral/processing_pixtral.js"),g=r("./src/models/pyannote/processing_pyannote.js"),f=r("./src/models/qwen2_vl/processing_qwen2_vl.js"),M=r("./src/models/sam/processing_sam.js"),w=r("./src/models/sam2/processing_sam2.js"),T=r("./src/models/smolvlm/processing_smolvlm.js"),P=r("./src/models/speecht5/processing_speecht5.js"),x=r("./src/models/ultravox/processing_ultravox.js"),b=r("./src/models/voxtral/processing_voxtral.js"),F=r("./src/models/wav2vec2/processing_wav2vec2.js"),k=r("./src/models/wav2vec2_with_lm/processing_wav2vec2_with_lm.js"),y=r("./src/models/whisper/processing_whisper.js")},"./src/models/pvt/image_processing_pvt.js":(e,t,r)=>{r.r(t),r.d(t,{PvtImageProcessor:()=>s});var o=r("./src/base/image_processors_utils.js");class s extends o.ImageProcessor{}},"./src/models/pyannote/feature_extraction_pyannote.js":(e,t,r)=>{r.r(t),r.d(t,{PyAnnoteFeatureExtractor:()=>i});var o=r("./src/base/feature_extraction_utils.js"),s=r("./src/utils/tensor.js"),a=r("./src/utils/maths.js");class i extends o.FeatureExtractor{async _call(e){(0,o.validate_audio_inputs)(e,"PyAnnoteFeatureExtractor"),e instanceof Float64Array&&(e=new Float32Array(e));let t=[1,1,e.length];return{input_values:new s.Tensor("float32",e,t)}}samples_to_frames(e){return(e-this.config.offset)/this.config.step}post_process_speaker_diarization(e,t){let r=t/this.samples_to_frames(t)/this.config.sampling_rate,o=[];for(let t of e.tolist()){let e=[],s=-1;for(let r=0;r<t.length;++r){let o=(0,a.softmax)(t[r]),[i,n]=(0,a.max)(o),[l,c]=[r,r+1];n!==s?(s=n,e.push({id:n,start:l,end:c,score:i})):(e.at(-1).end=c,e.at(-1).score+=i)}o.push(e.map(({id:e,start:t,end:o,score:s})=>({id:e,start:t*r,end:o*r,confidence:s/(o-t)})))}return o}}},"./src/models/pyannote/processing_pyannote.js":(e,t,r)=>{r.r(t),r.d(t,{PyAnnoteProcessor:()=>a});var o=r("./src/base/processing_utils.js"),s=r("./src/models/pyannote/feature_extraction_pyannote.js");class a extends o.Processor{static feature_extractor_class=s.PyAnnoteFeatureExtractor;async _call(e){return await this.feature_extractor(e)}post_process_speaker_diarization(...e){return this.feature_extractor.post_process_speaker_diarization(...e)}get sampling_rate(){return this.feature_extractor.config.sampling_rate}}},"./src/models/qwen2_vl/image_processing_qwen2_vl.js":(e,t,r)=>{r.r(t),r.d(t,{Qwen2VLImageProcessor:()=>a});var o=r("./src/base/image_processors_utils.js"),s=r("./src/utils/tensor.js");class a extends o.ImageProcessor{async _call(e,...t){let{pixel_values:r,original_sizes:o,reshaped_input_sizes:a}=await super._call(e,...t),i=r,{temporal_patch_size:n,merge_size:l,patch_size:c}=this.config;1===i.dims[0]&&(i=(0,s.cat)(Array.from({length:n},()=>i),0));let d=i.dims[0]/n,u=i.dims[1],m=Math.floor(i.dims[2]/c),p=Math.floor(i.dims[3]/c);return{pixel_values:i.view(d,n,u,Math.floor(m/l),l,c,Math.floor(p/l),l,c).permute(0,3,6,4,7,2,1,5,8).view(d*m*p,u*n*c*c),image_grid_thw:new s.Tensor("int64",[d,m,p],[1,3]),original_sizes:o,reshaped_input_sizes:a}}}},"./src/models/qwen2_vl/processing_qwen2_vl.js":(e,t,r)=>{r.r(t),r.d(t,{Qwen2VLProcessor:()=>i});var o=r("./src/base/processing_utils.js"),s=r("./src/models/auto/image_processing_auto.js"),a=r("./src/tokenizers.js");r("./src/utils/image.js");class i extends o.Processor{static image_processor_class=s.AutoImageProcessor;static tokenizer_class=a.AutoTokenizer;async _call(e,t=null,...r){let o,s;if(Array.isArray(e)||(e=[e]),t&&(s=(o=await this.image_processor(t)).image_grid_thw),s){let t=this.image_processor.config.merge_size**2,r=0,o=s.tolist();e=e.map(e=>{for(;e.includes("<|image_pad|>");){let s=Number(o[r++].reduce((e,t)=>e*t,1n));e=e.replace("<|image_pad|>","<|placeholder|>".repeat(Math.floor(s/t)))}return e.replaceAll("<|placeholder|>","<|image_pad|>")})}return{...this.tokenizer(e),...o}}}},"./src/models/rt_detr/image_processing_rt_detr.js":(e,t,r)=>{r.r(t),r.d(t,{RTDetrImageProcessor:()=>s});var o=r("./src/base/image_processors_utils.js");class s extends o.ImageProcessor{post_process_object_detection(...e){return(0,o.post_process_object_detection)(...e)}}},"./src/models/sam/image_processing_sam.js":(e,t,r)=>{r.r(t),r.d(t,{SamImageProcessor:()=>i});var o=r("./src/base/image_processors_utils.js"),s=r("./src/utils/core.js"),a=r("./src/utils/tensor.js");class i extends o.ImageProcessor{reshape_input_points(e,t,r,o=!1){e=structuredClone(e);let i=(0,s.calculateDimensions)(e);if(3===i.length)o||(i=[1,...i]),e=[e];else if(4!==i.length)throw Error("The input_points must be a 4D tensor of shape `batch_size`, `point_batch_size`, `nb_points_per_image`, `2`.");for(let o=0;o<e.length;++o){let[s,a]=t[o],[i,n]=r[o],l=[n/a,i/s];for(let t=0;t<e[o].length;++t)for(let r=0;r<e[o][t].length;++r)for(let s=0;s<e[o][t][r].length;++s)e[o][t][r][s]*=l[s%2]}return new a.Tensor("float32",Float32Array.from(e.flat(1/0)),i)}add_input_labels(e,t){let r=(0,s.calculateDimensions)(e);if(2===r.length)r=[1,...r],e=[e];else if(3!==r.length)throw Error("The input_points must be a 4D tensor of shape `batch_size`, `point_batch_size`, `nb_points_per_image`, `2`.");if(r.some((e,r)=>e!==t.dims[r]))throw Error(`The first ${r.length} dimensions of 'input_points' and 'input_labels' must be the same.`);return new a.Tensor("int64",e.flat(1/0).map(BigInt),r)}async _call(e,{input_points:t=null,input_labels:r=null,input_boxes:o=null}={}){let s=await super._call(e);if(t&&(s.input_points=this.reshape_input_points(t,s.original_sizes,s.reshaped_input_sizes)),r){if(!s.input_points)throw Error("`input_points` must be provided if `input_labels` are provided.");s.input_labels=this.add_input_labels(r,s.input_points)}return o&&(s.input_boxes=this.reshape_input_points(o,s.original_sizes,s.reshaped_input_sizes,!0)),s}async post_process_masks(e,t,r,{mask_threshold:o=0,binarize:s=!0,pad_size:i=null}={}){let n=[],l=[(i=i??this.pad_size??this.size).height,i.width];for(let i=0;i<t.length;++i){let c=t[i],d=r[i],u=await (0,a.interpolate_4d)(e[i],{mode:"bilinear",size:l});if(u=u.slice(null,null,[0,d[0]],[0,d[1]]),u=await (0,a.interpolate_4d)(u,{mode:"bilinear",size:c}),s){let e=u.data,t=new Uint8Array(e.length);for(let r=0;r<e.length;++r)e[r]>o&&(t[r]=1);u=new a.Tensor("bool",t,u.dims)}n.push(u)}return n}generate_crop_boxes(e,t,{crop_n_layers:r=0,overlap_ratio:o=512/1500,points_per_crop:s=32,crop_n_points_downscale_factor:a=1}={}){}}},"./src/models/sam/processing_sam.js":(e,t,r)=>{r.r(t),r.d(t,{SamProcessor:()=>a});var o=r("./src/base/processing_utils.js"),s=r("./src/models/auto/image_processing_auto.js");class a extends o.Processor{static image_processor_class=s.AutoImageProcessor;async _call(...e){return await this.image_processor(...e)}post_process_masks(...e){return this.image_processor.post_process_masks(...e)}reshape_input_points(...e){return this.image_processor.reshape_input_points(...e)}}},"./src/models/sam2/image_processing_sam2.js":(e,t,r)=>{r.r(t),r.d(t,{Sam2ImageProcessor:()=>o.SamImageProcessor});var o=r("./src/models/sam/image_processing_sam.js")},"./src/models/sam2/processing_sam2.js":(e,t,r)=>{r.r(t),r.d(t,{Sam2Processor:()=>s,Sam2VideoProcessor:()=>a});var o=r("./src/models/sam/processing_sam.js");class s extends o.SamProcessor{}class a extends s{}},"./src/models/sam3/image_processing_sam3.js":(e,t,r)=>{r.r(t),r.d(t,{Sam3ImageProcessor:()=>o.Sam2ImageProcessor});var o=r("./src/models/sam2/image_processing_sam2.js")},"./src/models/seamless_m4t/feature_extraction_seamless_m4t.js":(e,t,r)=>{r.r(t),r.d(t,{SeamlessM4TFeatureExtractor:()=>i});var o=r("./src/base/feature_extraction_utils.js"),s=r("./src/utils/tensor.js"),a=r("./src/utils/audio.js");class i extends o.FeatureExtractor{constructor(e){super(e);let t=this.config.sampling_rate,r=(0,a.mel_filter_bank)(257,this.config.num_mel_bins,20,Math.floor(t/2),t,null,"kaldi",!0);this.mel_filters=r,this.window=(0,a.window_function)(400,"povey",{periodic:!1})}async _extract_fbank_features(e,t){return e=e.map(e=>32768*e),(0,a.spectrogram)(e,this.window,400,160,{fft_length:512,power:2,center:!1,preemphasis:.97,mel_filters:this.mel_filters,log_mel:"log",mel_floor:1192092955078125e-22,remove_dc_offset:!0,max_num_frames:t,transpose:!0})}async _call(e,{padding:t=!0,pad_to_multiple_of:r=2,do_normalize_per_mel_bins:a=!0,return_attention_mask:i=!0}={}){let n;(0,o.validate_audio_inputs)(e,"SeamlessM4TFeatureExtractor");let l=await this._extract_fbank_features(e,this.config.max_length);if(a){let[e,t]=l.dims,r=l.data;for(let o=0;o<t;++o){let s=0;for(let a=0;a<e;++a)s+=r[a*t+o];let a=s/e,i=0;for(let s=0;s<e;++s)i+=(r[s*t+o]-a)**2;let n=Math.sqrt((i/=e-1)+1e-7);for(let s=0;s<e;++s){let e=s*t+o;r[e]=(r[e]-a)/n}}}if(t){let[e,t]=l.dims,o=l.data,a=e%r;if(a>0){let r=new Float32Array(t*(e+a));r.set(o),r.fill(this.config.padding_value,o.length);let c=e+a;l=new s.Tensor(l.type,r,[c,t]),i&&(n=new s.Tensor("int64",new BigInt64Array(c),[1,c])).data.fill(1n,0,e)}}let[c,d]=l.dims,u=this.config.stride;if(0!=c%u)throw Error(`The number of frames (${c}) must be a multiple of the stride (${u}).`);let m=l.view(1,Math.floor(c/u),d*u),p={input_features:m};if(i){let e=m.dims[1],t=new BigInt64Array(e);if(n){let e=n.data;for(let r=1,o=0;r<c;r+=u,++o)t[o]=e[r]}else t.fill(1n);p.attention_mask=new s.Tensor("int64",t,[1,e])}return p}}},"./src/models/segformer/image_processing_segformer.js":(e,t,r)=>{r.r(t),r.d(t,{SegformerFeatureExtractor:()=>a,SegformerImageProcessor:()=>s});var o=r("./src/base/image_processors_utils.js");class s extends o.ImageProcessor{post_process_semantic_segmentation(...e){return(0,o.post_process_semantic_segmentation)(...e)}}class a extends s{}},"./src/models/siglip/image_processing_siglip.js":(e,t,r)=>{r.r(t),r.d(t,{SiglipImageProcessor:()=>s});var o=r("./src/base/image_processors_utils.js");class s extends o.ImageProcessor{}},"./src/models/smolvlm/image_processing_smolvlm.js":(e,t,r)=>{r.r(t),r.d(t,{SmolVLMImageProcessor:()=>o.Idefics3ImageProcessor});var o=r("./src/models/idefics3/image_processing_idefics3.js")},"./src/models/smolvlm/processing_smolvlm.js":(e,t,r)=>{r.r(t),r.d(t,{SmolVLMProcessor:()=>o.Idefics3Processor});var o=r("./src/models/idefics3/processing_idefics3.js")},"./src/models/snac/feature_extraction_snac.js":(e,t,r)=>{r.r(t),r.d(t,{SnacFeatureExtractor:()=>s});var o=r("./src/models/dac/feature_extraction_dac.js");class s extends o.DacFeatureExtractor{}},"./src/models/speecht5/feature_extraction_speecht5.js":(e,t,r)=>{r.r(t),r.d(t,{SpeechT5FeatureExtractor:()=>s});var o=r("./src/base/feature_extraction_utils.js");class s extends o.FeatureExtractor{}},"./src/models/speecht5/processing_speecht5.js":(e,t,r)=>{r.r(t),r.d(t,{SpeechT5Processor:()=>i});var o=r("./src/base/processing_utils.js"),s=r("./src/tokenizers.js"),a=r("./src/models/auto/feature_extraction_auto.js");class i extends o.Processor{static tokenizer_class=s.AutoTokenizer;static feature_extractor_class=a.AutoFeatureExtractor;async _call(e){return await this.feature_extractor(e)}}},"./src/models/swin2sr/image_processing_swin2sr.js":(e,t,r)=>{r.r(t),r.d(t,{Swin2SRImageProcessor:()=>s});var o=r("./src/base/image_processors_utils.js");class s extends o.ImageProcessor{pad_image(e,t,r,o={}){let[s,a,i]=t;return super.pad_image(e,t,{width:a+(r-a%r)%r,height:s+(r-s%r)%r},{mode:"symmetric",center:!1,constant_values:-1,...o})}}},"./src/models/ultravox/processing_ultravox.js":(e,t,r)=>{r.r(t),r.d(t,{UltravoxProcessor:()=>i});var o=r("./src/models/auto/feature_extraction_auto.js"),s=r("./src/tokenizers.js"),a=r("./src/base/processing_utils.js");class i extends a.Processor{static tokenizer_class=s.AutoTokenizer;static feature_extractor_class=o.AutoFeatureExtractor;static uses_processor_config=!0;async _call(e,t=null,r={}){if(Array.isArray(e))throw Error("Batched inputs are not supported yet.");let o={};if(t){let s=t.length,{input_features:a}=await this.feature_extractor(t,{...r,max_length:s}),i=1+Math.ceil(Math.round(s/this.config.encoder_ds_factor+1e-4)/this.config.stack_factor);o.audio_token_len=[i],o.audio_values=a;let n=this.config.audio_placeholder;if(!e.includes(n))throw Error(`The input text does not contain the image token ${n}.`);e=e.replaceAll(n,n.repeat(i))}return{...this.tokenizer(e,{add_special_tokens:!1,...r}),...o}}}},"./src/models/vit/image_processing_vit.js":(e,t,r)=>{r.r(t),r.d(t,{ViTFeatureExtractor:()=>a,ViTImageProcessor:()=>s});var o=r("./src/base/image_processors_utils.js");class s extends o.ImageProcessor{}class a extends s{}},"./src/models/vitmatte/image_processing_vitmatte.js":(e,t,r)=>{r.r(t),r.d(t,{VitMatteImageProcessor:()=>a});var o=r("./src/base/image_processors_utils.js"),s=r("./src/utils/tensor.js");class a extends o.ImageProcessor{async _call(e,t){Array.isArray(e)||(e=[e]),Array.isArray(t)||(t=[t]);let r=await Promise.all(e.map(e=>this.preprocess(e))),o=await Promise.all(t.map(e=>this.preprocess(e,{do_normalize:!1,do_convert_rgb:!1,do_convert_grayscale:!0})));return{pixel_values:(0,s.stack)(r.map((e,t)=>(0,s.cat)([e.pixel_values,o[t].pixel_values],0)),0),original_sizes:r.map(e=>e.original_size),reshaped_input_sizes:r.map(e=>e.reshaped_input_size)}}}},"./src/models/vitpose/image_processing_vitpose.js":(e,t,r)=>{r.r(t),r.d(t,{VitPoseImageProcessor:()=>s});var o=r("./src/base/image_processors_utils.js");class s extends o.ImageProcessor{post_process_pose_estimation(e,t,{threshold:r=null}={}){let o=e.tolist(),[s,a,i,n]=e.dims,l=[];for(let e=0;e<s;++e){let s=o[e],a=t[e],c=[];for(let e=0;e<a.length;++e){let t=a[e],o=[],l=[],d=[],u=t.at(-2)/n,m=t.at(-1)/i;for(let e=0;e<s.length;++e){let[t,a]=[0,0],i=0,n=-1/0,c=s[e];for(let e=0;e<c.length;++e){let r=c[e];for(let o=0;o<r.length;++o){let s=r[o];i+=s,n=Math.max(n,s),t+=(o+.5)*s,a+=e*s}}if(null!=r&&n<r)continue;let p=[u*t/i,m*a/i];o.push(p),d.push(e),l.push(n)}c.push({bbox:t,scores:l,labels:d,keypoints:o})}l.push(c)}return l}}},"./src/models/voxtral/processing_voxtral.js":(e,t,r)=>{r.r(t),r.d(t,{VoxtralProcessor:()=>l});var o=r("./src/models/auto/feature_extraction_auto.js"),s=r("./src/tokenizers.js"),a=r("./src/base/processing_utils.js"),i=r("./src/utils/tensor.js");let n="[AUDIO]";class l extends a.Processor{static tokenizer_class=s.AutoTokenizer;static feature_extractor_class=o.AutoFeatureExtractor;static uses_processor_config=!1;async _call(e,t=null,r={}){if(Array.isArray(e))throw Error("Batched inputs are not supported yet.");let o={};if(t){if(!e.includes(n))throw Error(`The input text does not contain the audio token ${n}.`);Array.isArray(t)||(t=[t]);let s=e.split(n),a=s.length-1;if(a!==t.length)throw Error(`The number of audio inputs (${t.length}) does not match the number of audio tokens in the text (${a}).`);let l=this.feature_extractor.config.n_samples,c=t.map(e=>(function(e,t){let r=[];for(let o=0;o<e.length;o+=t)r.push(e.subarray(o,Math.min(o+t,e.length)));return r})(e,l)),d=c.map(e=>e.length),u=c.flat(),m=(await Promise.all(u.map(e=>this.feature_extractor(e,r)))).map(e=>e.input_features);o.audio_values=m.length>1?(0,i.cat)(m,0):m[0];let p=s[0];for(let e=0;e<d.length;++e){p+="[BEGIN_AUDIO]";for(let t=0;t<d[e];++t)p+=n.repeat(375);p+=s[e+1]}e=p}return{...this.tokenizer(e,{add_special_tokens:!1,...r}),...o}}}},"./src/models/wav2vec2/feature_extraction_wav2vec2.js":(e,t,r)=>{r.r(t),r.d(t,{Wav2Vec2FeatureExtractor:()=>a});var o=r("./src/base/feature_extraction_utils.js"),s=r("./src/utils/tensor.js");class a extends o.FeatureExtractor{_zero_mean_unit_var_norm(e){let t=e.reduce((e,t)=>e+t,0)/e.length,r=e.reduce((e,r)=>e+(r-t)**2,0)/e.length;return e.map(e=>(e-t)/Math.sqrt(r+1e-7))}async _call(e){(0,o.validate_audio_inputs)(e,"Wav2Vec2FeatureExtractor"),e instanceof Float64Array&&(e=new Float32Array(e));let t=e;this.config.do_normalize&&(t=this._zero_mean_unit_var_norm(t));let r=[1,t.length];return{input_values:new s.Tensor("float32",t,r),attention_mask:new s.Tensor("int64",new BigInt64Array(t.length).fill(1n),r)}}}},"./src/models/wav2vec2/processing_wav2vec2.js":(e,t,r)=>{r.r(t),r.d(t,{Wav2Vec2Processor:()=>i});var o=r("./src/tokenizers.js"),s=r("./src/models/auto/feature_extraction_auto.js"),a=r("./src/base/processing_utils.js");class i extends a.Processor{static tokenizer_class=o.AutoTokenizer;static feature_extractor_class=s.AutoFeatureExtractor;async _call(e){return await this.feature_extractor(e)}}},"./src/models/wav2vec2_with_lm/processing_wav2vec2_with_lm.js":(e,t,r)=>{r.r(t),r.d(t,{Wav2Vec2ProcessorWithLM:()=>i});var o=r("./src/tokenizers.js"),s=r("./src/models/auto/feature_extraction_auto.js"),a=r("./src/base/processing_utils.js");class i extends a.Processor{static tokenizer_class=o.AutoTokenizer;static feature_extractor_class=s.AutoFeatureExtractor;async _call(e){return await this.feature_extractor(e)}}},"./src/models/wespeaker/feature_extraction_wespeaker.js":(e,t,r)=>{r.r(t),r.d(t,{WeSpeakerFeatureExtractor:()=>a});var o=r("./src/base/feature_extraction_utils.js");r("./src/utils/tensor.js");var s=r("./src/utils/audio.js");class a extends o.FeatureExtractor{constructor(e){super(e);let t=this.config.sampling_rate,r=(0,s.mel_filter_bank)(257,this.config.num_mel_bins,20,Math.floor(t/2),t,null,"kaldi",!0);this.mel_filters=r,this.window=(0,s.window_function)(400,"hamming",{periodic:!1}),this.min_num_frames=this.config.min_num_frames}async _extract_fbank_features(e){return e=e.map(e=>32768*e),(0,s.spectrogram)(e,this.window,400,160,{fft_length:512,power:2,center:!1,preemphasis:.97,mel_filters:this.mel_filters,log_mel:"log",mel_floor:1192092955078125e-22,remove_dc_offset:!0,transpose:!0,min_num_frames:this.min_num_frames})}async _call(e){(0,o.validate_audio_inputs)(e,"WeSpeakerFeatureExtractor");let t=(await this._extract_fbank_features(e)).unsqueeze_(0);if(null===this.config.fbank_centering_span){let e=t.mean(1).data,r=t.data,[o,s,a]=t.dims;for(let t=0;t<o;++t){let o=t*s*a,i=t*a;for(let t=0;t<s;++t){let s=o+t*a;for(let t=0;t<a;++t)r[s+t]-=e[i+t]}}}return{input_features:t}}}},"./src/models/whisper/common_whisper.js":(e,t,r)=>{r.r(t),r.d(t,{WHISPER_LANGUAGE_MAPPING:()=>s,WHISPER_TO_LANGUAGE_CODE_MAPPING:()=>a,whisper_language_to_code:()=>i});let o=[["en","english"],["zh","chinese"],["de","german"],["es","spanish"],["ru","russian"],["ko","korean"],["fr","french"],["ja","japanese"],["pt","portuguese"],["tr","turkish"],["pl","polish"],["ca","catalan"],["nl","dutch"],["ar","arabic"],["sv","swedish"],["it","italian"],["id","indonesian"],["hi","hindi"],["fi","finnish"],["vi","vietnamese"],["he","hebrew"],["uk","ukrainian"],["el","greek"],["ms","malay"],["cs","czech"],["ro","romanian"],["da","danish"],["hu","hungarian"],["ta","tamil"],["no","norwegian"],["th","thai"],["ur","urdu"],["hr","croatian"],["bg","bulgarian"],["lt","lithuanian"],["la","latin"],["mi","maori"],["ml","malayalam"],["cy","welsh"],["sk","slovak"],["te","telugu"],["fa","persian"],["lv","latvian"],["bn","bengali"],["sr","serbian"],["az","azerbaijani"],["sl","slovenian"],["kn","kannada"],["et","estonian"],["mk","macedonian"],["br","breton"],["eu","basque"],["is","icelandic"],["hy","armenian"],["ne","nepali"],["mn","mongolian"],["bs","bosnian"],["kk","kazakh"],["sq","albanian"],["sw","swahili"],["gl","galician"],["mr","marathi"],["pa","punjabi"],["si","sinhala"],["km","khmer"],["sn","shona"],["yo","yoruba"],["so","somali"],["af","afrikaans"],["oc","occitan"],["ka","georgian"],["be","belarusian"],["tg","tajik"],["sd","sindhi"],["gu","gujarati"],["am","amharic"],["yi","yiddish"],["lo","lao"],["uz","uzbek"],["fo","faroese"],["ht","haitian creole"],["ps","pashto"],["tk","turkmen"],["nn","nynorsk"],["mt","maltese"],["sa","sanskrit"],["lb","luxembourgish"],["my","myanmar"],["bo","tibetan"],["tl","tagalog"],["mg","malagasy"],["as","assamese"],["tt","tatar"],["haw","hawaiian"],["ln","lingala"],["ha","hausa"],["ba","bashkir"],["jw","javanese"],["su","sundanese"]],s=new Map(o),a=new Map([...o.map(([e,t])=>[t,e]),["burmese","my"],["valencian","ca"],["flemish","nl"],["haitian","ht"],["letzeburgesch","lb"],["pushto","ps"],["panjabi","pa"],["moldavian","ro"],["moldovan","ro"],["sinhalese","si"],["castilian","es"]]);function i(e){e=e.toLowerCase();let t=a.get(e);if(void 0===t){let r=e.match(/^<\|([a-z]{2})\|>$/);if(r&&(e=r[1]),s.has(e))t=e;else{let t=2===e.length?s.keys():s.values();throw Error(`Language "${e}" is not supported. Must be one of: ${JSON.stringify(Array.from(t))}`)}}return t}},"./src/models/whisper/feature_extraction_whisper.js":(e,t,r)=>{r.r(t),r.d(t,{WhisperFeatureExtractor:()=>i});var o=r("./src/base/feature_extraction_utils.js");r("./src/utils/tensor.js");var s=r("./src/utils/audio.js"),a=r("./src/utils/maths.js");class i extends o.FeatureExtractor{constructor(e){super(e),this.config.mel_filters??=(0,s.mel_filter_bank)(Math.floor(1+this.config.n_fft/2),this.config.feature_size,0,8e3,this.config.sampling_rate,"slaney","slaney"),this.window=(0,s.window_function)(this.config.n_fft,"hann")}async _extract_fbank_features(e){let t=await (0,s.spectrogram)(e,this.window,this.config.n_fft,this.config.hop_length,{power:2,mel_filters:this.config.mel_filters,log_mel:"log10",max_num_frames:Math.min(Math.floor(e.length/this.config.hop_length),this.config.nb_max_frames)}),r=t.data,o=(0,a.max)(r)[0];for(let e=0;e<r.length;++e)r[e]=(Math.max(r[e],o-8)+4)/4;return t}async _call(e,{max_length:t=null}={}){let r;(0,o.validate_audio_inputs)(e,"WhisperFeatureExtractor");let s=t??this.config.n_samples;return e.length>s?(e.length>this.config.n_samples&&console.warn("Attempting to extract features for audio longer than 30 seconds. If using a pipeline to extract transcript from a long audio clip, remember to specify `chunk_length_s` and/or `stride_length_s`."),r=e.slice(0,s)):(r=new Float32Array(s)).set(e),{input_features:(await this._extract_fbank_features(r)).unsqueeze_(0)}}}},"./src/models/whisper/generation_whisper.js":(e,t,r)=>{r.r(t),r.d(t,{WhisperGenerationConfig:()=>s});var o=r("./src/generation/configuration_utils.js");class s extends o.GenerationConfig{return_timestamps=null;return_token_timestamps=null;num_frames=null;alignment_heads=null;task=null;language=null;no_timestamps_token_id=null;prompt_ids=null;is_multilingual=null;lang_to_id=null;task_to_id=null;max_initial_timestamp_index=1}},"./src/models/whisper/processing_whisper.js":(e,t,r)=>{r.r(t),r.d(t,{WhisperProcessor:()=>i});var o=r("./src/models/auto/feature_extraction_auto.js"),s=r("./src/tokenizers.js"),a=r("./src/base/processing_utils.js");class i extends a.Processor{static tokenizer_class=s.AutoTokenizer;static feature_extractor_class=o.AutoFeatureExtractor;async _call(e){return await this.feature_extractor(e)}}},"./src/models/yolos/image_processing_yolos.js":(e,t,r)=>{r.r(t),r.d(t,{YolosFeatureExtractor:()=>a,YolosImageProcessor:()=>s});var o=r("./src/base/image_processors_utils.js");class s extends o.ImageProcessor{post_process_object_detection(...e){return(0,o.post_process_object_detection)(...e)}}class a extends s{}},"./src/ops/registry.js":(e,t,r)=>{r.r(t),r.d(t,{TensorOpRegistry:()=>i});var o=r("./src/backends/onnx.js"),s=r("./src/utils/tensor.js");let a=async(e,t,r)=>{let a=await (0,o.createInferenceSession)(new Uint8Array(e),t);return async e=>{let t=(0,o.isONNXProxy)(),i=Object.fromEntries(Object.entries(e).map(([e,r])=>[e,(t?r.clone():r).ort_tensor])),n=await (0,o.runInferenceSession)(a,i);return Array.isArray(r)?r.map(e=>new s.Tensor(n[e])):new s.Tensor(n[r])}};class i{static session_options={};static get nearest_interpolate_4d(){return this._nearest_interpolate_4d||(this._nearest_interpolate_4d=a([8,10,18,0,58,129,1,10,41,10,1,120,10,0,10,0,10,1,115,18,1,121,34,6,82,101,115,105,122,101,42,18,10,4,109,111,100,101,34,7,110,101,97,114,101,115,116,160,1,3,18,1,114,90,31,10,1,120,18,26,10,24,8,1,18,20,10,3,18,1,98,10,3,18,1,99,10,3,18,1,104,10,3,18,1,119,90,15,10,1,115,18,10,10,8,8,7,18,4,10,2,8,4,98,31,10,1,121,18,26,10,24,8,1,18,20,10,3,18,1,98,10,3,18,1,99,10,3,18,1,104,10,3,18,1,119,66,2,16,21],this.session_options,"y")),this._nearest_interpolate_4d}static get bilinear_interpolate_4d(){return this._bilinear_interpolate_4d||(this._bilinear_interpolate_4d=a([8,9,18,0,58,128,1,10,40,10,1,120,10,0,10,0,10,1,115,18,1,121,34,6,82,101,115,105,122,101,42,17,10,4,109,111,100,101,34,6,108,105,110,101,97,114,160,1,3,18,1,114,90,31,10,1,120,18,26,10,24,8,1,18,20,10,3,18,1,98,10,3,18,1,99,10,3,18,1,104,10,3,18,1,119,90,15,10,1,115,18,10,10,8,8,7,18,4,10,2,8,4,98,31,10,1,121,18,26,10,24,8,1,18,20,10,3,18,1,98,10,3,18,1,99,10,3,18,1,104,10,3,18,1,119,66,2,16,20],this.session_options,"y")),this._bilinear_interpolate_4d}static get bicubic_interpolate_4d(){return this._bicubic_interpolate_4d||(this._bicubic_interpolate_4d=a([8,9,18,0,58,127,10,39,10,1,120,10,0,10,0,10,1,115,18,1,121,34,6,82,101,115,105,122,101,42,16,10,4,109,111,100,101,34,5,99,117,98,105,99,160,1,3,18,1,114,90,31,10,1,120,18,26,10,24,8,1,18,20,10,3,18,1,98,10,3,18,1,99,10,3,18,1,104,10,3,18,1,119,90,15,10,1,115,18,10,10,8,8,7,18,4,10,2,8,4,98,31,10,1,121,18,26,10,24,8,1,18,20,10,3,18,1,98,10,3,18,1,99,10,3,18,1,104,10,3,18,1,119,66,2,16,20],this.session_options,"y")),this._bicubic_interpolate_4d}static get matmul(){return this._matmul||(this._matmul=a([8,9,18,0,58,55,10,17,10,1,97,10,1,98,18,1,99,34,6,77,97,116,77,117,108,18,1,114,90,9,10,1,97,18,4,10,2,8,1,90,9,10,1,98,18,4,10,2,8,1,98,9,10,1,99,18,4,10,2,8,1,66,2,16,20],this.session_options,"c")),this._matmul}static get stft(){return this._stft||(this._stft=a([8,7,18,0,58,148,1,10,38,10,1,115,10,1,106,10,1,119,10,1,108,18,1,111,34,4,83,84,70,84,42,15,10,8,111,110,101,115,105,100,101,100,24,1,160,1,2,18,1,115,90,26,10,1,115,18,21,10,19,8,1,18,15,10,3,18,1,98,10,3,18,1,115,10,3,18,1,99,90,11,10,1,106,18,6,10,4,8,7,18,0,90,16,10,1,119,18,11,10,9,8,1,18,5,10,3,18,1,119,90,11,10,1,108,18,6,10,4,8,7,18,0,98,31,10,1,111,18,26,10,24,8,1,18,20,10,3,18,1,98,10,3,18,1,102,10,3,18,1,100,10,3,18,1,99,66,2,16,17],this.session_options,"o")),this._stft}static get rfft(){return this._rfft||(this._rfft=a([8,9,18,0,58,97,10,33,10,1,120,10,0,10,1,97,18,1,121,34,3,68,70,84,42,15,10,8,111,110,101,115,105,100,101,100,24,1,160,1,2,18,1,100,90,21,10,1,120,18,16,10,14,8,1,18,10,10,3,18,1,115,10,3,18,1,99,90,11,10,1,97,18,6,10,4,8,7,18,0,98,21,10,1,121,18,16,10,14,8,1,18,10,10,3,18,1,115,10,3,18,1,99,66,2,16,20],this.session_options,"y")),this._rfft}static get top_k(){return this._top_k||(this._top_k=a([8,10,18,0,58,73,10,18,10,1,120,10,1,107,18,1,118,18,1,105,34,4,84,111,112,75,18,1,116,90,9,10,1,120,18,4,10,2,8,1,90,15,10,1,107,18,10,10,8,8,7,18,4,10,2,8,1,98,9,10,1,118,18,4,10,2,8,1,98,9,10,1,105,18,4,10,2,8,7,66,2,16,21],this.session_options,["v","i"])),this._top_k}static get slice(){return this._slice||(this._slice=a([8,7,18,0,58,96,10,25,10,1,120,10,1,115,10,1,101,10,1,97,10,1,116,18,1,121,34,5,83,108,105,99,101,18,1,114,90,9,10,1,120,18,4,10,2,8,1,90,9,10,1,115,18,4,10,2,8,7,90,9,10,1,101,18,4,10,2,8,7,90,9,10,1,97,18,4,10,2,8,7,90,9,10,1,116,18,4,10,2,8,7,98,9,10,1,121,18,4,10,2,8,1,66,2,16,13],this.session_options,"y")),this._slice}}},"./src/pipelines.js":(e,t,r)=>{r.r(t),r.d(t,{AudioClassificationPipeline:()=>C,AutomaticSpeechRecognitionPipeline:()=>E,BackgroundRemovalPipeline:()=>D,DepthEstimationPipeline:()=>G,DocumentQuestionAnsweringPipeline:()=>O,FeatureExtractionPipeline:()=>y,FillMaskPipeline:()=>w,ImageClassificationPipeline:()=>L,ImageFeatureExtractionPipeline:()=>v,ImageSegmentationPipeline:()=>I,ImageToImagePipeline:()=>B,ImageToTextPipeline:()=>A,ObjectDetectionPipeline:()=>j,Pipeline:()=>h,QuestionAnsweringPipeline:()=>M,SummarizationPipeline:()=>P,Text2TextGenerationPipeline:()=>T,TextClassificationPipeline:()=>g,TextGenerationPipeline:()=>F,TextToAudioPipeline:()=>N,TokenClassificationPipeline:()=>f,TranslationPipeline:()=>x,ZeroShotAudioClassificationPipeline:()=>S,ZeroShotClassificationPipeline:()=>k,ZeroShotImageClassificationPipeline:()=>z,ZeroShotObjectDetectionPipeline:()=>V,pipeline:()=>$});var o=r("./src/tokenizers.js"),s=r("./src/models.js"),a=r("./src/models/auto/processing_auto.js");r("./src/base/processing_utils.js");var i=r("./src/utils/generic.js"),n=r("./src/utils/core.js"),l=r("./src/utils/maths.js"),c=r("./src/utils/audio.js"),d=r("./src/utils/tensor.js"),u=r("./src/utils/image.js");async function m(e){return Array.isArray(e)||(e=[e]),await Promise.all(e.map(e=>u.RawImage.read(e)))}async function p(e,t){return Array.isArray(e)||(e=[e]),await Promise.all(e.map(e=>"string"==typeof e||e instanceof URL?(0,c.read_audio)(e,t):e instanceof Float64Array?new Float32Array(e):e))}function _(e,t){t&&(e=e.map(e=>0|e));let[r,o,s,a]=e;return{xmin:r,ymin:o,xmax:s,ymax:a}}class h extends i.Callable{constructor({task:e,model:t,tokenizer:r=null,processor:o=null}){super(),this.task=e,this.model=t,this.tokenizer=r,this.processor=o}async dispose(){await this.model.dispose()}}class g extends h{constructor(e){super(e)}async _call(e,{top_k:t=1}={}){let r=this.tokenizer(e,{padding:!0,truncation:!0}),o=await this.model(r),s="multi_label_classification"===this.model.config.problem_type?e=>e.sigmoid():e=>new d.Tensor("float32",(0,l.softmax)(e.data),e.dims),a=this.model.config.id2label,i=[];for(let e of o.logits){let r=s(e),o=await (0,d.topk)(r,t),n=o[0].tolist(),l=o[1].tolist().map((e,t)=>({label:a?a[e]:`LABEL_${e}`,score:n[t]}));1===t?i.push(...l):i.push(l)}return Array.isArray(e)||1===t?i:i[0]}}class f extends h{constructor(e){super(e)}async _call(e,{ignore_labels:t=["O"]}={}){let r=Array.isArray(e),o=this.tokenizer(r?e:[e],{padding:!0,truncation:!0}),s=(await this.model(o)).logits,a=this.model.config.id2label,i=[];for(let e=0;e<s.dims[0];++e){let r=o.input_ids[e],n=s[e],c=[];for(let e=0;e<n.dims[0];++e){let o=n[e],s=(0,l.max)(o.data)[1],i=a?a[s]:`LABEL_${s}`;if(t.includes(i))continue;let d=this.tokenizer.decode([r[e].item()],{skip_special_tokens:!0});if(""===d)continue;let u=(0,l.softmax)(o.data);c.push({entity:i,score:u[s],index:e,word:d})}i.push(c)}return r?i:i[0]}}class M extends h{constructor(e){super(e)}async _call(e,t,{top_k:r=1}={}){let o=this.tokenizer(e,{text_pair:t,padding:!0,truncation:!0}),{start_logits:s,end_logits:a}=await this.model(o),i=o.input_ids.tolist(),c=o.attention_mask.tolist(),d=this.tokenizer.all_special_ids,u=[];for(let e=0;e<s.dims[0];++e){let t=i[e],o=t.findIndex(e=>e==this.tokenizer.sep_token_id);c[e].map((e,r)=>1==e&&(0===r||r>o&&-1===d.findIndex(e=>e==t[r])));let m=s[e].tolist(),p=a[e].tolist();for(let r=1;r<m.length;++r)(0==c[e]||r<=o||-1!==d.findIndex(e=>e==t[r]))&&(m[r]=-1/0,p[r]=-1/0);let _=(0,l.softmax)(m).map((e,t)=>[e,t]),h=(0,l.softmax)(p).map((e,t)=>[e,t]);_[0][0]=0,h[0][0]=0;let g=(0,n.product)(_,h).filter(e=>e[0][1]<=e[1][1]).map(e=>[e[0][1],e[1][1],e[0][0]*e[1][0]]).sort((e,t)=>t[2]-e[2]);for(let e=0;e<Math.min(g.length,r);++e){let[r,o,s]=g[e],a=t.slice(r,o+1),i=this.tokenizer.decode(a,{skip_special_tokens:!0});u.push({answer:i,score:s})}}return 1===r?u[0]:u}}class w extends h{constructor(e){super(e)}async _call(e,{top_k:t=5}={}){let r=this.tokenizer(e,{padding:!0,truncation:!0}),{logits:o}=await this.model(r),s=[],a=r.input_ids.tolist();for(let e=0;e<a.length;++e){let r=a[e],i=r.findIndex(e=>e==this.tokenizer.mask_token_id);if(-1===i)throw Error(`Mask token (${this.tokenizer.mask_token}) not found in text.`);let n=o[e][i],c=await (0,d.topk)(new d.Tensor("float32",(0,l.softmax)(n.data),n.dims),t),u=c[0].tolist(),m=c[1].tolist();s.push(m.map((e,t)=>{let o=r.slice();return o[i]=e,{score:u[t],token:Number(e),token_str:this.tokenizer.decode([e]),sequence:this.tokenizer.decode(o,{skip_special_tokens:!0})}}))}return Array.isArray(e)?s:s[0]}}class T extends h{_key="generated_text";constructor(e){super(e)}async _call(e,t={}){let r;Array.isArray(e)||(e=[e]),this.model.config.prefix&&(e=e.map(e=>this.model.config.prefix+e));let o=this.model.config.task_specific_params;o&&o[this.task]&&o[this.task].prefix&&(e=e.map(e=>o[this.task].prefix+e));let s=this.tokenizer,a={padding:!0,truncation:!0};r=this instanceof x&&"_build_translation_inputs"in s?s._build_translation_inputs(e,a,t):s(e,a);let i=await this.model.generate({...r,...t});return s.batch_decode(i,{skip_special_tokens:!0}).map(e=>({[this._key]:e}))}}class P extends T{_key="summary_text";constructor(e){super(e)}}class x extends T{_key="translation_text";constructor(e){super(e)}}function b(e){return Array.isArray(e)&&e.every(e=>"role"in e&&"content"in e)}class F extends h{constructor(e){super(e)}async _call(e,t={}){let r,o,s=!1,a=!1,i=t.add_special_tokens??(this.tokenizer.add_bos_token||this.tokenizer.add_eos_token)??!1;if("string"==typeof e)r=e=[e];else if(Array.isArray(e)&&e.every(e=>"string"==typeof e))s=!0,r=e;else{if(b(e))e=[e];else if(Array.isArray(e)&&e.every(b))s=!0;else throw Error("Input must be a string, an array of strings, a Chat, or an array of Chats");a=!0,r=e.map(e=>this.tokenizer.apply_chat_template(e,{tokenize:!1,add_generation_prompt:!0})),i=!1}let n=!a&&(t.return_full_text??!0);this.tokenizer.padding_side="left";let l=this.tokenizer(r,{add_special_tokens:i,padding:!0,truncation:!0}),c=await this.model.generate({...l,...t}),d=this.tokenizer.batch_decode(c,{skip_special_tokens:!0});!n&&l.input_ids.dims.at(-1)>0&&(o=this.tokenizer.batch_decode(l.input_ids,{skip_special_tokens:!0}).map(e=>e.length));let u=Array.from({length:e.length},e=>[]);for(let t=0;t<d.length;++t){let r=Math.floor(t/c.dims[0]*e.length);o&&(d[t]=d[t].slice(o[r])),u[r].push({generated_text:a?[...e[r],{role:"assistant",content:d[t]}]:d[t]})}return s||1!==u.length?u:u[0]}}class k extends h{constructor(e){super(e),this.label2id=Object.fromEntries(Object.entries(this.model.config.label2id).map(([e,t])=>[e.toLowerCase(),t])),this.entailment_id=this.label2id.entailment,void 0===this.entailment_id&&(console.warn("Could not find 'entailment' in label2id mapping. Using 2 as entailment_id."),this.entailment_id=2),this.contradiction_id=this.label2id.contradiction??this.label2id.not_entailment,void 0===this.contradiction_id&&(console.warn("Could not find 'contradiction' in label2id mapping. Using 0 as contradiction_id."),this.contradiction_id=0)}async _call(e,t,{hypothesis_template:r="This example is {}.",multi_label:o=!1}={}){let s=Array.isArray(e);s||(e=[e]),Array.isArray(t)||(t=[t]);let a=t.map(e=>r.replace("{}",e)),i=o||1===t.length,n=[];for(let r of e){let e=[];for(let t of a){let o=this.tokenizer(r,{text_pair:t,padding:!0,truncation:!0}),s=await this.model(o);i?e.push([s.logits.data[this.contradiction_id],s.logits.data[this.entailment_id]]):e.push(s.logits.data[this.entailment_id])}let o=(i?e.map(e=>(0,l.softmax)(e)[1]):(0,l.softmax)(e)).map((e,t)=>[e,t]).sort((e,t)=>t[0]-e[0]);n.push({sequence:r,labels:o.map(e=>t[e[1]]),scores:o.map(e=>e[0])})}return s?n:n[0]}}class y extends h{constructor(e){super(e)}async _call(e,{pooling:t="none",normalize:r=!1,quantize:o=!1,precision:s="binary"}={}){let a=this.tokenizer(e,{padding:!0,truncation:!0}),i=await this.model(a),n=i.last_hidden_state??i.logits??i.token_embeddings;switch(t){case"none":break;case"mean":n=(0,d.mean_pooling)(n,a.attention_mask);break;case"first_token":case"cls":n=n.slice(null,0);break;case"last_token":case"eos":n=n.slice(null,-1);break;default:throw Error(`Pooling method '${t}' not supported.`)}return r&&(n=n.normalize(2,-1)),o&&(n=(0,d.quantize_embeddings)(n,s)),n}}class v extends h{constructor(e){super(e)}async _call(e,{pool:t=null}={}){let r;let o=await m(e),{pixel_values:s}=await this.processor(o),a=await this.model({pixel_values:s});if(t){if(!("pooler_output"in a))throw Error("No pooled output was returned. Make sure the model has a 'pooler' layer when using the 'pool' option.");r=a.pooler_output}else r=a.last_hidden_state??a.logits??a.image_embeds;return r}}class C extends h{constructor(e){super(e)}async _call(e,{top_k:t=5}={}){let r=this.processor.feature_extractor.config.sampling_rate,o=await p(e,r),s=this.model.config.id2label,a=[];for(let e of o){let r=await this.processor(e),o=(await this.model(r)).logits[0],i=await (0,d.topk)(new d.Tensor("float32",(0,l.softmax)(o.data),o.dims),t),n=i[0].tolist(),c=i[1].tolist().map((e,t)=>({label:s?s[e]:`LABEL_${e}`,score:n[t]}));a.push(c)}return Array.isArray(e)?a:a[0]}}class S extends h{constructor(e){super(e)}async _call(e,t,{hypothesis_template:r="This is a sound of {}."}={}){let o=!Array.isArray(e);o&&(e=[e]);let s=t.map(e=>r.replace("{}",e)),a=this.tokenizer(s,{padding:!0,truncation:!0}),i=this.processor.feature_extractor.config.sampling_rate,n=await p(e,i),c=[];for(let e of n){let r=await this.processor(e),o=await this.model({...a,...r}),s=(0,l.softmax)(o.logits_per_audio.data);c.push([...s].map((e,r)=>({score:e,label:t[r]})))}return o?c[0]:c}}class E extends h{constructor(e){super(e)}async _call(e,t={}){switch(this.model.config.model_type){case"whisper":case"lite-whisper":return this._call_whisper(e,t);case"wav2vec2":case"wav2vec2-bert":case"unispeech":case"unispeech-sat":case"hubert":case"parakeet_ctc":return this._call_wav2vec2(e,t);case"moonshine":return this._call_moonshine(e,t);default:throw Error(`AutomaticSpeechRecognitionPipeline does not support model type '${this.model.config.model_type}'.`)}}async _call_wav2vec2(e,t){t.language&&console.warn('`language` parameter is not yet supported for `wav2vec2` models, defaulting to "English".'),t.task&&console.warn('`task` parameter is not yet supported for `wav2vec2` models, defaulting to "transcribe".');let r=!Array.isArray(e);r&&(e=[e]);let o=this.processor.feature_extractor.config.sampling_rate,s=await p(e,o),a=[];for(let e of s){let t=await this.processor(e),r=(await this.model(t)).logits[0],o=[];for(let e of r)o.push((0,l.max)(e.data)[1]);let s=this.tokenizer.decode(o,{skip_special_tokens:!0}).trim();a.push({text:s})}return r?a[0]:a}async _call_whisper(e,t){let r=t.return_timestamps??!1,o=t.chunk_length_s??0,s=t.force_full_sequences??!1,a=t.stride_length_s??null,i={...t};"word"===r&&(i.return_token_timestamps=!0,i.return_timestamps=!1);let n=!Array.isArray(e);n&&(e=[e]);let c=this.processor.feature_extractor.config.chunk_length/this.model.config.max_source_positions,d=this.processor.feature_extractor.config.hop_length,u=this.processor.feature_extractor.config.sampling_rate,m=await p(e,u),_=[];for(let e of m){let t=[];if(o>0){if(null===a)a=o/6;else if(o<=a)throw Error("`chunk_length_s` must be larger than `stride_length_s`.");let r=u*o,s=u*a,i=r-2*s,n=0;for(;;){let o=n+r,a=e.subarray(n,o),l=await this.processor(a),c=0===n,d=o>=e.length;if(t.push({stride:[a.length,c?0:s,d?0:s],input_features:l.input_features,is_last:d}),d)break;n+=i}}else t=[{stride:[e.length,0,0],input_features:(await this.processor(e)).input_features,is_last:!0}];for(let e of t){i.num_frames=Math.floor(e.stride[0]/d);let t=await this.model.generate({inputs:e.input_features,...i});"word"===r?(e.tokens=t.sequences.tolist()[0],e.token_timestamps=t.token_timestamps.tolist()[0].map(e=>(0,l.round)(e,2))):e.tokens=t[0].tolist(),e.stride=e.stride.map(e=>e/u)}let[n,m]=this.tokenizer._decode_asr(t,{time_precision:c,return_timestamps:r,force_full_sequences:s});_.push({text:n,...m})}return n?_[0]:_}async _call_moonshine(e,t){let r=!Array.isArray(e);r&&(e=[e]);let o=this.processor.feature_extractor.config.sampling_rate,s=await p(e,o),a=[];for(let e of s){let r=await this.processor(e),s=6*Math.floor(e.length/o),i=await this.model.generate({max_new_tokens:s,...t,...r}),n=this.processor.batch_decode(i,{skip_special_tokens:!0})[0];a.push({text:n})}return r?a[0]:a}}class A extends h{constructor(e){super(e)}async _call(e,t={}){let r=Array.isArray(e),o=await m(e),{pixel_values:s}=await this.processor(o),a=[];for(let e of s){e.dims=[1,...e.dims];let r=await this.model.generate({inputs:e,...t}),o=this.tokenizer.batch_decode(r,{skip_special_tokens:!0}).map(e=>({generated_text:e.trim()}));a.push(o)}return r?a:a[0]}}class L extends h{constructor(e){super(e)}async _call(e,{top_k:t=5}={}){let r=await m(e),{pixel_values:o}=await this.processor(r),s=await this.model({pixel_values:o}),a=this.model.config.id2label,i=[];for(let e of s.logits){let r=await (0,d.topk)(new d.Tensor("float32",(0,l.softmax)(e.data),e.dims),t),o=r[0].tolist(),s=r[1].tolist().map((e,t)=>({label:a?a[e]:`LABEL_${e}`,score:o[t]}));i.push(s)}return Array.isArray(e)?i:i[0]}}class I extends h{constructor(e){super(e),this.subtasks_mapping={panoptic:"post_process_panoptic_segmentation",instance:"post_process_instance_segmentation",semantic:"post_process_semantic_segmentation"}}async _call(e,{threshold:t=.5,mask_threshold:r=.5,overlap_mask_area_threshold:o=.8,label_ids_to_fuse:s=null,target_sizes:a=null,subtask:i=null}={}){if(Array.isArray(e)&&1!==e.length)throw Error("Image segmentation pipeline currently only supports a batch size of 1.");let n=await m(e),l=n.map(e=>[e.height,e.width]),c=await this.processor(n),{inputNames:d,outputNames:p}=this.model.sessions.model;if(!d.includes("pixel_values")){if(1!==d.length)throw Error(`Expected a single input name, but got ${d.length} inputs: ${d}.`);let e=d[0];if(e in c)throw Error(`Input name ${e} already exists in the inputs.`);c[e]=c.pixel_values}let _=await this.model(c),h=null;if(null!==i)h=this.subtasks_mapping[i];else if(this.processor.image_processor){for(let[e,t]of Object.entries(this.subtasks_mapping))if(t in this.processor.image_processor){h=this.processor.image_processor[t].bind(this.processor.image_processor),i=e;break}}let g=this.model.config.id2label,f=[];if(i){if("panoptic"===i||"instance"===i){let e=h(_,t,r,o,s,a??l)[0],i=e.segmentation;for(let t of e.segments_info){let e=new Uint8ClampedArray(i.data.length);for(let r=0;r<i.data.length;++r)i.data[r]===t.id&&(e[r]=255);let r=new u.RawImage(e,i.dims[1],i.dims[0],1);f.push({score:t.score,label:g[t.label_id],mask:r})}}else if("semantic"===i){let{segmentation:e,labels:t}=h(_,a??l)[0];for(let r of t){let t=new Uint8ClampedArray(e.data.length);for(let o=0;o<e.data.length;++o)e.data[o]===r&&(t[o]=255);let o=new u.RawImage(t,e.dims[1],e.dims[0],1);f.push({score:null,label:g[r],mask:o})}}else throw Error(`Subtask ${i} not supported.`)}else{let e=_[p[0]];for(let t=0;t<l.length;++t){let r=l[t],o=e[t];o.data.some(e=>e<-1e-5||e>1.00001)&&o.sigmoid_();let s=await u.RawImage.fromTensor(o.mul_(255).to("uint8")).resize(r[1],r[0]);f.push({label:null,score:null,mask:s})}}return f}}class D extends I{constructor(e){super(e)}async _call(e,t={}){if(Array.isArray(e)&&1!==e.length)throw Error("Background removal pipeline currently only supports a batch size of 1.");let r=await m(e),o=await super._call(e,t);return r.map((e,t)=>{let r=e.clone();return r.putAlpha(o[t].mask),r})}}class z extends h{constructor(e){super(e)}async _call(e,t,{hypothesis_template:r="This is a photo of {}"}={}){let o=Array.isArray(e),s=await m(e),a=t.map(e=>r.replace("{}",e)),i=this.tokenizer(a,{padding:"siglip"!==this.model.config.model_type||"max_length",truncation:!0}),{pixel_values:n}=await this.processor(s),c=await this.model({...i,pixel_values:n}),d="siglip"===this.model.config.model_type?e=>e.sigmoid().data:e=>(0,l.softmax)(e.data),u=[];for(let e of c.logits_per_image){let r=[...d(e)].map((e,r)=>({score:e,label:t[r]}));r.sort((e,t)=>t.score-e.score),u.push(r)}return o?u:u[0]}}class j extends h{constructor(e){super(e)}async _call(e,{threshold:t=.9,percentage:r=!1}={}){let o=Array.isArray(e);if(o&&1!==e.length)throw Error("Object detection pipeline currently only supports a batch size of 1.");let s=await m(e),a=r?null:s.map(e=>[e.height,e.width]),{pixel_values:i,pixel_mask:n}=await this.processor(s),l=await this.model({pixel_values:i,pixel_mask:n}),c=this.processor.image_processor.post_process_object_detection(l,t,a),d=this.model.config.id2label,u=c.map(e=>e.boxes.map((t,o)=>({score:e.scores[o],label:d[e.classes[o]],box:_(t,!r)})));return o?u:u[0]}}class V extends h{constructor(e){super(e)}async _call(e,t,{threshold:r=.1,top_k:o=null,percentage:s=!1}={}){let a=Array.isArray(e),i=await m(e),n=this.tokenizer(t,{padding:!0,truncation:!0}),l=await this.processor(i),c=[];for(let e=0;e<i.length;++e){let a;let d=i[e],u=s?null:[[d.height,d.width]],m=l.pixel_values[e].unsqueeze_(0),p=await this.model({...n,pixel_values:m});if("post_process_grounded_object_detection"in this.processor){let e=this.processor.post_process_grounded_object_detection(p,n.input_ids,{box_threshold:r,text_threshold:r,target_sizes:u})[0];a=e.boxes.map((t,r)=>({score:e.scores[r],label:e.labels[r],box:_(t,!s)}))}else{let e=this.processor.image_processor.post_process_object_detection(p,r,u,!0)[0];a=e.boxes.map((r,o)=>({score:e.scores[o],label:t[e.classes[o]],box:_(r,!s)}))}a.sort((e,t)=>t.score-e.score),null!==o&&(a=a.slice(0,o)),c.push(a)}return a?c:c[0]}}class O extends h{constructor(e){super(e)}async _call(e,t,r={}){let o=(await m(e))[0],{pixel_values:s}=await this.processor(o),a=`<s_docvqa><s_question>${t}</s_question><s_answer>`,i=this.tokenizer(a,{add_special_tokens:!1,padding:!0,truncation:!0}).input_ids,n=await this.model.generate({inputs:s,max_length:this.model.config.decoder.max_position_embeddings,decoder_input_ids:i,...r}),l=this.tokenizer.batch_decode(n)[0].match(/<s_answer>(.*?)<\/s_answer>/),c=null;return l&&l.length>=2&&(c=l[1].trim()),[{answer:c}]}}class N extends h{DEFAULT_VOCODER_ID="Xenova/speecht5_hifigan";constructor(e){super(e),this.vocoder=e.vocoder??null}async _prepare_speaker_embeddings(e){if(("string"==typeof e||e instanceof URL)&&(e=new Float32Array(await (await fetch(e)).arrayBuffer())),e instanceof Float32Array)e=new d.Tensor("float32",e,[e.length]);else if(!(e instanceof d.Tensor))throw Error("Speaker embeddings must be a `Tensor`, `Float32Array`, `string`, or `URL`.");return e}async _call(e,{speaker_embeddings:t=null,num_inference_steps:r,speed:o}={}){return this.processor?this._call_text_to_spectrogram(e,{speaker_embeddings:t}):"supertonic"===this.model.config.model_type?this._call_supertonic(e,{speaker_embeddings:t,num_inference_steps:r,speed:o}):this._call_text_to_waveform(e)}async _call_supertonic(e,{speaker_embeddings:t,num_inference_steps:r,speed:o}){if(!t)throw Error("Speaker embeddings must be provided for Supertonic models.");t=await this._prepare_speaker_embeddings(t);let{sampling_rate:s,style_dim:a}=this.model.config;t=t.view(1,-1,a);let i=this.tokenizer(e,{padding:!0,truncation:!0}),{waveform:n}=await this.model.generate_speech({...i,style:t,num_inference_steps:r,speed:o});return new c.RawAudio(n.data,s)}async _call_text_to_waveform(e){let t=this.tokenizer(e,{padding:!0,truncation:!0}),{waveform:r}=await this.model(t),o=this.model.config.sampling_rate;return new c.RawAudio(r.data,o)}async _call_text_to_spectrogram(e,{speaker_embeddings:t}){this.vocoder||(console.log("No vocoder specified, using default HifiGan vocoder."),this.vocoder=await s.AutoModel.from_pretrained(this.DEFAULT_VOCODER_ID,{dtype:"fp32"}));let{input_ids:r}=this.tokenizer(e,{padding:!0,truncation:!0});t=(t=await this._prepare_speaker_embeddings(t)).view(1,-1);let{waveform:o}=await this.model.generate_speech(r,t,{vocoder:this.vocoder}),a=this.processor.feature_extractor.config.sampling_rate;return new c.RawAudio(o.data,a)}}class B extends h{constructor(e){super(e)}async _call(e){let t=await m(e),r=await this.processor(t),o=await this.model(r),s=[];for(let e of o.reconstruction){let t=e.squeeze().clamp_(0,1).mul_(255).round_().to("uint8");s.push(u.RawImage.fromTensor(t))}return s.length>1?s:s[0]}}class G extends h{constructor(e){super(e)}async _call(e){let t=await m(e),r=await this.processor(t),{predicted_depth:o}=await this.model(r),s=[];for(let e=0;e<t.length;++e){let r=o[e],[a,i]=r.dims.slice(-2),[n,l]=t[e].size,c=(await (0,d.interpolate_4d)(r.view(1,1,a,i),{size:[l,n],mode:"bilinear"})).view(l,n),m=c.min().item(),p=c.max().item(),_=c.sub(m).div_(p-m).mul_(255).to("uint8").unsqueeze(0),h=u.RawImage.fromTensor(_);s.push({predicted_depth:c,depth:h})}return s.length>1?s:s[0]}}let R=Object.freeze({"text-classification":{tokenizer:o.AutoTokenizer,pipeline:g,model:s.AutoModelForSequenceClassification,default:{model:"Xenova/distilbert-base-uncased-finetuned-sst-2-english"},type:"text"},"token-classification":{tokenizer:o.AutoTokenizer,pipeline:f,model:s.AutoModelForTokenClassification,default:{model:"Xenova/bert-base-multilingual-cased-ner-hrl"},type:"text"},"question-answering":{tokenizer:o.AutoTokenizer,pipeline:M,model:s.AutoModelForQuestionAnswering,default:{model:"Xenova/distilbert-base-cased-distilled-squad"},type:"text"},"fill-mask":{tokenizer:o.AutoTokenizer,pipeline:w,model:s.AutoModelForMaskedLM,default:{model:"Xenova/bert-base-uncased"},type:"text"},summarization:{tokenizer:o.AutoTokenizer,pipeline:P,model:s.AutoModelForSeq2SeqLM,default:{model:"Xenova/distilbart-cnn-6-6"},type:"text"},translation:{tokenizer:o.AutoTokenizer,pipeline:x,model:s.AutoModelForSeq2SeqLM,default:{model:"Xenova/t5-small"},type:"text"},"text2text-generation":{tokenizer:o.AutoTokenizer,pipeline:T,model:s.AutoModelForSeq2SeqLM,default:{model:"Xenova/flan-t5-small"},type:"text"},"text-generation":{tokenizer:o.AutoTokenizer,pipeline:F,model:s.AutoModelForCausalLM,default:{model:"Xenova/gpt2"},type:"text"},"zero-shot-classification":{tokenizer:o.AutoTokenizer,pipeline:k,model:s.AutoModelForSequenceClassification,default:{model:"Xenova/distilbert-base-uncased-mnli"},type:"text"},"audio-classification":{pipeline:C,model:s.AutoModelForAudioClassification,processor:a.AutoProcessor,default:{model:"Xenova/wav2vec2-base-superb-ks"},type:"audio"},"zero-shot-audio-classification":{tokenizer:o.AutoTokenizer,pipeline:S,model:s.AutoModel,processor:a.AutoProcessor,default:{model:"Xenova/clap-htsat-unfused"},type:"multimodal"},"automatic-speech-recognition":{tokenizer:o.AutoTokenizer,pipeline:E,model:[s.AutoModelForSpeechSeq2Seq,s.AutoModelForCTC],processor:a.AutoProcessor,default:{model:"Xenova/whisper-tiny.en"},type:"multimodal"},"text-to-audio":{tokenizer:o.AutoTokenizer,pipeline:N,model:[s.AutoModelForTextToWaveform,s.AutoModelForTextToSpectrogram],processor:[a.AutoProcessor,null],default:{model:"Xenova/speecht5_tts"},type:"text"},"image-to-text":{tokenizer:o.AutoTokenizer,pipeline:A,model:s.AutoModelForVision2Seq,processor:a.AutoProcessor,default:{model:"Xenova/vit-gpt2-image-captioning"},type:"multimodal"},"image-classification":{pipeline:L,model:s.AutoModelForImageClassification,processor:a.AutoProcessor,default:{model:"Xenova/vit-base-patch16-224"},type:"multimodal"},"image-segmentation":{pipeline:I,model:[s.AutoModelForImageSegmentation,s.AutoModelForSemanticSegmentation,s.AutoModelForUniversalSegmentation],processor:a.AutoProcessor,default:{model:"Xenova/detr-resnet-50-panoptic"},type:"multimodal"},"background-removal":{pipeline:D,model:[s.AutoModelForImageSegmentation,s.AutoModelForSemanticSegmentation,s.AutoModelForUniversalSegmentation],processor:a.AutoProcessor,default:{model:"Xenova/modnet"},type:"image"},"zero-shot-image-classification":{tokenizer:o.AutoTokenizer,pipeline:z,model:s.AutoModel,processor:a.AutoProcessor,default:{model:"Xenova/clip-vit-base-patch32"},type:"multimodal"},"object-detection":{pipeline:j,model:s.AutoModelForObjectDetection,processor:a.AutoProcessor,default:{model:"Xenova/detr-resnet-50"},type:"multimodal"},"zero-shot-object-detection":{tokenizer:o.AutoTokenizer,pipeline:V,model:s.AutoModelForZeroShotObjectDetection,processor:a.AutoProcessor,default:{model:"Xenova/owlvit-base-patch32"},type:"multimodal"},"document-question-answering":{tokenizer:o.AutoTokenizer,pipeline:O,model:s.AutoModelForDocumentQuestionAnswering,processor:a.AutoProcessor,default:{model:"Xenova/donut-base-finetuned-docvqa"},type:"multimodal"},"image-to-image":{pipeline:B,model:s.AutoModelForImageToImage,processor:a.AutoProcessor,default:{model:"Xenova/swin2SR-classical-sr-x2-64"},type:"image"},"depth-estimation":{pipeline:G,model:s.AutoModelForDepthEstimation,processor:a.AutoProcessor,default:{model:"Xenova/dpt-large"},type:"image"},"feature-extraction":{tokenizer:o.AutoTokenizer,pipeline:y,model:s.AutoModel,default:{model:"Xenova/all-MiniLM-L6-v2"},type:"text"},"image-feature-extraction":{processor:a.AutoProcessor,pipeline:v,model:[s.AutoModelForImageFeatureExtraction,s.AutoModel],default:{model:"Xenova/vit-base-patch16-224-in21k"},type:"image"}}),q=Object.freeze({"sentiment-analysis":"text-classification",ner:"token-classification",asr:"automatic-speech-recognition","text-to-speech":"text-to-audio",embeddings:"feature-extraction"});async function $(e,t=null,{progress_callback:r=null,config:o=null,cache_dir:s=null,local_files_only:a=!1,revision:i="main",device:l=null,dtype:c=null,subfolder:d="onnx",use_external_data_format:u=null,model_file_name:m=null,session_options:p={}}={}){let _=R[(e=q[e]??e).split("_",1)[0]];if(!_)throw Error(`Unsupported pipeline: ${e}. Must be one of [${Object.keys(R)}]`);t||(t=_.default.model,console.log(`No model specified. Using default model: "${t}".`));let h=new Map([["tokenizer",_.tokenizer],["model",_.model],["processor",_.processor]]),g=await W(h,t,{progress_callback:r,config:o,cache_dir:s,local_files_only:a,revision:i,device:l,dtype:c,subfolder:d,use_external_data_format:u,model_file_name:m,session_options:p});return g.task=e,(0,n.dispatchCallback)(r,{status:"ready",task:e,model:t}),new _.pipeline(g)}async function W(e,t,r){let o=Object.create(null),s=[];for(let[a,i]of e.entries()){let e;i&&(e=Array.isArray(i)?new Promise(async(e,o)=>{let s;for(let a of i){if(null===a){e(null);return}try{e(await a.from_pretrained(t,r));return}catch(e){if(e.message?.includes("Unsupported model type"))s=e;else if(e.message?.includes("Could not locate file"))s=e;else{o(e);return}}}o(s)}):i.from_pretrained(t,r),o[a]=e,s.push(e))}for(let[e,t]of(await Promise.all(s),Object.entries(o)))o[e]=await t;return o}},"./src/tokenizers.js":(e,t,r)=>{r.r(t),r.d(t,{AlbertTokenizer:()=>eb,AutoTokenizer:()=>ts,BartTokenizer:()=>eV,BertTokenizer:()=>ex,BlenderbotSmallTokenizer:()=>e9,BlenderbotTokenizer:()=>e6,BloomTokenizer:()=>eG,CLIPTokenizer:()=>e3,CamembertTokenizer:()=>eL,CodeGenTokenizer:()=>e2,CodeLlamaTokenizer:()=>eq,CohereTokenizer:()=>tr,ConvBertTokenizer:()=>eS,DebertaTokenizer:()=>ey,DebertaV2Tokenizer:()=>ev,DistilBertTokenizer:()=>eA,ElectraTokenizer:()=>eD,EsmTokenizer:()=>eX,FalconTokenizer:()=>eU,GPT2Tokenizer:()=>ej,GPTNeoXTokenizer:()=>eQ,GemmaTokenizer:()=>eJ,Grok1Tokenizer:()=>eY,HerbertTokenizer:()=>eC,LlamaTokenizer:()=>eR,M2M100Tokenizer:()=>e0,MBart50Tokenizer:()=>eN,MBartTokenizer:()=>eO,MPNetTokenizer:()=>eW,MarianTokenizer:()=>e5,MgpstrTokenizer:()=>to,MobileBertTokenizer:()=>eF,NllbTokenizer:()=>eZ,NougatTokenizer:()=>te,PreTrainedTokenizer:()=>eP,Qwen2Tokenizer:()=>eH,RoFormerTokenizer:()=>eE,RobertaTokenizer:()=>eB,SiglipTokenizer:()=>e4,SpeechT5Tokenizer:()=>e7,SqueezeBertTokenizer:()=>ek,T5Tokenizer:()=>ez,TokenizerModel:()=>b,VitsTokenizer:()=>tt,Wav2Vec2CTCTokenizer:()=>e8,WhisperTokenizer:()=>e1,XLMRobertaTokenizer:()=>e$,XLMTokenizer:()=>eI,is_chinese_char:()=>f});var o=r("./src/utils/generic.js"),s=r("./src/utils/core.js"),a=r("./src/utils/hub.js"),i=r("./src/utils/maths.js"),n=r("./src/utils/tensor.js"),l=r("./src/utils/data-structures.js"),c=r("./node_modules/@huggingface/jinja/dist/index.js"),d=r("./src/models/whisper/common_whisper.js");async function u(e,t){let r=await Promise.all([(0,a.getModelJSON)(e,"tokenizer.json",!0,t),(0,a.getModelJSON)(e,"tokenizer_config.json",!0,t)]);return null!==t.legacy&&(r[1].legacy=t.legacy),r}function m(e,t=!0){if(void 0!==e.Regex){let t=e.Regex.replace(/\\([#&~])/g,"$1");for(let[e,r]of P)t=t.replaceAll(e,r);return RegExp(t,"gu")}if(void 0===e.String)return console.warn("Unknown pattern type:",e),null;{let r=(0,s.escapeRegExp)(e.String);return RegExp(t?r:`(${r})`,"gu")}}function p(e){return new Map(Object.entries(e))}function _(e){let t=e.dims;switch(t.length){case 1:return e.tolist();case 2:if(1!==t[0])throw Error("Unable to decode tensor with `batch size !== 1`. Use `tokenizer.batch_decode(...)` for batched inputs.");return e.tolist()[0];default:throw Error(`Expected tensor to have 1-2 dimensions, got ${t.length}.`)}}function h(e){return e.replace(/ \./g,".").replace(/ \?/g,"?").replace(/ \!/g,"!").replace(/ ,/g,",").replace(/ \' /g,"'").replace(/ n\'t/g,"n't").replace(/ \'m/g,"'m").replace(/ \'s/g,"'s").replace(/ \'ve/g,"'ve").replace(/ \'re/g,"'re")}function g(e){return e.replace(/\p{M}/gu,"")}function f(e){return e>=19968&&e<=40959||e>=13312&&e<=19903||e>=131072&&e<=173791||e>=173824&&e<=177983||e>=177984&&e<=178207||e>=178208&&e<=183983||e>=63744&&e<=64255||e>=194560&&e<=195103}let M="\\p{P}\\u0021-\\u002F\\u003A-\\u0040\\u005B-\\u0060\\u007B-\\u007E",w=RegExp(`^[${M}]+$`,"gu"),T=".,!?",P=new Map([["(?i:'s|'t|'re|'ve|'m|'ll|'d)","(?:'([sS]|[tT]|[rR][eE]|[vV][eE]|[mM]|[lL][lL]|[dD]))"],["(?i:[sdmt]|ll|ve|re)","(?:[sS]|[dD]|[mM]|[tT]|[lL][lL]|[vV][eE]|[rR][eE])"],["[^\\r\\n\\p{L}\\p{N}]?+","[^\\r\\n\\p{L}\\p{N}]?"],["[^\\s\\p{L}\\p{N}]++","[^\\s\\p{L}\\p{N}]+"],[` ?[^(\\s|[${T}])]+`,` ?[^\\s${T}]+`]]);class x{constructor(e){this.content=e.content,this.id=e.id,this.single_word=e.single_word??!1,this.lstrip=e.lstrip??!1,this.rstrip=e.rstrip??!1,this.special=e.special??!1,this.normalized=e.normalized??null}}class b extends o.Callable{constructor(e){super(),this.config=e,this.vocab=[],this.tokens_to_ids=new Map,this.unk_token_id=void 0,this.unk_token=void 0,this.end_of_word_suffix=void 0,this.fuse_unk=this.config.fuse_unk??!1}static fromConfig(e,...t){switch(e.type){case"WordPiece":return new F(e);case"Unigram":return new k(e,...t);case"BPE":return new C(e);default:if(e.vocab){if(Array.isArray(e.vocab))return new k(e,...t);if(!(Object.hasOwn(e,"continuing_subword_prefix")&&Object.hasOwn(e,"unk_token")))return new S(e,...t);if(Object.hasOwn(e,"merges"))return new C(e);return new F(e)}throw Error(`Unknown TokenizerModel type: ${e.type}`)}}_call(e){return e=this.encode(e),this.fuse_unk&&(e=function(e,t,r){let o=[],s=0;for(;s<e.length;){if(o.push(e[s]),(t.get(e[s])??r)!==r){++s;continue}for(;++s<e.length&&(t.get(e[s])??r)===r;)t.get(o.at(-1))!==r&&(o[o.length-1]+=e[s])}return o}(e,this.tokens_to_ids,this.unk_token_id)),e}encode(e){throw Error("encode should be implemented in subclass.")}convert_tokens_to_ids(e){return e.map(e=>this.tokens_to_ids.get(e)??this.unk_token_id)}convert_ids_to_tokens(e){return e.map(e=>this.vocab[e]??this.unk_token)}}class F extends b{constructor(e){for(let[t,r]of(super(e),this.tokens_to_ids=p(e.vocab),this.unk_token_id=this.tokens_to_ids.get(e.unk_token),this.unk_token=e.unk_token,this.max_input_chars_per_word=e.max_input_chars_per_word??100,this.vocab=Array(this.tokens_to_ids.size),this.tokens_to_ids))this.vocab[r]=t}encode(e){let t=[];for(let r of e){let e=[...r];if(e.length>this.max_input_chars_per_word){t.push(this.unk_token);continue}let o=!1,s=0,a=[];for(;s<e.length;){let t=e.length,r=null;for(;s<t;){let o=e.slice(s,t).join("");if(s>0&&(o=this.config.continuing_subword_prefix+o),this.tokens_to_ids.has(o)){r=o;break}--t}if(null===r){o=!0;break}a.push(r),s=t}o?t.push(this.unk_token):t.push(...a)}return t}}class k extends b{constructor(e,t){super(e);let r=e.vocab.length;this.vocab=Array(r),this.scores=Array(r);for(let t=0;t<r;++t)[this.vocab[t],this.scores[t]]=e.vocab[t];this.unk_token_id=e.unk_id,this.unk_token=this.vocab[e.unk_id],this.tokens_to_ids=new Map(this.vocab.map((e,t)=>[e,t])),this.bos_token=" ",this.bos_token_id=this.tokens_to_ids.get(this.bos_token),this.eos_token=t.eos_token,this.eos_token_id=this.tokens_to_ids.get(this.eos_token),this.unk_token=this.vocab[this.unk_token_id],this.minScore=(0,i.min)(this.scores)[0],this.unk_score=this.minScore-10,this.scores[this.unk_token_id]=this.unk_score,this.trie=new l.CharTrie,this.trie.extend(this.vocab),this.fuse_unk=!0}populateNodes(e){let t=e.chars,r=0;for(;r<t.length;){let o=!1,a=[],i=t.slice(r).join("");for(let t of this.trie.commonPrefixSearch(i)){a.push(t);let i=this.tokens_to_ids.get(t),n=this.scores[i],l=(0,s.len)(t);e.insert(r,l,n,i),o||1!==l||(o=!0)}o||e.insert(r,1,this.unk_score,this.unk_token_id),r+=1}}tokenize(e){let t=new l.TokenLattice(e,this.bos_token_id,this.eos_token_id);return this.populateNodes(t),t.tokens()}encode(e){let t=[];for(let r of e){let e=this.tokenize(r);t.push(...e)}return t}}let y=(()=>{let e=[...Array.from({length:94},(e,t)=>t+33),...Array.from({length:12},(e,t)=>t+161),...Array.from({length:82},(e,t)=>t+174)],t=e.slice(),r=0;for(let o=0;o<256;++o)e.includes(o)||(e.push(o),t.push(256+r),r+=1);let o=t.map(e=>String.fromCharCode(e));return Object.fromEntries(e.map((e,t)=>[e,o[t]]))})(),v=(0,s.reverseDictionary)(y);class C extends b{constructor(e){for(let[t,r]of(super(e),this.tokens_to_ids=p(e.vocab),this.unk_token_id=this.tokens_to_ids.get(e.unk_token),this.unk_token=e.unk_token,this.vocab=Array(this.tokens_to_ids.size),this.tokens_to_ids))this.vocab[r]=t;let t=Array.isArray(e.merges[0]);this.merges=t?e.merges:e.merges.map(e=>e.split(" ",2)),this.bpe_ranks=new Map(this.merges.map((e,t)=>[JSON.stringify(e),t])),this.end_of_word_suffix=e.end_of_word_suffix,this.continuing_subword_suffix=e.continuing_subword_suffix??null,this.byte_fallback=this.config.byte_fallback??!1,this.byte_fallback&&(this.text_encoder=new TextEncoder),this.ignore_merges=this.config.ignore_merges??!1,this.max_length_to_cache=256,this.cache_capacity=1e4,this.cache=new l.LRUCache(this.cache_capacity)}clear_cache(){this.cache.clear()}bpe(e){if(0===e.length)return[];let t=this.cache.get(e);if(void 0!==t)return t;let r=Array.from(e);this.end_of_word_suffix&&(r[r.length-1]+=this.end_of_word_suffix);let o=[];if(r.length>1){let e=new l.PriorityQueue((e,t)=>e.score<t.score),t={token:r[0],bias:0,prev:null,next:null},s=t;for(let t=1;t<r.length;++t){let o={bias:t/r.length,token:r[t],prev:s,next:null};s.next=o,this._add_node(e,s),s=o}for(;!e.isEmpty();){let r=e.pop();if(r.deleted||!r.next||r.next.deleted)continue;if(r.deleted=!0,r.next.deleted=!0,r.prev){let e={...r.prev};r.prev.deleted=!0,r.prev=e,e.prev?e.prev.next=e:t=e}let o={token:r.token+r.next.token,bias:r.bias,prev:r.prev,next:r.next.next};o.prev?(o.prev.next=o,this._add_node(e,o.prev)):t=o,o.next&&(o.next.prev=o,this._add_node(e,o))}for(let e=t;null!==e;e=e.next)o.push(e.token)}else o=r;if(this.continuing_subword_suffix)for(let e=0;e<o.length-1;++e)o[e]+=this.continuing_subword_suffix;return e.length<this.max_length_to_cache&&this.cache.put(e,o),o}_add_node(e,t){let r=this.bpe_ranks.get(JSON.stringify([t.token,t.next.token]));void 0!==r&&(t.score=r+t.bias,e.push(t))}encode(e){let t=[];for(let r of e){if(this.ignore_merges&&this.tokens_to_ids.has(r)){t.push(r);continue}for(let e of this.bpe(r))if(this.tokens_to_ids.has(e))t.push(e);else if(this.byte_fallback){let r=Array.from(this.text_encoder.encode(e)).map(e=>`<0x${e.toString(16).toUpperCase().padStart(2,"0")}>`);r.every(e=>this.tokens_to_ids.has(e))?t.push(...r):t.push(this.unk_token)}else t.push(this.unk_token)}return t}}class S extends b{constructor(e,t){for(let[r,o]of(super(e),this.tokens_to_ids=p(t.target_lang?e.vocab[t.target_lang]:e.vocab),this.bos_token=t.bos_token,this.bos_token_id=this.tokens_to_ids.get(this.bos_token),this.eos_token=t.eos_token,this.eos_token_id=this.tokens_to_ids.get(this.eos_token),this.pad_token=t.pad_token,this.pad_token_id=this.tokens_to_ids.get(this.pad_token),this.unk_token=t.unk_token,this.unk_token_id=this.tokens_to_ids.get(this.unk_token),this.vocab=Array(this.tokens_to_ids.size),this.tokens_to_ids))this.vocab[o]=r}encode(e){return e}}class E extends o.Callable{constructor(e){super(),this.config=e}static fromConfig(e){if(null===e)return null;switch(e.type){case"BertNormalizer":return new R(e);case"Precompiled":return new e_(e);case"Sequence":return new G(e);case"Replace":return new A(e);case"NFC":return new I(e);case"NFD":return new D(e);case"NFKC":return new z(e);case"NFKD":return new j(e);case"Strip":return new V(e);case"StripAccents":return new O(e);case"Lowercase":return new N(e);case"Prepend":return new B(e);default:throw Error(`Unknown Normalizer type: ${e.type}`)}}normalize(e){throw Error("normalize should be implemented in subclass.")}_call(e){return this.normalize(e)}}class A extends E{normalize(e){let t=m(this.config.pattern);return null===t?e:e.replaceAll(t,this.config.content)}}class L extends E{form=void 0;normalize(e){return e=e.normalize(this.form)}}class I extends L{form="NFC"}class D extends L{form="NFD"}class z extends L{form="NFKC"}class j extends L{form="NFKD"}class V extends E{normalize(e){return this.config.strip_left&&this.config.strip_right?e=e.trim():(this.config.strip_left&&(e=e.trimStart()),this.config.strip_right&&(e=e.trimEnd())),e}}class O extends E{normalize(e){return e=g(e)}}class N extends E{normalize(e){return e=e.toLowerCase()}}class B extends E{normalize(e){return e=this.config.prepend+e}}class G extends E{constructor(e){super(e),this.normalizers=e.normalizers.map(e=>E.fromConfig(e))}normalize(e){return this.normalizers.reduce((e,t)=>t.normalize(e),e)}}class R extends E{_tokenize_chinese_chars(e){let t=[];for(let r=0;r<e.length;++r){let o=e[r];f(o.charCodeAt(0))?(t.push(" "),t.push(o),t.push(" ")):t.push(o)}return t.join("")}stripAccents(e){return e.normalize("NFD").replace(/\p{Mn}/gu,"")}_is_control(e){switch(e){case"	":case"\n":case"\r":return!1;default:return/^\p{Cc}|\p{Cf}|\p{Co}|\p{Cs}$/u.test(e)}}_clean_text(e){let t=[];for(let r of e){let e=r.charCodeAt(0);!(0===e||65533===e||this._is_control(r))&&(/^\s$/.test(r)?t.push(" "):t.push(r))}return t.join("")}normalize(e){return this.config.clean_text&&(e=this._clean_text(e)),this.config.handle_chinese_chars&&(e=this._tokenize_chinese_chars(e)),this.config.lowercase?(e=e.toLowerCase(),!1!==this.config.strip_accents&&(e=this.stripAccents(e))):this.config.strip_accents&&(e=this.stripAccents(e)),e}}class q extends o.Callable{static fromConfig(e){if(null===e)return null;switch(e.type){case"BertPreTokenizer":return new $(e);case"Sequence":return new eh(e);case"Whitespace":return new eg(e);case"WhitespaceSplit":return new ef(e);case"Metaspace":return new em(e);case"ByteLevel":return new W(e);case"Split":return new U(e);case"Punctuation":return new Q(e);case"Digits":return new X(e);case"Replace":return new eM(e);case"FixedLength":return new ew(e);default:throw Error(`Unknown PreTokenizer type: ${e.type}`)}}pre_tokenize_text(e,t){throw Error("pre_tokenize_text should be implemented in subclass.")}pre_tokenize(e,t){return(Array.isArray(e)?e.map(e=>this.pre_tokenize_text(e,t)):this.pre_tokenize_text(e,t)).flat()}_call(e,t){return this.pre_tokenize(e,t)}}class $ extends q{constructor(e){super(),this.pattern=RegExp(`[^\\s${M}]+|[${M}]`,"gu")}pre_tokenize_text(e,t){return e.trim().match(this.pattern)||[]}}class W extends q{constructor(e){super(),this.config=e,this.add_prefix_space=this.config.add_prefix_space,this.trim_offsets=this.config.trim_offsets,this.use_regex=this.config.use_regex??!0,this.pattern=/'s|'t|'re|'ve|'m|'ll|'d| ?\p{L}+| ?\p{N}+| ?[^\s\p{L}\p{N}]+|\s+(?!\S)|\s+/gu,this.byte_encoder=y,this.text_encoder=new TextEncoder}pre_tokenize_text(e,t){return this.add_prefix_space&&!e.startsWith(" ")&&(e=" "+e),(this.use_regex?e.match(this.pattern)||[]:[e]).map(e=>Array.from(this.text_encoder.encode(e),e=>this.byte_encoder[e]).join(""))}}class U extends q{constructor(e){super(),this.config=e,this.pattern=m(this.config.pattern,this.config.invert)}pre_tokenize_text(e,t){return null===this.pattern?[]:this.config.invert?e.match(this.pattern)||[]:this.config.behavior?.toLowerCase()==="removed"?e.split(this.pattern).filter(e=>e):function(e,t){let r=[],o=0;for(let s of e.matchAll(t)){let t=s[0];o<s.index&&r.push(e.slice(o,s.index)),t.length>0&&r.push(t),o=s.index+t.length}return o<e.length&&r.push(e.slice(o)),r}(e,this.pattern)}}class Q extends q{constructor(e){super(),this.config=e,this.pattern=RegExp(`[^${M}]+|[${M}]+`,"gu")}pre_tokenize_text(e,t){return e.match(this.pattern)||[]}}class X extends q{constructor(e){super(),this.config=e;let t=`[^\\d]+|\\d${this.config.individual_digits?"":"+"}`;this.pattern=RegExp(t,"gu")}pre_tokenize_text(e,t){return e.match(this.pattern)||[]}}class H extends o.Callable{constructor(e){super(),this.config=e}static fromConfig(e){if(null===e)return null;switch(e.type){case"TemplateProcessing":return new K(e);case"ByteLevel":return new Z(e);case"RobertaProcessing":return new Y(e);case"BertProcessing":return new J(e);case"Sequence":return new ee(e);default:throw Error(`Unknown PostProcessor type: ${e.type}`)}}post_process(e,...t){throw Error("post_process should be implemented in subclass.")}_call(e,...t){return this.post_process(e,...t)}}class J extends H{constructor(e){super(e),this.cls=e.cls[0],this.sep=e.sep[0]}post_process(e,t=null,{add_special_tokens:r=!0}={}){r&&(e=(0,s.mergeArrays)([this.cls],e,[this.sep]));let o=Array(e.length).fill(0);if(null!==t){let a=r&&this instanceof Y?[this.sep]:[],i=r?[this.sep]:[];e=(0,s.mergeArrays)(e,a,t,i),o=(0,s.mergeArrays)(o,Array(t.length+a.length+i.length).fill(1))}return{tokens:e,token_type_ids:o}}}class Y extends J{}class K extends H{constructor(e){super(e),this.single=e.single,this.pair=e.pair}post_process(e,t=null,{add_special_tokens:r=!0}={}){let o=null===t?this.single:this.pair,a=[],i=[];for(let n of o)"SpecialToken"in n?r&&(a.push(n.SpecialToken.id),i.push(n.SpecialToken.type_id)):"Sequence"in n&&("A"===n.Sequence.id?(a=(0,s.mergeArrays)(a,e),i=(0,s.mergeArrays)(i,Array(e.length).fill(n.Sequence.type_id))):"B"===n.Sequence.id&&(a=(0,s.mergeArrays)(a,t),i=(0,s.mergeArrays)(i,Array(t.length).fill(n.Sequence.type_id))));return{tokens:a,token_type_ids:i}}}class Z extends H{post_process(e,t=null){return t&&(e=(0,s.mergeArrays)(e,t)),{tokens:e}}}class ee extends H{constructor(e){super(e),this.processors=e.processors.map(e=>H.fromConfig(e))}post_process(e,t=null,r={}){let o;for(let s of this.processors)if(s instanceof Z)e=s.post_process(e).tokens,t&&(t=s.post_process(t).tokens);else{let a=s.post_process(e,t,r);e=a.tokens,o=a.token_type_ids}return{tokens:e,token_type_ids:o}}}class et extends o.Callable{constructor(e){super(),this.config=e,this.added_tokens=[],this.end_of_word_suffix=null,this.trim_offsets=e.trim_offsets}static fromConfig(e){if(null===e)return null;switch(e.type){case"WordPiece":return new ei(e);case"Metaspace":return new ep(e);case"ByteLevel":return new en(e);case"Replace":return new er(e);case"ByteFallback":return new eo(e);case"Fuse":return new es(e);case"Strip":return new ea(e);case"Sequence":return new ec(e);case"CTC":return new el(e);case"BPEDecoder":return new ed(e);default:throw Error(`Unknown Decoder type: ${e.type}`)}}_call(e){return this.decode(e)}decode(e){return this.decode_chain(e).join("")}decode_chain(e){throw Error("`decode_chain` should be implemented in subclass.")}}class er extends et{decode_chain(e){let t=m(this.config.pattern);return null===t?e:e.map(e=>e.replaceAll(t,this.config.content))}}class eo extends et{constructor(e){super(e),this.text_decoder=new TextDecoder}decode_chain(e){let t=[],r=[];for(let o of e){let e=null;if(6===o.length&&o.startsWith("<0x")&&o.endsWith(">")){let t=parseInt(o.slice(3,5),16);isNaN(t)||(e=t)}if(null!==e)r.push(e);else{if(r.length>0){let e=this.text_decoder.decode(Uint8Array.from(r));t.push(e),r=[]}t.push(o)}}if(r.length>0){let e=this.text_decoder.decode(Uint8Array.from(r));t.push(e),r=[]}return t}}class es extends et{decode_chain(e){return[e.join("")]}}class ea extends et{constructor(e){super(e),this.content=this.config.content,this.start=this.config.start,this.stop=this.config.stop}decode_chain(e){return e.map(e=>{let t=0;for(let r=0;r<this.start;++r){if(e[r]===this.content){t=r+1;continue}break}let r=e.length;for(let t=0;t<this.stop;++t){let o=e.length-t-1;if(e[o]===this.content){r=o;continue}break}return e.slice(t,r)})}}class ei extends et{constructor(e){super(e),this.cleanup=e.cleanup}decode_chain(e){return e.map((e,t)=>(0!==t&&(e=e.startsWith(this.config.prefix)?e.replace(this.config.prefix,""):" "+e),this.cleanup&&(e=h(e)),e))}}class en extends et{constructor(e){super(e),this.byte_decoder=v,this.text_decoder=new TextDecoder("utf-8",{fatal:!1,ignoreBOM:!0}),this.end_of_word_suffix=null}convert_tokens_to_string(e){let t=new Uint8Array([...e.join("")].map(e=>this.byte_decoder[e]));return this.text_decoder.decode(t)}decode_chain(e){let t=[],r=[];for(let o of e)void 0!==this.added_tokens.find(e=>e.content===o)?(r.length>0&&(t.push(this.convert_tokens_to_string(r)),r=[]),t.push(o)):r.push(o);return r.length>0&&t.push(this.convert_tokens_to_string(r)),t}}class el extends et{constructor(e){super(e),this.pad_token=this.config.pad_token,this.word_delimiter_token=this.config.word_delimiter_token,this.cleanup=this.config.cleanup}convert_tokens_to_string(e){if(0===e.length)return"";let t=[e[0]];for(let r=1;r<e.length;++r)e[r]!==t.at(-1)&&t.push(e[r]);let r=t.filter(e=>e!==this.pad_token).join("");return this.cleanup&&(r=h(r).replaceAll(this.word_delimiter_token," ").trim()),r}decode_chain(e){return[this.convert_tokens_to_string(e)]}}class ec extends et{constructor(e){super(e),this.decoders=e.decoders.map(e=>et.fromConfig(e))}decode_chain(e){return this.decoders.reduce((e,t)=>t.decode_chain(e),e)}}class ed extends et{constructor(e){super(e),this.suffix=this.config.suffix}decode_chain(e){return e.map((t,r)=>t.replaceAll(this.suffix,r===e.length-1?"":" "))}}class eu extends et{decode_chain(e){let t="";for(let r=1;r<e.length;r+=2)t+=e[r];return[t]}}class em extends q{constructor(e){super(),this.replacement=e.replacement,this.strRep=e.str_rep||this.replacement,this.prepend_scheme=e.prepend_scheme??"always"}pre_tokenize_text(e,{section_index:t}={}){let r=e.replaceAll(" ",this.strRep);return r.startsWith(this.replacement)||"always"!==this.prepend_scheme&&("first"!==this.prepend_scheme||0!==t)||(r=this.strRep+r),[r]}}class ep extends et{constructor(e){super(e),this.replacement=e.replacement}decode_chain(e){let t=[];for(let r=0;r<e.length;++r){let o=e[r].replaceAll(this.replacement," ");0==r&&o.startsWith(" ")&&(o=o.substring(1)),t.push(o)}return t}}class e_ extends E{constructor(e){super(e),this.charsmap=e.precompiled_charsmap}normalize(e){return e=(e=(e=e.replace(/[\u0001-\u0008\u000B\u000E-\u001F\u007F\u008F\u009F]/gm,"")).replace(/[\u0009\u000A\u000C\u000D\u00A0\u1680\u2000-\u200F\u2028\u2029\u202F\u205F\u2581\u3000\uFEFF\uFFFD]/gm," ")).includes("")?e.split("").map(e=>e.normalize("NFKC")).join(""):e.normalize("NFKC")}}class eh extends q{constructor(e){super(),this.tokenizers=e.pretokenizers.map(e=>q.fromConfig(e))}pre_tokenize_text(e,t){return this.tokenizers.reduce((e,r)=>r.pre_tokenize(e,t),[e])}}class eg extends q{constructor(e){super()}pre_tokenize_text(e,t){return e.match(/\w+|[^\w\s]+/g)||[]}}class ef extends q{constructor(e){super()}pre_tokenize_text(e,t){return e.match(/\S+/g)||[]}}class eM extends q{constructor(e){super(),this.config=e,this.pattern=m(this.config.pattern),this.content=this.config.content}pre_tokenize_text(e,t){return null===this.pattern?[e]:[e.replaceAll(this.pattern,this.config.content)]}}class ew extends q{constructor(e){super(),this._length=e.length}pre_tokenize_text(e,t){let r=[];for(let t=0;t<e.length;t+=this._length)r.push(e.slice(t,t+this._length));return r}}let eT=["bos_token","eos_token","unk_token","sep_token","pad_token","cls_token","mask_token"];class eP extends o.Callable{return_token_type_ids=!1;padding_side="right";constructor(e,t){for(let r of(super(),this.config=t,this.normalizer=E.fromConfig(e.normalizer),this.pre_tokenizer=q.fromConfig(e.pre_tokenizer),this.model=b.fromConfig(e.model,t),this.post_processor=H.fromConfig(e.post_processor),this.decoder=et.fromConfig(e.decoder),this.special_tokens=[],this.all_special_ids=[],this.added_tokens=[],e.added_tokens)){let e=new x(r);this.added_tokens.push(e),this.model.tokens_to_ids.set(e.content,e.id),this.model.vocab[e.id]=e.content,e.special&&(this.special_tokens.push(e.content),this.all_special_ids.push(e.id))}if(this.additional_special_tokens=t.additional_special_tokens??[],this.special_tokens.push(...this.additional_special_tokens),this.special_tokens=[...new Set(this.special_tokens)],this.decoder&&(this.decoder.added_tokens=this.added_tokens,this.decoder.end_of_word_suffix=this.model.end_of_word_suffix),this.added_tokens_splitter=new l.DictionarySplitter(this.added_tokens.map(e=>e.content)),this.added_tokens_map=new Map(this.added_tokens.map(e=>[e.content,e])),this.mask_token=this.getToken("mask_token"),this.mask_token_id=this.model.tokens_to_ids.get(this.mask_token),this.pad_token=this.getToken("pad_token","eos_token"),this.pad_token_id=this.model.tokens_to_ids.get(this.pad_token),this.sep_token=this.getToken("sep_token"),this.sep_token_id=this.model.tokens_to_ids.get(this.sep_token),this.unk_token=this.getToken("unk_token"),this.unk_token_id=this.model.tokens_to_ids.get(this.unk_token),this.bos_token=this.getToken("bos_token"),this.bos_token_id=this.model.tokens_to_ids.get(this.bos_token),this.eos_token=this.getToken("eos_token"),this.eos_token_id=this.model.tokens_to_ids.get(this.eos_token),this.model_max_length=t.model_max_length,this.remove_space=t.remove_space,this.clean_up_tokenization_spaces=t.clean_up_tokenization_spaces??!0,this.do_lowercase_and_remove_accent=t.do_lowercase_and_remove_accent??!1,t.padding_side&&(this.padding_side=t.padding_side),this.add_bos_token=t.add_bos_token,this.add_eos_token=t.add_eos_token,this.legacy=!1,this.chat_template=t.chat_template??null,Array.isArray(this.chat_template)){let e=Object.create(null);for(let{name:t,template:r}of this.chat_template){if("string"!=typeof t||"string"!=typeof r)throw Error('Chat template must be a list of objects with "name" and "template" properties');e[t]=r}this.chat_template=e}this._compiled_template_cache=new Map}getToken(...e){for(let t of e){let e=this.config[t];if(e){if("object"!=typeof e)return e;if("AddedToken"===e.__type)return e.content;throw Error(`Unknown token: ${e}`)}}return null}static async from_pretrained(e,{progress_callback:t=null,config:r=null,cache_dir:o=null,local_files_only:s=!1,revision:a="main",legacy:i=null}={}){return new this(...await u(e,{progress_callback:t,config:r,cache_dir:o,local_files_only:s,revision:a,legacy:i}))}_call(e,{text_pair:t=null,add_special_tokens:r=!0,padding:o=!1,truncation:a=null,max_length:l=null,return_tensor:c=!0,return_token_type_ids:d=null}={}){let u;let m=Array.isArray(e);if(m){if(0===e.length)throw Error("text array must be non-empty");if(null!==t){if(Array.isArray(t)){if(e.length!==t.length)throw Error("text and text_pair must have the same length")}else throw Error("text_pair must also be an array");u=e.map((e,o)=>this._encode_plus(e,{text_pair:t[o],add_special_tokens:r,return_token_type_ids:d}))}else u=e.map(e=>this._encode_plus(e,{add_special_tokens:r,return_token_type_ids:d}))}else{if(null==e)throw Error("text may not be null or undefined");if(Array.isArray(t))throw Error("When specifying `text_pair`, since `text` is a string, `text_pair` must also be a string (i.e., not an array).");u=[this._encode_plus(e,{text_pair:t,add_special_tokens:r,return_token_type_ids:d})]}if(null===l?l=this.model_max_length:null===a&&(!0===o?(console.warn("`max_length` is ignored when `padding: true` and there is no truncation strategy. To pad to max length, use `padding: 'max_length'`."),l=this.model_max_length):!1===o&&(console.warn("Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation: true` to explicitly truncate examples to max length."),a=!0)),!0===o&&(l=Math.min((0,i.max)(u.map(e=>e.input_ids.length))[0],l??1/0)),l=Math.min(l,this.model_max_length??1/0),o||a)for(let e=0;e<u.length;++e)u[e].input_ids.length!==l&&(u[e].input_ids.length>l?a&&function(e,t){for(let r of Object.keys(e))e[r].length=t}(u[e],l):o&&function(e,t,r,o){for(let a of Object.keys(e)){let i=t-e[a].length,n=r(a),l=Array(i).fill(n);e[a]="right"===o?(0,s.mergeArrays)(e[a],l):(0,s.mergeArrays)(l,e[a])}}(u[e],l,e=>"input_ids"===e?this.pad_token_id:0,this.padding_side));let p={};if(c){if(!(o&&a)&&u.some(e=>{for(let t of Object.keys(e))if(e[t].length!==u[0][t]?.length)return!0;return!1}))throw Error("Unable to create tensor, you should probably activate truncation and/or padding with 'padding=true' and 'truncation=true' to have batched tensors with the same length.");let e=[u.length,u[0].input_ids.length];for(let t of Object.keys(u[0]))p[t]=new n.Tensor("int64",BigInt64Array.from(u.flatMap(e=>e[t]).map(BigInt)),e)}else{for(let e of Object.keys(u[0]))p[e]=u.map(t=>t[e]);if(!m)for(let e of Object.keys(p))p[e]=p[e][0]}return p}_encode_text(e){if(null===e)return null;let t=this.added_tokens_splitter.split(e);for(let e=0;e<t.length;++e){let r=this.added_tokens_map.get(t[e]);r&&(r.lstrip&&e>0&&(t[e-1]=t[e-1].trimEnd()),r.rstrip&&e<t.length-1&&(t[e+1]=t[e+1].trimStart()))}return t.flatMap((e,t)=>{if(0===e.length)return[];if(this.added_tokens_map.has(e))return[e];if(!0===this.remove_space&&(e=e.trim().split(/\s+/).join(" ")),this.do_lowercase_and_remove_accent&&(e=g(e.toLowerCase())),null!==this.normalizer&&(e=this.normalizer(e)),0===e.length)return[];let r=null!==this.pre_tokenizer?this.pre_tokenizer(e,{section_index:t}):[e];return this.model(r)})}_encode_plus(e,{text_pair:t=null,add_special_tokens:r=!0,return_token_type_ids:o=null}={}){let{tokens:s,token_type_ids:a}=this._tokenize_helper(e,{pair:t,add_special_tokens:r}),i=this.model.convert_tokens_to_ids(s),n={input_ids:i,attention_mask:Array(i.length).fill(1)};return(o??this.return_token_type_ids)&&a&&(n.token_type_ids=a),n}_tokenize_helper(e,{pair:t=null,add_special_tokens:r=!1}={}){let o=this._encode_text(e),a=this._encode_text(t);return this.post_processor?this.post_processor(o,a,{add_special_tokens:r}):{tokens:(0,s.mergeArrays)(o??[],a??[])}}tokenize(e,{pair:t=null,add_special_tokens:r=!1}={}){return this._tokenize_helper(e,{pair:t,add_special_tokens:r}).tokens}encode(e,{text_pair:t=null,add_special_tokens:r=!0,return_token_type_ids:o=null}={}){return this._encode_plus(e,{text_pair:t,add_special_tokens:r,return_token_type_ids:o}).input_ids}batch_decode(e,t={}){return e instanceof n.Tensor&&(e=e.tolist()),e.map(e=>this.decode(e,t))}decode(e,t={}){if(e instanceof n.Tensor&&(e=_(e)),!Array.isArray(e)||0===e.length||!(0,s.isIntegralNumber)(e[0]))throw Error("token_ids must be a non-empty array of integers.");return this.decode_single(e,t)}decode_single(e,{skip_special_tokens:t=!1,clean_up_tokenization_spaces:r=null}){let o=this.model.convert_ids_to_tokens(e);t&&(o=o.filter(e=>!this.special_tokens.includes(e)));let s=this.decoder?this.decoder(o):o.join(" ");return this.decoder&&this.decoder.end_of_word_suffix&&(s=s.replaceAll(this.decoder.end_of_word_suffix," "),t&&(s=s.trim())),(r??this.clean_up_tokenization_spaces)&&(s=h(s)),s}get_chat_template({chat_template:e=null,tools:t=null}={}){if(this.chat_template&&"object"==typeof this.chat_template){let r=this.chat_template;if(null!==e&&Object.hasOwn(r,e))e=r[e];else if(null===e){if(null!==t&&"tool_use"in r)e=r.tool_use;else if("default"in r)e=r.default;else throw Error(`This model has multiple chat templates with no default specified! Please either pass a chat template or the name of the template you wish to use to the 'chat_template' argument. Available template names are ${Object.keys(r).sort()}.`)}}else if(null===e){if(this.chat_template)e=this.chat_template;else throw Error("Cannot use apply_chat_template() because tokenizer.chat_template is not set and no template argument was passed! For information about writing templates and setting the tokenizer.chat_template attribute, please see the documentation at https://huggingface.co/docs/transformers/main/en/chat_templating")}return e}apply_chat_template(e,{tools:t=null,documents:r=null,chat_template:o=null,add_generation_prompt:s=!1,tokenize:a=!0,padding:i=!1,truncation:n=!1,max_length:l=null,return_tensor:d=!0,return_dict:u=!1,tokenizer_kwargs:m={},...p}={}){if("string"!=typeof(o=this.get_chat_template({chat_template:o,tools:t})))throw Error(`chat_template must be a string, but got ${typeof o}`);let _=this._compiled_template_cache.get(o);void 0===_&&(_=new c.Template(o),this._compiled_template_cache.set(o,_));let h=Object.create(null);for(let e of eT){let t=this.getToken(e);t&&(h[e]=t)}let g=_.render({messages:e,add_generation_prompt:s,tools:t,documents:r,...h,...p});if(a){let e=this._call(g,{add_special_tokens:!1,padding:i,truncation:n,max_length:l,return_tensor:d,...m});return u?e:e.input_ids}return g}}class ex extends eP{return_token_type_ids=!0}class eb extends eP{return_token_type_ids=!0}class eF extends eP{return_token_type_ids=!0}class ek extends eP{return_token_type_ids=!0}class ey extends eP{return_token_type_ids=!0}class ev extends eP{return_token_type_ids=!0}class eC extends eP{return_token_type_ids=!0}class eS extends eP{return_token_type_ids=!0}class eE extends eP{return_token_type_ids=!0}class eA extends eP{}class eL extends eP{}class eI extends eP{return_token_type_ids=!0;constructor(e,t){super(e,t),console.warn('WARNING: `XLMTokenizer` is not yet supported by Hugging Face\'s "fast" tokenizers library. Therefore, you may experience slightly inaccurate results.')}}class eD extends eP{return_token_type_ids=!0}class ez extends eP{}class ej extends eP{}class eV extends eP{}class eO extends eP{constructor(e,t){super(e,t),this.languageRegex=/^[a-z]{2}_[A-Z]{2}$/,this.language_codes=this.special_tokens.filter(e=>this.languageRegex.test(e)),this.lang_to_token=e=>e}_build_translation_inputs(e,t,r){return eK(this,e,t,r)}}class eN extends eO{}class eB extends eP{}class eG extends eP{}class eR extends eP{padding_side="left";constructor(e,t){super(e,t),this.legacy=t.legacy??!0,this.legacy||(this.normalizer=null,this.pre_tokenizer=new em({replacement:"",prepend_scheme:"first"}))}_encode_text(e){if(null===e)return null;if(this.legacy||0===e.length)return super._encode_text(e);let t=super._encode_text(""+e.replaceAll(""," "));return t.length>1&&""===t[0]&&this.special_tokens.includes(t[1])&&(t=t.slice(1)),t}}class eq extends eP{}class e$ extends eP{}class eW extends eP{}class eU extends eP{}class eQ extends eP{}class eX extends eP{}class eH extends eP{}class eJ extends eP{}class eY extends eP{}function eK(e,t,r,o){if(!("language_codes"in e)||!Array.isArray(e.language_codes))throw Error("Tokenizer must have `language_codes` attribute set and it should be an array of language ids.");if(!("languageRegex"in e)||!(e.languageRegex instanceof RegExp))throw Error("Tokenizer must have `languageRegex` attribute set and it should be a regular expression.");if(!("lang_to_token"in e)||"function"!=typeof e.lang_to_token)throw Error("Tokenizer must have `lang_to_token` attribute set and it should be a function.");let s=o.src_lang,a=o.tgt_lang;if(!e.language_codes.includes(a))throw Error(`Target language code "${a}" is not valid. Must be one of: {${e.language_codes.join(", ")}}`);if(void 0!==s){if(!e.language_codes.includes(s))throw Error(`Source language code "${s}" is not valid. Must be one of: {${e.language_codes.join(", ")}}`);for(let t of e.post_processor.config.single)if("SpecialToken"in t&&e.languageRegex.test(t.SpecialToken.id)){t.SpecialToken.id=e.lang_to_token(s);break}}return o.forced_bos_token_id=e.model.convert_tokens_to_ids([e.lang_to_token(a)])[0],e._call(t,r)}class eZ extends eP{constructor(e,t){super(e,t),this.languageRegex=/^[a-z]{3}_[A-Z][a-z]{3}$/,this.language_codes=this.special_tokens.filter(e=>this.languageRegex.test(e)),this.lang_to_token=e=>e}_build_translation_inputs(e,t,r){return eK(this,e,t,r)}}class e0 extends eP{constructor(e,t){super(e,t),this.languageRegex=/^__[a-z]{2,3}__$/,this.language_codes=this.special_tokens.filter(e=>this.languageRegex.test(e)).map(e=>e.slice(2,-2)),this.lang_to_token=e=>`__${e}__`}_build_translation_inputs(e,t,r){return eK(this,e,t,r)}}class e1 extends eP{get timestamp_begin(){return this.model.convert_tokens_to_ids(["<|notimestamps|>"])[0]+1}_decode_asr(e,{return_timestamps:t=!1,return_language:r=!1,time_precision:o=null,force_full_sequences:s=!0}={}){if(null===o)throw Error("Must specify time_precision");let a=null,n="word"===t;function l(){return{language:a,timestamp:[null,null],text:""}}let c=[],u=l(),m=0,p=this.timestamp_begin,_=p+1500,h=[],g=[],f=!1,M=null,T=new Set(this.all_special_ids);for(let r of e){let e=r.tokens,s=n?r.token_timestamps:null,P=null,x=p;if("stride"in r){let[t,s,a]=r.stride;if(m-=s,M=t-a,s&&(x=s/o+p),a)for(let t=e.length-1;t>=0;--t){let r=Number(e[t]);if(r>=p){if(null!==P&&(r-p)*o<M)break;P=r}}}let b=[],F=[];for(let r=0;r<e.length;++r){let M=Number(e[r]);if(T.has(M)){let e=this.decode([M]),r=d.WHISPER_LANGUAGE_MAPPING.get(e.slice(2,-2));if(void 0!==r){if(null!==a&&r!==a&&!t){h.push(b);let e=this.findLongestCommonSequence(h)[0],t=this.decode(e);u.text=t,c.push(u),h=[],b=[],u=l()}a=u.language=r}}else if(M>=p&&M<=_){let e=(M-p)*o+m,t=(0,i.round)(e,2);if(null!==P&&M>=P)f=!0;else if(f||h.length>0&&M<x)f=!1;else if(null===u.timestamp[0])u.timestamp[0]=t;else if(t===u.timestamp[0]);else{u.timestamp[1]=t,h.push(b),n&&g.push(F);let[e,r]=this.findLongestCommonSequence(h,g),o=this.decode(e);u.text=o,n&&(u.words=this.collateWordTimestamps(e,r,a)),c.push(u),h=[],b=[],g=[],F=[],u=l()}}else if(b.push(M),n){let e,t=(0,i.round)(s[r]+m,2);if(r+1<s.length){e=(0,i.round)(s[r+1]+m,2);let a=this.decode([M]);w.test(a)&&(e=(0,i.round)(Math.min(t+o,e),2))}else e=null;F.push([t,e])}}if("stride"in r){let[e,t,o]=r.stride;m+=e-o}b.length>0?(h.push(b),n&&g.push(F)):h.every(e=>0===e.length)&&(u=l(),h=[],b=[],g=[],F=[])}if(h.length>0){if(s&&t)throw Error("Whisper did not predict an ending timestamp, which can happen if audio is cut off in the middle of a word. Also make sure WhisperTimeStampLogitsProcessor was used during generation.");let[e,r]=this.findLongestCommonSequence(h,g),o=this.decode(e);u.text=o,n&&(u.words=this.collateWordTimestamps(e,r,a)),c.push(u)}let P=Object.create(null),x=c.map(e=>e.text).join("");if(t||r){for(let e=0;e<c.length;++e){let o=c[e];t||delete o.timestamp,r||delete o.language}if(n){let e=[];for(let t of c)for(let r of t.words)e.push(r);P={chunks:e}}else P={chunks:c}}return[x,P]}findLongestCommonSequence(e,t=null){let r=e[0],o=r.length,s=[],a=Array.isArray(t)&&t.length>0,i=a?[]:null,n=a?t[0]:null;for(let l=1;l<e.length;++l){let c=e[l],d=0,u=[o,o,0,0],m=c.length;for(let e=1;e<o+m;++e){let s;let i=Math.max(0,o-e),p=Math.min(o,o+m-e),_=r.slice(i,p),h=Math.max(0,e-o),g=Math.min(m,e),f=c.slice(h,g);if(_.length!==f.length)throw Error("There is a bug within whisper `decode_asr` function, please report it. Dropping to prevent bad inference.");s=a?_.filter((e,r)=>e===f[r]&&n[i+r]<=t[l][h+r]).length:_.filter((e,t)=>e===f[t]).length;let M=e/1e4,w=s/e+M;s>1&&w>d&&(d=w,u=[i,p,h,g])}let[p,_,h,g]=u,f=Math.floor((_+p)/2),M=Math.floor((g+h)/2);s.push(...r.slice(0,f)),o=(r=c.slice(M)).length,a&&(i.push(...n.slice(0,f)),n=t[l].slice(M))}return(s.push(...r),a)?(i.push(...n),[s,i]):[s,[]]}collateWordTimestamps(e,t,r){let[o,s,a]=this.combineTokensIntoWords(e,r),i=[];for(let e=0;e<o.length;++e){let r=a[e];i.push({text:o[e],timestamp:[t[r.at(0)][0],t[r.at(-1)][1]]})}return i}combineTokensIntoWords(e,t,r="\"'\xa1\xbf([{-",o="\"'.,!?:)]}"){let s,a,i;return["chinese","japanese","thai","lao","myanmar"].includes(t=t??"english")?[s,a,i]=this.splitTokensOnUnicode(e):[s,a,i]=this.splitTokensOnSpaces(e),this.mergePunctuations(s,a,i,r,o)}decode(e,t){let r;return t?.decode_with_timestamps?(e instanceof n.Tensor&&(e=_(e)),r=this.decodeWithTimestamps(e,t)):r=super.decode(e,t),r}decodeWithTimestamps(e,t){let r=t?.time_precision??.02,o=Array.from(this.all_special_ids).at(-1)+1,s=[[]];for(let t of e)if((t=Number(t))>=o){let e=((t-o)*r).toFixed(2);s.push(`<|${e}|>`),s.push([])}else s[s.length-1].push(t);return(s=s.map(e=>"string"==typeof e?e:super.decode(e,t))).join("")}splitTokensOnUnicode(e){let t=this.decode(e,{decode_with_timestamps:!0}),r=[],o=[],s=[],a=[],i=[],n=0;for(let l=0;l<e.length;++l){let c=e[l];a.push(c),i.push(l);let d=this.decode(a,{decode_with_timestamps:!0});d.includes("")&&""!==t[n+d.indexOf("")]||(r.push(d),o.push(a),s.push(i),a=[],i=[],n+=d.length)}return[r,o,s]}splitTokensOnSpaces(e){let[t,r,o]=this.splitTokensOnUnicode(e),s=[],a=[],i=[],n=RegExp(`^[${M}]$`,"gu");for(let e=0;e<t.length;++e){let l=t[e],c=r[e],d=o[e],u=c[0]>=this.model.tokens_to_ids.get("<|endoftext|>"),m=l.startsWith(" "),p=l.trim(),_=n.test(p);if(u||m||_||0===s.length)s.push(l),a.push(c),i.push(d);else{let e=s.length-1;s[e]+=l,a[e].push(...c),i[e].push(...d)}}return[s,a,i]}mergePunctuations(e,t,r,o,a){let i=structuredClone(e),n=structuredClone(t),l=structuredClone(r),c=i.length-2,d=i.length-1;for(;c>=0;)i[c].startsWith(" ")&&o.includes(i[c].trim())?(i[d]=i[c]+i[d],n[d]=(0,s.mergeArrays)(n[c],n[d]),l[d]=(0,s.mergeArrays)(l[c],l[d]),i[c]="",n[c]=[],l[c]=[]):d=c,--c;for(c=0,d=1;d<i.length;)!i[c].endsWith(" ")&&a.includes(i[d])?(i[c]+=i[d],n[c]=(0,s.mergeArrays)(n[c],n[d]),l[c]=(0,s.mergeArrays)(l[c],l[d]),i[d]="",n[d]=[],l[d]=[]):c=d,++d;return[i.filter(e=>e),n.filter(e=>e.length>0),l.filter(e=>e.length>0)]}}class e2 extends eP{}class e3 extends eP{}class e4 extends eP{}class e5 extends eP{constructor(e,t){super(e,t),this.languageRegex=/^(>>\w+<<)\s*/g,this.supported_language_codes=this.model.vocab.filter(e=>this.languageRegex.test(e)),console.warn('WARNING: `MarianTokenizer` is not yet supported by Hugging Face\'s "fast" tokenizers library. Therefore, you may experience slightly inaccurate results.')}_encode_text(e){if(null===e)return null;let[t,...r]=e.trim().split(this.languageRegex);if(0===r.length)return super._encode_text(t);if(2===r.length){let[e,t]=r;return this.supported_language_codes.includes(e)||console.warn(`Unsupported language code "${e}" detected, which may lead to unexpected behavior. Should be one of: ${JSON.stringify(this.supported_language_codes)}`),(0,s.mergeArrays)([e],super._encode_text(t))}}}class e8 extends eP{}class e6 extends eP{}class e9 extends eP{}class e7 extends eP{}class te extends eP{}class tt extends eP{constructor(e,t){super(e,t),this.decoder=new eu({})}}class tr extends eP{}class to extends eP{}class ts{static TOKENIZER_CLASS_MAPPING={T5Tokenizer:ez,DistilBertTokenizer:eA,CamembertTokenizer:eL,DebertaTokenizer:ey,DebertaV2Tokenizer:ev,BertTokenizer:ex,HerbertTokenizer:eC,ConvBertTokenizer:eS,RoFormerTokenizer:eE,XLMTokenizer:eI,ElectraTokenizer:eD,MobileBertTokenizer:eF,SqueezeBertTokenizer:ek,AlbertTokenizer:eb,GPT2Tokenizer:ej,BartTokenizer:eV,MBartTokenizer:eO,MBart50Tokenizer:eN,RobertaTokenizer:eB,WhisperTokenizer:e1,CodeGenTokenizer:e2,CLIPTokenizer:e3,SiglipTokenizer:e4,MarianTokenizer:e5,BloomTokenizer:eG,NllbTokenizer:eZ,M2M100Tokenizer:e0,LlamaTokenizer:eR,CodeLlamaTokenizer:eq,XLMRobertaTokenizer:e$,MPNetTokenizer:eW,FalconTokenizer:eU,GPTNeoXTokenizer:eQ,EsmTokenizer:eX,Wav2Vec2CTCTokenizer:e8,BlenderbotTokenizer:e6,BlenderbotSmallTokenizer:e9,SpeechT5Tokenizer:e7,NougatTokenizer:te,VitsTokenizer:tt,Qwen2Tokenizer:eH,GemmaTokenizer:eJ,Grok1Tokenizer:eY,CohereTokenizer:tr,MgpstrTokenizer:to,PreTrainedTokenizer:eP};static async from_pretrained(e,{progress_callback:t=null,config:r=null,cache_dir:o=null,local_files_only:s=!1,revision:a="main",legacy:i=null}={}){let[n,l]=await u(e,{progress_callback:t,config:r,cache_dir:o,local_files_only:s,revision:a,legacy:i}),c=l.tokenizer_class?.replace(/Fast$/,"")??"PreTrainedTokenizer",d=this.TOKENIZER_CLASS_MAPPING[c];return d||(console.warn(`Unknown tokenizer class "${c}", attempting to construct from base class.`),d=eP),new d(n,l)}}},"./src/utils/audio.js":(e,t,r)=>{r.r(t),r.d(t,{RawAudio:()=>b,hamming:()=>p,hanning:()=>m,mel_filter_bank:()=>M,read_audio:()=>d,spectrogram:()=>T,window_function:()=>P});var o=r("./src/utils/hub.js"),s=r("./src/utils/maths.js"),a=r("./src/utils/core.js"),n=r("./src/env.js"),l=r("./src/utils/tensor.js"),c=r("?7992");async function d(e,t){let r;if("undefined"==typeof AudioContext)throw Error("Unable to load audio from path/URL since `AudioContext` is not available in your environment. Instead, audio data should be passed directly to the pipeline/processor. For more information and some example code, see https://huggingface.co/docs/transformers.js/guides/node-audio-processing.");let s=await (await (0,o.getFile)(e)).arrayBuffer(),a=new AudioContext({sampleRate:t});void 0===t&&console.warn(`No sampling rate provided, using default of ${a.sampleRate}Hz.`);let i=await a.decodeAudioData(s);if(2===i.numberOfChannels){let e=Math.sqrt(2),t=i.getChannelData(0),o=i.getChannelData(1);r=new Float32Array(t.length);for(let s=0;s<i.length;++s)r[s]=e*(t[s]+o[s])/2}else r=i.getChannelData(0);return r}function u(e,t){if(e<1)return new Float64Array;if(1===e)return new Float64Array([1]);let r=1-t,o=2*Math.PI/(e-1),s=new Float64Array(e);for(let a=0;a<e;++a)s[a]=t-r*Math.cos(a*o);return s}function m(e){return u(e,.5)}function p(e){return u(e,.54)}let _={htk:e=>2595*Math.log10(1+e/700),kaldi:e=>1127*Math.log(1+e/700),slaney:(e,t=1e3,r=15,o=27/Math.log(6.4))=>e>=t?r+Math.log(e/t)*o:3*e/200};function h(e,t="htk"){let r=_[t];if(!r)throw Error('mel_scale should be one of "htk", "slaney" or "kaldi".');return"number"==typeof e?r(e):e.map(e=>r(e))}let g={htk:e=>700*(10**(e/2595)-1),kaldi:e=>700*(Math.exp(e/1127)-1),slaney:(e,t=1e3,r=15,o=Math.log(6.4)/27)=>e>=r?t*Math.exp(o*(e-r)):200*e/3};function f(e,t,r){let o=(t-e)/(r-1);return Float64Array.from({length:r},(t,r)=>e+o*r)}function M(e,t,r,o,s,a=null,i="htk",n=!1){let l;if(null!==a&&"slaney"!==a)throw Error('norm must be one of null or "slaney"');if(e<2)throw Error(`Require num_frequency_bins: ${e} >= 2`);if(r>o)throw Error(`Require min_frequency: ${r} <= max_frequency: ${o}`);let c=f(h(r,i),h(o,i),t+2),d=function(e,t="htk"){let r=g[t];if(!r)throw Error('mel_scale should be one of "htk", "slaney" or "kaldi".');return"number"==typeof e?r(e):e.map(e=>r(e))}(c,i);if(n){let t=s/((e-1)*2);l=h(Float64Array.from({length:e},(e,r)=>r*t),i),d=c}else l=f(0,Math.floor(s/2),e);let u=function(e,t){let r=Float64Array.from({length:t.length-1},(e,r)=>t[r+1]-t[r]),o=Array.from({length:e.length},()=>Array(t.length));for(let r=0;r<e.length;++r){let s=o[r];for(let o=0;o<t.length;++o)s[o]=t[o]-e[r]}let s=t.length-2,a=Array.from({length:s},()=>Array(e.length));for(let t=0;t<e.length;++t){let e=o[t];for(let o=0;o<s;++o){let s=-e[o]/r[o],i=e[o+2]/r[o+1];a[o][t]=Math.max(0,Math.min(s,i))}}return a}(l,d);if(null!==a&&"slaney"===a)for(let r=0;r<t;++r){let t=u[r],o=2/(d[r+2]-d[r]);for(let r=0;r<e;++r)t[r]*=o}return u}function w(e,t,r,o,a){if(r<=0)throw Error("reference must be greater than zero");if(o<=0)throw Error("min_value must be greater than zero");let i=Math.log10(r=Math.max(o,r));for(let r=0;r<e.length;++r)e[r]=t*Math.log10(Math.max(o,e[r])-i);if(null!==a){if(a<=0)throw Error("db_range must be greater than zero");let t=(0,s.max)(e)[0]-a;for(let r=0;r<e.length;++r)e[r]=Math.max(e[r],t)}return e}async function T(e,t,r,o,{fft_length:i=null,power:n=1,center:c=!0,pad_mode:d="reflect",onesided:u=!0,preemphasis:m=null,preemphasis_htk_flavor:p=!0,mel_filters:_=null,mel_floor:h=1e-10,log_mel:g=null,reference:f=1,min_value:M=1e-10,db_range:P=null,remove_dc_offset:x=null,min_num_frames:b=null,max_num_frames:F=null,do_pad:k=!0,transpose:y=!1,mel_offset:v=0}={}){let C=t.length;if(null===i&&(i=r),r>i)throw Error(`frame_length (${r}) may not be larger than fft_length (${i})`);if(C!==r)throw Error(`Length of the window (${C}) must equal frame_length (${r})`);if(o<=0)throw Error("hop_length must be greater than zero");if(null===n&&null!==_)throw Error("You have provided `mel_filters` but `power` is `None`. Mel spectrogram computation is not yet supported for complex-valued spectrogram. Specify `power` to fix this issue.");if(!p)throw Error("`preemphasis_htk_flavor=false` is not currently supported.");if(c)switch(d){case"reflect":{let t=Math.floor((i-1)/2)+1;e=function(e,t,r){let o=new e.constructor(e.length+t+r),s=e.length-1;for(let r=0;r<e.length;++r)o[t+r]=e[r];for(let r=1;r<=t;++r)o[t-r]=e[(0,a.calculateReflectOffset)(r,s)];for(let i=1;i<=r;++i)o[s+t+i]=e[(0,a.calculateReflectOffset)(s-i,s)];return o}(e,t,t);break}case"constant":{let t=Math.floor(i/2),r=new e.constructor(e.length+2*t);r.set(e,t),e=r;break}default:throw Error(`pad_mode="${d}" not implemented yet.`)}let S=Math.floor(1+Math.floor((e.length-r)/o));null!==b&&S<b&&(S=b);let E=u?Math.floor(i/2)+1:i,A=S,L=S;null!==F&&(F>S?k&&(L=F):L=A=F);let I=new s.FFT(i),D=new Float64Array(i),z=new Float64Array(I.outputBufferSize),j=new Float32Array(E*L);for(let s=0;s<A;++s){let a=s*o,i=Math.min(e.length-a,r);i!==r&&D.fill(0,0,r);for(let t=0;t<i;++t)D[t]=e[a+t];if(x){let e=0;for(let t=0;t<i;++t)e+=D[t];let t=e/i;for(let e=0;e<i;++e)D[e]-=t}if(null!==m){for(let e=i-1;e>=1;--e)D[e]-=m*D[e-1];D[0]*=1-m}for(let e=0;e<t.length;++e)D[e]*=t[e];I.realTransform(z,D);for(let e=0;e<E;++e){let t=e<<1;j[e*L+s]=z[t]**2+z[t+1]**2}}if(null!==n&&2!==n){let e=n/2;for(let t=0;t<j.length;++t)j[t]**=e}let V=_.length,O=await (0,l.matmul)(new l.Tensor("float32",_.flat(),[V,E]),new l.Tensor("float32",j,[E,L]));y&&(O=O.transpose(1,0));let N=O.data;for(let e=0;e<N.length;++e)N[e]=v+Math.max(h,N[e]);if(null!==n&&null!==g){let e=Math.min(N.length,A*V);switch(g){case"log":for(let t=0;t<e;++t)N[t]=Math.log(N[t]);break;case"log10":for(let t=0;t<e;++t)N[t]=Math.log10(N[t]);break;case"dB":if(1===n)!function(e,t=1,r=1e-5,o=null){w(e,20,t,r,o)}(N,f,M,P);else if(2===n)!function(e,t=1,r=1e-10,o=null){w(e,10,t,r,o)}(N,f,M,P);else throw Error(`Cannot use log_mel option '${g}' with power ${n}`);break;default:throw Error(`log_mel must be one of null, 'log', 'log10' or 'dB'. Got '${g}'`)}}return O}function P(e,t,{periodic:r=!0,frame_length:o=null,center:s=!0}={}){let a;let i=r?e+1:e;switch(t){case"boxcar":a=new Float64Array(i).fill(1);break;case"hann":case"hann_window":a=m(i);break;case"hamming":a=p(i);break;case"povey":a=m(i).map(e=>Math.pow(e,.85));break;default:throw Error(`Unknown window type ${t}.`)}if(r&&(a=a.subarray(0,e)),null===o)return a;if(e>o)throw Error(`Length of the window (${e}) may not be larger than frame_length (${o})`);return a}function x(e,t,r){for(let o=0;o<r.length;++o)e.setUint8(t+o,r.charCodeAt(o))}class b{constructor(e,t){this.audio=e,this.sampling_rate=t}toWav(){return function(e,t){let r=44,o=new ArrayBuffer(44+4*e.length),s=new DataView(o);x(s,0,"RIFF"),s.setUint32(4,36+4*e.length,!0),x(s,8,"WAVE"),x(s,12,"fmt "),s.setUint32(16,16,!0),s.setUint16(20,3,!0),s.setUint16(22,1,!0),s.setUint32(24,t,!0),s.setUint32(28,4*t,!0),s.setUint16(32,4,!0),s.setUint16(34,32,!0),x(s,36,"data"),s.setUint32(40,4*e.length,!0);for(let t=0;t<e.length;++t,r+=4)s.setFloat32(r,e[t],!0);return o}(this.audio,this.sampling_rate)}toBlob(){return new Blob([this.toWav()],{type:"audio/wav"})}async save(e){let t;if(n.apis.IS_BROWSER_ENV){if(n.apis.IS_WEBWORKER_ENV)throw Error("Unable to save a file from a Web Worker.");t=a.saveBlob}else if(n.apis.IS_FS_AVAILABLE)t=async(e,t)=>{let r=await t.arrayBuffer();c.writeFileSync(e,i.from(r))};else throw Error("Unable to save because filesystem is disabled in this environment.");await t(e,this.toBlob())}}},"./src/utils/constants.js":(e,t,r)=>{r.r(t),r.d(t,{CHAT_TEMPLATE_NAME:()=>l,CONFIG_NAME:()=>s,FEATURE_EXTRACTOR_NAME:()=>a,GENERATION_CONFIG_NAME:()=>c,GITHUB_ISSUE_URL:()=>o,IMAGE_PROCESSOR_NAME:()=>i,PROCESSOR_NAME:()=>n});let o="https://github.com/huggingface/transformers.js/issues/new/choose",s="config.json",a="preprocessor_config.json",i=a,n="processor_config.json",l="chat_template.jinja",c="generation_config.json"},"./src/utils/core.js":(e,t,r)=>{function o(e,t){e&&e(t)}function s(e){return Object.fromEntries(Object.entries(e).map(([e,t])=>[t,e]))}function a(e){return e.replace(/[.*+?^${}()|[\]\\]/g,"\\$&")}function i(e){return e?.prototype?.__proto__?.constructor?.name==="TypedArray"}function n(e){return Number.isInteger(e)||"bigint"==typeof e}function l(e){return null==e||-1===e}function c(e){let t=[],r=e;for(;Array.isArray(r);)t.push(r.length),r=r[0];return t}function d(e,t,r){let o=e[t];if(void 0!==o)return delete e[t],o;if(void 0===r)throw Error(`Key ${t} does not exist in object.`);return r}function u(...e){return Array.prototype.concat.apply([],e)}function m(...e){return e.reduce((e,t)=>e.flatMap(e=>t.map(t=>[e,t])))}function p(e,t){return Math.abs((e+t)%(2*t)-t)}function _(e,t){let r=URL.createObjectURL(t),o=document.createElement("a");o.href=r,o.download=e,o.click(),o.remove(),URL.revokeObjectURL(r)}function h(e,t){return Object.assign({},...t.map(t=>{if(void 0!==e[t])return{[t]:e[t]}}))}function g(e){let t=0;for(let r of e)++t;return t}function f(e,t){let r=0;for(let o of e)o===t&&++r;return r}r.r(t),r.d(t,{calculateDimensions:()=>c,calculateReflectOffset:()=>p,count:()=>f,dispatchCallback:()=>o,escapeRegExp:()=>a,isIntegralNumber:()=>n,isNullishDimension:()=>l,isTypedArray:()=>i,len:()=>g,mergeArrays:()=>u,pick:()=>h,pop:()=>d,product:()=>m,reverseDictionary:()=>s,saveBlob:()=>_})},"./src/utils/data-structures.js":(e,t,r)=>{r.r(t),r.d(t,{CharTrie:()=>s,DictionarySplitter:()=>l,LRUCache:()=>c,PriorityQueue:()=>o,TokenLattice:()=>i});class o{constructor(e=(e,t)=>e>t,t=1/0){this._heap=[],this._comparator=e,this._maxSize=t}get size(){return this._heap.length}isEmpty(){return 0===this.size}peek(){return this._heap[0]}push(...e){return this.extend(e)}extend(e){for(let t of e)if(this.size<this._maxSize)this._heap.push(t),this._siftUp();else{let e=this._smallest();this._comparator(t,this._heap[e])&&(this._heap[e]=t,this._siftUpFrom(e))}return this.size}pop(){let e=this.peek(),t=this.size-1;return t>0&&this._swap(0,t),this._heap.pop(),this._siftDown(),e}replace(e){let t=this.peek();return this._heap[0]=e,this._siftDown(),t}_parent(e){return(e+1>>>1)-1}_left(e){return(e<<1)+1}_right(e){return e+1<<1}_greater(e,t){return this._comparator(this._heap[e],this._heap[t])}_swap(e,t){let r=this._heap[e];this._heap[e]=this._heap[t],this._heap[t]=r}_siftUp(){this._siftUpFrom(this.size-1)}_siftUpFrom(e){for(;e>0&&this._greater(e,this._parent(e));)this._swap(e,this._parent(e)),e=this._parent(e)}_siftDown(){let e=0;for(;this._left(e)<this.size&&this._greater(this._left(e),e)||this._right(e)<this.size&&this._greater(this._right(e),e);){let t=this._right(e)<this.size&&this._greater(this._right(e),this._left(e))?this._right(e):this._left(e);this._swap(e,t),e=t}}_smallest(){return 2**Math.floor(Math.log2(this.size))-1}}class s{constructor(){this.root=a.default()}extend(e){for(let t of e)this.push(t)}push(e){let t=this.root;for(let r of e){let e=t.children.get(r);void 0===e&&(e=a.default(),t.children.set(r,e)),t=e}t.isLeaf=!0}*commonPrefixSearch(e){let t=this.root;if(void 0===t)return;let r="";for(let o of e){if(r+=o,void 0===(t=t.children.get(o)))return;t.isLeaf&&(yield r)}}}class a{constructor(e,t){this.isLeaf=e,this.children=t}static default(){return new a(!1,new Map)}}class i{constructor(e,t,r){this.chars=Array.from(e),this.len=this.chars.length,this.bosTokenId=t,this.eosTokenId=r,this.nodes=[],this.beginNodes=Array.from({length:this.len+1},()=>[]),this.endNodes=Array.from({length:this.len+1},()=>[]);let o=new n(this.bosTokenId,0,0,0,0),s=new n(this.eosTokenId,1,this.len,0,0);this.nodes.push(o.clone()),this.nodes.push(s.clone()),this.beginNodes[this.len].push(s),this.endNodes[0].push(o)}insert(e,t,r,o){let s=new n(o,this.nodes.length,e,t,r);this.beginNodes[e].push(s),this.endNodes[e+t].push(s),this.nodes.push(s)}viterbi(){let e=this.len,t=0;for(;t<=e;){if(0==this.beginNodes[t].length)return[];for(let e of this.beginNodes[t]){e.prev=null;let r=0,o=null;for(let s of this.endNodes[t]){let t=s.backtraceScore+e.score;(null===o||t>r)&&(o=s.clone(),r=t)}if(null===o)return[];e.prev=o,e.backtraceScore=r}++t}let r=[],o=this.beginNodes[e][0].prev;if(null===o)return[];let s=o.clone();for(;null!==s.prev;)r.push(s.clone()),s=s.clone().prev.clone();return r.reverse(),r}piece(e){return this.chars.slice(e.pos,e.pos+e.length).join("")}tokens(){return this.viterbi().map(e=>this.piece(e))}tokenIds(){return this.viterbi().map(e=>e.tokenId)}}class n{constructor(e,t,r,o,s){this.tokenId=e,this.nodeId=t,this.pos=r,this.length=o,this.score=s,this.prev=null,this.backtraceScore=0}clone(){let e=new n(this.tokenId,this.nodeId,this.pos,this.length,this.score);return e.prev=this.prev,e.backtraceScore=this.backtraceScore,e}}class l{constructor(e){this.trie=this._buildTrie(e)}_buildTrie(e){let t=Object.create(null);for(let r of e){let e=t;for(let t=0;t<r.length;++t)e=e[r[t]]??=Object.create(null);e.end=r}return t}split(e){let t=[],r=e.length,o=0,s=0;for(;s<r;){let a=this.trie,i=null,n=s;for(;n<r&&(a=a[e[n]]);)a.end&&(i=a.end),++n;i?(s>o&&t.push(e.slice(o,s)),t.push(i),s+=i.length,o=s):++s}return o<r&&t.push(e.slice(o)),t}}class c{constructor(e){this.capacity=e,this.cache=new Map}get(e){if(!this.cache.has(e))return;let t=this.cache.get(e);return this.cache.delete(e),this.cache.set(e,t),t}put(e,t){this.cache.has(e)&&this.cache.delete(e),this.cache.set(e,t),this.cache.size>this.capacity&&this.cache.delete(this.cache.keys().next().value)}clear(){this.cache.clear()}}},"./src/utils/devices.js":(e,t,r)=>{r.r(t),r.d(t,{DEVICE_TYPES:()=>o});let o=Object.freeze({auto:"auto",gpu:"gpu",cpu:"cpu",wasm:"wasm",webgpu:"webgpu",cuda:"cuda",dml:"dml",webnn:"webnn","webnn-npu":"webnn-npu","webnn-gpu":"webnn-gpu","webnn-cpu":"webnn-cpu"})},"./src/utils/dtypes.js":(e,t,r)=>{r.r(t),r.d(t,{DATA_TYPES:()=>i,DEFAULT_DEVICE_DTYPE_MAPPING:()=>n,DEFAULT_DTYPE_SUFFIX_MAPPING:()=>l,isWebGpuFp16Supported:()=>a});var o=r("./src/env.js"),s=r("./src/utils/devices.js");let a=function(){let e;return async function(){if(void 0===e){if(o.apis.IS_WEBGPU_AVAILABLE)try{e=(await navigator.gpu.requestAdapter()).features.has("shader-f16")}catch(t){e=!1}else e=!1}return e}}(),i=Object.freeze({auto:"auto",fp32:"fp32",fp16:"fp16",q8:"q8",int8:"int8",uint8:"uint8",q4:"q4",bnb4:"bnb4",q4f16:"q4f16"}),n=Object.freeze({[s.DEVICE_TYPES.wasm]:i.q8}),l=Object.freeze({[i.fp32]:"",[i.fp16]:"_fp16",[i.int8]:"_int8",[i.uint8]:"_uint8",[i.q8]:"_quantized",[i.q4]:"_q4",[i.q4f16]:"_q4f16",[i.bnb4]:"_bnb4"})},"./src/utils/generic.js":(e,t,r)=>{r.r(t),r.d(t,{Callable:()=>o});let o=class{constructor(){let e=function(...t){return e._call(...t)};return Object.setPrototypeOf(e,new.target.prototype)}_call(...e){throw Error("Must implement _call method in subclass")}}},"./src/utils/hub.js":(e,t,r)=>{r.r(t),r.d(t,{MAX_EXTERNAL_DATA_CHUNKS:()=>l,getFile:()=>p,getModelFile:()=>f,getModelJSON:()=>w,getModelText:()=>M});var o=r("?7992"),s=r("?5af5"),i=r("./src/env.js"),n=r("./src/utils/core.js");let l=100,c={txt:"text/plain",html:"text/html",css:"text/css",js:"text/javascript",json:"application/json",png:"image/png",jpg:"image/jpeg",jpeg:"image/jpeg",gif:"image/gif"};class d{constructor(e){if(this.filePath=e,this.headers=new Headers,this.exists=o.existsSync(e),this.exists){this.status=200,this.statusText="OK";let t=o.statSync(e);this.headers.set("content-length",t.size.toString()),this.updateContentType();let r=o.createReadStream(e);this.body=new ReadableStream({start(e){r.on("data",t=>e.enqueue(t)),r.on("end",()=>e.close()),r.on("error",t=>e.error(t))},cancel(){r.destroy()}})}else this.status=404,this.statusText="Not Found",this.body=null}updateContentType(){let e=this.filePath.toString().split(".").pop().toLowerCase();this.headers.set("content-type",c[e]??"application/octet-stream")}clone(){let e=new d(this.filePath);return e.exists=this.exists,e.status=this.status,e.statusText=this.statusText,e.headers=new Headers(this.headers),e}async arrayBuffer(){return(await o.promises.readFile(this.filePath)).buffer}async blob(){return new Blob([await o.promises.readFile(this.filePath)],{type:this.headers.get("content-type")})}async text(){return await o.promises.readFile(this.filePath,"utf8")}async json(){return JSON.parse(await this.text())}}function u(e,t=null,r=null){let o;try{o=new URL(e)}catch(e){return!1}return(!t||!!t.includes(o.protocol))&&(!r||!!r.includes(o.hostname))}let m=/^(\b[\w\-.]+\b\/)?\b[\w\-.]{1,96}\b$/;async function p(e){if(i.env.useFS&&!u(e,["http:","https:","blob:"]))return new d(e instanceof URL?"file:"===e.protocol?e.pathname:e.toString():e);if(void 0===a||a?.release?.name!=="node")return fetch(e);{let t=!!a.env?.TESTING_REMOTELY,r=i.env.version,o=new Headers;if(o.set("User-Agent",`transformers.js/${r}; is_ci/${t};`),u(e,["http:","https:"],["huggingface.co","hf.co"])){let e=a.env?.HF_TOKEN??a.env?.HF_ACCESS_TOKEN;e&&o.set("Authorization",`Bearer ${e}`)}return fetch(e,{headers:o})}}let _={400:"Bad request error occurred while trying to load file",401:"Unauthorized access to file",403:"Forbidden access to file",404:"Could not locate file",408:"Request timeout error occurred while trying to load file",500:"Internal server error error occurred while trying to load file",502:"Bad gateway error occurred while trying to load file",503:"Service unavailable error occurred while trying to load file",504:"Gateway timeout error occurred while trying to load file"};class h{constructor(e){this.path=e}async match(e){let t=new d(s.join(this.path,e));return t.exists?t:void 0}async put(e,t,r){let a=s.join(this.path,e);try{let e=t.headers.get("Content-Length"),i=parseInt(e??"0"),n=0;await o.promises.mkdir(s.dirname(a),{recursive:!0});let l=o.createWriteStream(a),c=t.body.getReader();for(;;){let{done:e,value:t}=await c.read();if(e)break;await new Promise((e,r)=>{l.write(t,t=>{if(t){r(t);return}e()})}),n+=t.length;let o=i?n/i*100:0;r?.({progress:o,loaded:n,total:i})}l.close()}catch(e){try{await o.promises.unlink(a)}catch{}throw e}}}async function g(e,...t){for(let r of t)try{let t=await e.match(r);if(t)return t}catch(e){continue}}async function f(e,t,r=!0,o={},s=!1){let a,l,c,M;if(!i.env.allowLocalModels){if(o.local_files_only)throw Error("Invalid configuration detected: local models are disabled (`env.allowLocalModels=false`) but you have requested to only use local models (`local_files_only=true`).");if(!i.env.allowRemoteModels)throw Error("Invalid configuration detected: both local and remote models are disabled. Fix by setting `env.allowLocalModels` or `env.allowRemoteModels` to `true`.")}if((0,n.dispatchCallback)(o.progress_callback,{status:"initiate",name:e,file:t}),!a&&i.env.useCustomCache){if(!i.env.customCache)throw Error("`env.useCustomCache=true`, but `env.customCache` is not defined.");if(!i.env.customCache.match||!i.env.customCache.put)throw Error("`env.customCache` must be an object which implements the `match` and `put` functions of the Web Cache API. For more information, see https://developer.mozilla.org/en-US/docs/Web/API/Cache");a=i.env.customCache}if(!a&&i.env.useBrowserCache){if("undefined"==typeof caches)throw Error("Browser cache is not available in this environment.");try{a=await caches.open("transformers-cache")}catch(e){console.warn("An error occurred while opening the browser cache:",e)}}if(!a&&i.env.useFSCache){if(!i.apis.IS_FS_AVAILABLE)throw Error("File System Cache is not available in this environment.");a=new h(o.cache_dir??i.env.cacheDir)}let w=o.revision??"main",x=P(e,t),b=!(!m.test(e)||e.includes("..")||e.includes("--")||e.endsWith(".git")||e.endsWith(".ipynb")),F=b?P(i.env.localModelPath,x):x,k=P(i.env.remoteHost,i.env.remotePathTemplate.replaceAll("{model}",e).replaceAll("{revision}",encodeURIComponent(w)),t),y=a instanceof h?"main"===w?x:P(e,w,t):k,v=!1;a&&(c=await g(a,F,y));let C=void 0!==c;if(void 0===c){if(i.env.allowLocalModels){if(u(x,["http:","https:"])){if(o.local_files_only)throw Error(`\`local_files_only=true\`, but attempted to load a remote file from: ${x}.`);if(!i.env.allowRemoteModels)throw Error(`\`env.allowRemoteModels=false\`, but attempted to load a remote file from: ${x}.`)}else try{c=await p(F),l=F}catch(e){console.warn(`Unable to load from local path "${F}": "${e}"`)}}if(void 0===c||404===c.status){if(o.local_files_only||!i.env.allowRemoteModels){if(!r)return null;throw Error(`\`local_files_only=true\` or \`env.allowRemoteModels=false\` and file was not found locally at "${F}".`)}if(!b)throw Error(`Local file missing at "${F}" and download aborted due to invalid model ID "${e}".`);if(200!==(c=await p(k)).status)return function(e,t,r){if(!r)return null;let o=_[e]??`Error (${e}) occurred while trying to load file`;throw Error(`${o}: "${t}".`)}(c.status,k,r);l=y}v=a&&"undefined"!=typeof Response&&c instanceof Response&&200===c.status}if((0,n.dispatchCallback)(o.progress_callback,{status:"download",name:e,file:t}),!(i.apis.IS_NODE_ENV&&s)){let r;o.progress_callback?C&&"undefined"!=typeof navigator&&/firefox/i.test(navigator.userAgent)?(r=new Uint8Array(await c.arrayBuffer()),(0,n.dispatchCallback)(o.progress_callback,{status:"progress",name:e,file:t,progress:100,loaded:r.length,total:r.length})):r=await T(c,r=>{(0,n.dispatchCallback)(o.progress_callback,{status:"progress",name:e,file:t,...r})}):r=new Uint8Array(await c.arrayBuffer()),M=r}if(v&&l&&await a.match(l)===void 0){if(M)await a.put(l,new Response(M,{headers:c.headers})).catch(e=>{console.warn(`Unable to add response to browser cache: ${e}.`)});else{let r=o.progress_callback?r=>(0,n.dispatchCallback)(o.progress_callback,{status:"progress",name:e,file:t,...r}):void 0;await a.put(l,c,r)}}if((0,n.dispatchCallback)(o.progress_callback,{status:"done",name:e,file:t}),M){if(!i.apis.IS_NODE_ENV&&s)throw Error("Cannot return path in a browser environment.");return M}if(c instanceof d)return c.filePath;let S=await a?.match(l);if(S instanceof d)return S.filePath;if(S instanceof Response)return new Uint8Array(await S.arrayBuffer());if("string"==typeof S)return S;throw Error("Unable to get model file path or buffer.")}async function M(e,t,r=!0,o={}){let s=await f(e,t,r,o,!1);return null===s?null:new TextDecoder("utf-8").decode(s)}async function w(e,t,r=!0,o={}){let s=await M(e,t,r,o);return null===s?{}:JSON.parse(s)}async function T(e,t){let r=e.headers.get("Content-Length");null===r&&console.warn("Unable to determine content-length from response headers. Will expand buffer when needed.");let o=parseInt(r??"0"),s=new Uint8Array(o),a=0,i=e.body.getReader();async function n(){let{done:e,value:r}=await i.read();if(e)return;let l=a+r.length;if(l>o){let e=new Uint8Array(o=l);e.set(s),s=e}return s.set(r,a),t({progress:(a=l)/o*100,loaded:a,total:o}),n()}return await n(),s}function P(...e){return(e=e.map((t,r)=>(r&&(t=t.replace(RegExp("^/"),"")),r!==e.length-1&&(t=t.replace(RegExp("/$"),"")),t))).join("/")}},"./src/utils/image.js":(e,t,r)=>{let o,s,a;r.r(t),r.d(t,{RawImage:()=>_,load_image:()=>h});var i=r("./src/utils/core.js"),n=r("./src/utils/hub.js"),l=r("./src/env.js"),c=r("./src/utils/tensor.js"),d=r("?2b25");let u=l.apis.IS_BROWSER_ENV||l.apis.IS_WEBWORKER_ENV;if(u)o=(e,t)=>{if(!self.OffscreenCanvas)throw Error("OffscreenCanvas not supported by this browser.");return new self.OffscreenCanvas(e,t)},a=self.createImageBitmap,s=self.ImageData;else if(d)a=async e=>{let t=(await e.metadata()).channels,{data:r,info:o}=await e.rotate().raw().toBuffer({resolveWithObject:!0}),s=new _(new Uint8ClampedArray(r),o.width,o.height,o.channels);return void 0!==t&&t!==o.channels&&s.convert(t),s};else throw Error("Unable to load image processing library.");let m={0:"nearest",1:"lanczos",2:"bilinear",3:"bicubic",4:"box",5:"hamming"},p=new Map([["png","image/png"],["jpg","image/jpeg"],["jpeg","image/jpeg"],["gif","image/gif"]]);class _{constructor(e,t,r,o){this.data=e,this.width=t,this.height=r,this.channels=o}get size(){return[this.width,this.height]}static async read(e){if(e instanceof _)return e;if("string"==typeof e||e instanceof URL)return await this.fromURL(e);if(e instanceof Blob)return await this.fromBlob(e);if("undefined"!=typeof HTMLCanvasElement&&e instanceof HTMLCanvasElement||"undefined"!=typeof OffscreenCanvas&&e instanceof OffscreenCanvas)return this.fromCanvas(e);throw Error(`Unsupported input type: ${typeof e}`)}static fromCanvas(e){if(!u)throw Error("fromCanvas() is only supported in browser environments.");return new _(e.getContext("2d").getImageData(0,0,e.width,e.height).data,e.width,e.height,4)}static async fromURL(e){let t=await (0,n.getFile)(e);if(200!==t.status)throw Error(`Unable to read image from "${e}" (${t.status} ${t.statusText})`);let r=await t.blob();return this.fromBlob(r)}static async fromBlob(e){if(u){let t=await a(e),r=o(t.width,t.height).getContext("2d");return r.drawImage(t,0,0),new this(r.getImageData(0,0,t.width,t.height).data,t.width,t.height,4)}{let t=d(await e.arrayBuffer());return await a(t)}}static fromTensor(e,t="CHW"){if(3!==e.dims.length)throw Error(`Tensor should have 3 dimensions, but has ${e.dims.length} dimensions.`);if("CHW"===t)e=e.transpose(1,2,0);else if("HWC"===t);else throw Error(`Unsupported channel format: ${t}`);if(!(e.data instanceof Uint8ClampedArray||e.data instanceof Uint8Array))throw Error(`Unsupported tensor type: ${e.type}`);switch(e.dims[2]){case 1:case 2:case 3:case 4:return new _(e.data,e.dims[1],e.dims[0],e.dims[2]);default:throw Error(`Unsupported number of channels: ${e.dims[2]}`)}}grayscale(){if(1===this.channels)return this;let e=new Uint8ClampedArray(this.width*this.height*1);switch(this.channels){case 3:case 4:for(let t=0,r=0;t<this.data.length;t+=this.channels){let o=this.data[t],s=this.data[t+1],a=this.data[t+2];e[r++]=Math.round(.2989*o+.587*s+.114*a)}break;default:throw Error(`Conversion failed due to unsupported number of channels: ${this.channels}`)}return this._update(e,this.width,this.height,1)}rgb(){if(3===this.channels)return this;let e=new Uint8ClampedArray(this.width*this.height*3);switch(this.channels){case 1:for(let t=0,r=0;t<this.data.length;++t)e[r++]=this.data[t],e[r++]=this.data[t],e[r++]=this.data[t];break;case 4:for(let t=0,r=0;t<this.data.length;t+=4)e[r++]=this.data[t],e[r++]=this.data[t+1],e[r++]=this.data[t+2];break;default:throw Error(`Conversion failed due to unsupported number of channels: ${this.channels}`)}return this._update(e,this.width,this.height,3)}rgba(){if(4===this.channels)return this;let e=new Uint8ClampedArray(this.width*this.height*4);switch(this.channels){case 1:for(let t=0,r=0;t<this.data.length;++t)e[r++]=this.data[t],e[r++]=this.data[t],e[r++]=this.data[t],e[r++]=255;break;case 3:for(let t=0,r=0;t<this.data.length;t+=3)e[r++]=this.data[t],e[r++]=this.data[t+1],e[r++]=this.data[t+2],e[r++]=255;break;default:throw Error(`Conversion failed due to unsupported number of channels: ${this.channels}`)}return this._update(e,this.width,this.height,4)}putAlpha(e){if(e.width!==this.width||e.height!==this.height)throw Error(`Expected mask size to be ${this.width}x${this.height}, but got ${e.width}x${e.height}`);if(1!==e.channels)throw Error(`Expected mask to have 1 channel, but got ${e.channels}`);let t=this.data,r=e.data,o=this.width*this.height;if(3===this.channels){let e=new Uint8ClampedArray(4*o);for(let s=0,a=0,i=0;s<o;++s)e[i++]=t[a++],e[i++]=t[a++],e[i++]=t[a++],e[i++]=r[s];return this._update(e,this.width,this.height,4)}if(4===this.channels){for(let e=0;e<o;++e)t[4*e+3]=r[e];return this}throw Error(`Expected image to have 3 or 4 channels, but got ${this.channels}`)}async resize(e,t,{resample:r=2}={}){if(this.width===e&&this.height===t)return this;let s=m[r]??r,n=(0,i.isNullishDimension)(e),l=(0,i.isNullishDimension)(t);if(n&&l)return this;if(n?e=t/this.height*this.width:l&&(t=e/this.width*this.height),u){let r=this.channels,s=this.toCanvas(),a=o(e,t).getContext("2d");return a.drawImage(s,0,0,e,t),new _(a.getImageData(0,0,e,t).data,e,t,4).convert(r)}{let r=this.toSharp();switch(s){case"box":case"hamming":("box"===s||"hamming"===s)&&(console.warn(`Resampling method ${s} is not yet supported. Using bilinear instead.`),s="bilinear");case"nearest":case"bilinear":case"bicubic":r=r.affine([e/this.width,0,0,t/this.height],{interpolator:s});break;case"lanczos":r=r.resize({width:e,height:t,fit:"fill",kernel:"lanczos3"});break;default:throw Error(`Resampling method ${s} is not supported.`)}return await a(r)}}async pad([e,t,r,s]){if(e=Math.max(e,0),t=Math.max(t,0),r=Math.max(r,0),s=Math.max(s,0),0===e&&0===t&&0===r&&0===s)return this;if(u){let a=this.channels,i=this.toCanvas(),n=this.width+e+t,l=this.height+r+s,c=o(n,l).getContext("2d");return c.drawImage(i,0,0,this.width,this.height,e,r,this.width,this.height),new _(c.getImageData(0,0,n,l).data,n,l,4).convert(a)}{let o=this.toSharp().extend({left:e,right:t,top:r,bottom:s});return await a(o)}}async crop([e,t,r,s]){if(e=Math.max(e,0),t=Math.max(t,0),r=Math.min(r,this.width-1),s=Math.min(s,this.height-1),0===e&&0===t&&r===this.width-1&&s===this.height-1)return this;let i=r-e+1,n=s-t+1;if(u){let r=this.channels,s=this.toCanvas(),a=o(i,n).getContext("2d");return a.drawImage(s,e,t,i,n,0,0,i,n),new _(a.getImageData(0,0,i,n).data,i,n,4).convert(r)}{let r=this.toSharp().extract({left:e,top:t,width:i,height:n});return await a(r)}}async center_crop(e,t){if(this.width===e&&this.height===t)return this;let r=(this.width-e)/2,s=(this.height-t)/2;if(u){let a=this.channels,i=this.toCanvas(),n=o(e,t).getContext("2d"),l=0,c=0,d=0,u=0;return r>=0?l=r:d=-r,s>=0?c=s:u=-s,n.drawImage(i,l,c,e,t,d,u,e,t),new _(n.getImageData(0,0,e,t).data,e,t,4).convert(a)}{let o=this.toSharp();if(r>=0&&s>=0)o=o.extract({left:Math.floor(r),top:Math.floor(s),width:e,height:t});else if(r<=0&&s<=0){let a=Math.floor(-s),i=Math.floor(-r);o=o.extend({top:a,left:i,right:e-this.width-i,bottom:t-this.height-a})}else{let a=[0,0],i=0;s<0?(a[0]=Math.floor(-s),a[1]=t-this.height-a[0]):i=Math.floor(s);let n=[0,0],l=0;r<0?(n[0]=Math.floor(-r),n[1]=e-this.width-n[0]):l=Math.floor(r),o=o.extend({top:a[0],bottom:a[1],left:n[0],right:n[1]}).extract({left:l,top:i,width:e,height:t})}return await a(o)}}async toBlob(e="image/png",t=1){if(!u)throw Error("toBlob() is only supported in browser environments.");let r=this.toCanvas();return await r.convertToBlob({type:e,quality:t})}toTensor(e="CHW"){let t=new c.Tensor("uint8",new Uint8Array(this.data),[this.height,this.width,this.channels]);if("HWC"===e);else if("CHW"===e)t=t.permute(2,0,1);else throw Error(`Unsupported channel format: ${e}`);return t}toCanvas(){if(!u)throw Error("toCanvas() is only supported in browser environments.");let e=this.clone().rgba(),t=o(e.width,e.height),r=new s(e.data,e.width,e.height);return t.getContext("2d").putImageData(r,0,0),t}split(){let{data:e,width:t,height:r,channels:o}=this,s=e.constructor,a=e.length/o,i=Array.from({length:o},()=>new s(a));for(let t=0;t<a;++t){let r=o*t;for(let s=0;s<o;++s)i[s][t]=e[r+s]}return i.map(e=>new _(e,t,r,1))}_update(e,t,r,o=null){return this.data=e,this.width=t,this.height=r,null!==o&&(this.channels=o),this}clone(){return new _(this.data.slice(),this.width,this.height,this.channels)}convert(e){if(this.channels===e)return this;switch(e){case 1:this.grayscale();break;case 3:this.rgb();break;case 4:this.rgba();break;default:throw Error(`Conversion failed due to unsupported number of channels: ${this.channels}`)}return this}async save(e){if(u){if(l.apis.IS_WEBWORKER_ENV)throw Error("Unable to save an image from a Web Worker.");let t=e.split(".").pop().toLowerCase(),r=p.get(t)??"image/png",o=await this.toBlob(r);(0,i.saveBlob)(e,o)}else if(l.apis.IS_FS_AVAILABLE){let t=this.toSharp();return await t.toFile(e)}else throw Error("Unable to save the image because filesystem is disabled in this environment.")}toSharp(){if(u)throw Error("toSharp() is only supported in server-side environments.");return d(this.data,{raw:{width:this.width,height:this.height,channels:this.channels}})}}let h=_.read.bind(_)},"./src/utils/maths.js":(e,t,r)=>{function o(e,[t,r,s],[a,i],n="bilinear",l=!1){let c=i/s,d=a/r,u=new e.constructor(a*i*t),m=r*s,p=a*i;for(let o=0;o<a;++o)for(let a=0;a<i;++a){let n=o*i+a,l=(a+.5)/c-.5,_=(o+.5)/d-.5,h=Math.floor(l),g=Math.floor(_),f=Math.min(h+1,s-1),M=Math.min(g+1,r-1),w=l-(h=Math.max(h,0)),T=_-(g=Math.max(g,0)),P=(1-w)*(1-T),x=w*(1-T),b=(1-w)*T,F=w*T,k=g*s,y=M*s,v=k+h,C=k+f,S=y+h,E=y+f;for(let r=0;r<t;++r){let t=r*m;u[r*p+n]=P*e[t+v]+x*e[t+C]+b*e[t+S]+F*e[t+E]}}return u}function s(e,t,r){let o=Array(r.length),s=Array(r.length);for(let e=r.length-1,a=1;e>=0;--e)s[e]=a,o[e]=t[r[e]],a*=o[e];let a=r.map((e,t)=>s[r.indexOf(t)]),i=new e.constructor(e.length);for(let r=0;r<e.length;++r){let o=0;for(let e=t.length-1,s=r;e>=0;--e)o+=s%t[e]*a[e],s=Math.floor(s/t[e]);i[o]=e[r]}return[i,o]}function a(e){let t=u(e)[0],r=e.map(e=>Math.exp(e-t)),o=r.reduce((e,t)=>e+t,0);return r.map(e=>e/o)}function i(e){let t=u(e)[0],r=0;for(let o=0;o<e.length;++o)r+=Math.exp(e[o]-t);let o=Math.log(r);return e.map(e=>e-t-o)}function n(e,t){let r=0;for(let o=0;o<e.length;++o)r+=e[o]*t[o];return r}function l(e,t){let r=n(e,t),o=c(e);return r/(o*c(t))}function c(e){return Math.sqrt(e.reduce((e,t)=>e+t*t,0))}function d(e){if(0===e.length)throw Error("Array must not be empty");let t=e[0],r=0;for(let o=1;o<e.length;++o)e[o]<t&&(t=e[o],r=o);return[t,r]}function u(e){if(0===e.length)throw Error("Array must not be empty");let t=e[0],r=0;for(let o=1;o<e.length;++o)e[o]>t&&(t=e[o],r=o);return[t,r]}function m(e){return e>0&&(e&e-1)==0}r.r(t),r.d(t,{FFT:()=>h,bankers_round:()=>M,cos_sim:()=>l,dot:()=>n,dynamic_time_warping:()=>w,interpolate_data:()=>o,log_softmax:()=>i,magnitude:()=>c,max:()=>u,medianFilter:()=>g,min:()=>d,permute_data:()=>s,round:()=>f,softmax:()=>a});class p{constructor(e){if(this.size=0|e,this.size<=1||!m(this.size))throw Error("FFT size must be a power of two larger than 1");this._csize=e<<1,this.table=new Float64Array(2*this.size);for(let e=0;e<this.table.length;e+=2){let t=Math.PI*e/this.size;this.table[e]=Math.cos(t),this.table[e+1]=-Math.sin(t)}let t=0;for(let e=1;this.size>e;e<<=1)++t;this._width=t%2==0?t-1:t,this._bitrev=new Int32Array(1<<this._width);for(let e=0;e<this._bitrev.length;++e){this._bitrev[e]=0;for(let t=0;t<this._width;t+=2){let r=this._width-t-2;this._bitrev[e]|=(e>>>t&3)<<r}}}createComplexArray(){return new Float64Array(this._csize)}fromComplexArray(e,t){let r=t||Array(e.length>>>1);for(let t=0;t<e.length;t+=2)r[t>>>1]=e[t];return r}toComplexArray(e,t){let r=t||this.createComplexArray();for(let t=0;t<r.length;t+=2)r[t]=e[t>>>1],r[t+1]=0;return r}transform(e,t){if(e===t)throw Error("Input and output buffers must be different");this._transform4(e,t,1)}realTransform(e,t){if(e===t)throw Error("Input and output buffers must be different");this._realTransform4(e,t,1)}inverseTransform(e,t){if(e===t)throw Error("Input and output buffers must be different");this._transform4(e,t,-1);for(let t=0;t<e.length;++t)e[t]/=this.size}_transform4(e,t,r){let o,s;let a=this._csize,i=1<<this._width,n=a/i<<1,l=this._bitrev;if(4===n)for(o=0,s=0;o<a;o+=n,++s){let r=l[s];this._singleTransform2(t,e,o,r,i)}else for(o=0,s=0;o<a;o+=n,++s){let a=l[s];this._singleTransform4(t,e,o,a,i,r)}let c=this.table;for(i>>=2;i>=2;i>>=2){let t=(n=a/i<<1)>>>2;for(o=0;o<a;o+=n){let s=o+t-1;for(let a=o,n=0;a<s;a+=2,n+=i){let o=a,s=o+t,i=s+t,l=i+t,d=e[o],u=e[o+1],m=e[s],p=e[s+1],_=e[i],h=e[i+1],g=e[l],f=e[l+1],M=c[n],w=r*c[n+1],T=m*M-p*w,P=m*w+p*M,x=c[2*n],b=r*c[2*n+1],F=_*x-h*b,k=_*b+h*x,y=c[3*n],v=r*c[3*n+1],C=g*y-f*v,S=g*v+f*y,E=d+F,A=u+k,L=d-F,I=u-k,D=T+C,z=P+S,j=r*(T-C),V=r*(P-S);e[o]=E+D,e[o+1]=A+z,e[s]=L+V,e[s+1]=I-j,e[i]=E-D,e[i+1]=A-z,e[l]=L-V,e[l+1]=I+j}}}}_singleTransform2(e,t,r,o,s){let a=e[o],i=e[o+1],n=e[o+s],l=e[o+s+1];t[r]=a+n,t[r+1]=i+l,t[r+2]=a-n,t[r+3]=i-l}_singleTransform4(e,t,r,o,s,a){let i=2*s,n=3*s,l=e[o],c=e[o+1],d=e[o+s],u=e[o+s+1],m=e[o+i],p=e[o+i+1],_=e[o+n],h=e[o+n+1],g=l+m,f=c+p,M=l-m,w=c-p,T=d+_,P=u+h,x=a*(d-_),b=a*(u-h);t[r]=g+T,t[r+1]=f+P,t[r+2]=M+b,t[r+3]=w-x,t[r+4]=g-T,t[r+5]=f-P,t[r+6]=M-b,t[r+7]=w+x}_realTransform4(e,t,r){let o,s;let a=this._csize,i=1<<this._width,n=a/i<<1,l=this._bitrev;if(4===n)for(o=0,s=0;o<a;o+=n,++s){let r=l[s];this._singleRealTransform2(t,e,o,r>>>1,i>>>1)}else for(o=0,s=0;o<a;o+=n,++s){let a=l[s];this._singleRealTransform4(t,e,o,a>>>1,i>>>1,r)}let c=this.table;for(i>>=2;i>=2;i>>=2){let t=(n=a/i<<1)>>>1,s=t>>>1,l=s>>>1;for(o=0;o<a;o+=n)for(let a=0,n=0;a<=l;a+=2,n+=i){let i=o+a,d=i+s,u=d+s,m=u+s,p=e[i],_=e[i+1],h=e[d],g=e[d+1],f=e[u],M=e[u+1],w=e[m],T=e[m+1],P=c[n],x=r*c[n+1],b=h*P-g*x,F=h*x+g*P,k=c[2*n],y=r*c[2*n+1],v=f*k-M*y,C=f*y+M*k,S=c[3*n],E=r*c[3*n+1],A=w*S-T*E,L=w*E+T*S,I=p+v,D=_+C,z=p-v,j=_-C,V=b+A,O=F+L,N=r*(b-A),B=r*(F-L);if(e[i]=I+V,e[i+1]=D+O,e[d]=z+B,e[d+1]=j-N,0===a){e[u]=I-V,e[u+1]=D-O;continue}if(a===l)continue;let G=o+s-a,R=o+t-a;e[G]=z-r*B,e[G+1]=-j-r*N,e[R]=I-r*V,e[R+1]=-D+r*O}}let d=a>>>1;for(let t=2;t<d;t+=2)e[a-t]=e[t],e[a-t+1]=-e[t+1]}_singleRealTransform2(e,t,r,o,s){let a=e[o],i=e[o+s];t[r]=a+i,t[r+1]=0,t[r+2]=a-i,t[r+3]=0}_singleRealTransform4(e,t,r,o,s,a){let i=e[o],n=e[o+s],l=e[o+2*s],c=e[o+3*s],d=i+l,u=i-l,m=n+c,p=a*(n-c);t[r]=d+m,t[r+1]=0,t[r+2]=u,t[r+3]=-p,t[r+4]=d-m,t[r+5]=0,t[r+6]=u,t[r+7]=p}}class _{constructor(e){let t=2*(e-1),r=2*(2*e-1),o=2**Math.ceil(Math.log2(r));this.bufferSize=o,this._a=t;let s=new Float64Array(r),a=new Float64Array(o);this._chirpBuffer=new Float64Array(o),this._buffer1=new Float64Array(o),this._buffer2=new Float64Array(o),this._outBuffer1=new Float64Array(o),this._outBuffer2=new Float64Array(o);let i=-2*Math.PI/e,n=Math.cos(i),l=Math.sin(i);for(let t=0;t<r>>1;++t){let r=(t+1-e)**2/2,o=Math.sqrt(n**2+l**2)**r,i=r*Math.atan2(l,n),c=2*t;s[c]=o*Math.cos(i),s[c+1]=o*Math.sin(i),a[c]=s[c],a[c+1]=-s[c+1]}this._slicedChirpBuffer=s.subarray(t,r),this._f=new p(o>>1),this._f.transform(this._chirpBuffer,a)}_transform(e,t,r){let o=this._buffer1,s=this._buffer2,a=this._outBuffer1,i=this._outBuffer2,n=this._chirpBuffer,l=this._slicedChirpBuffer,c=this._a;if(r)for(let e=0;e<l.length;e+=2){let r=e+1,s=t[e>>1];o[e]=s*l[e],o[r]=s*l[r]}else for(let e=0;e<l.length;e+=2){let r=e+1;o[e]=t[e]*l[e]-t[r]*l[r],o[r]=t[e]*l[r]+t[r]*l[e]}this._f.transform(a,o);for(let e=0;e<n.length;e+=2){let t=e+1;s[e]=a[e]*n[e]-a[t]*n[t],s[t]=a[e]*n[t]+a[t]*n[e]}this._f.inverseTransform(i,s);for(let t=0;t<i.length;t+=2){let r=i[t+c],o=i[t+c+1],s=l[t],a=l[t+1];e[t]=r*s-o*a,e[t+1]=r*a+o*s}}transform(e,t){this._transform(e,t,!1)}realTransform(e,t){this._transform(e,t,!0)}}class h{constructor(e){this.fft_length=e,this.isPowerOfTwo=m(e),this.isPowerOfTwo?(this.fft=new p(e),this.outputBufferSize=2*e):(this.fft=new _(e),this.outputBufferSize=this.fft.bufferSize)}realTransform(e,t){this.fft.realTransform(e,t)}transform(e,t){this.fft.transform(e,t)}}function g(e,t){if(t%2==0||t<=0)throw Error("Window size must be a positive odd number");let r=new e.constructor(e.length),o=new e.constructor(t),s=Math.floor(t/2);for(let t=0;t<e.length;++t){let a=0;for(let r=-s;r<=s;++r){let s=t+r;s<0?s=Math.abs(s):s>=e.length&&(s=2*(e.length-1)-s),o[a++]=e[s]}o.sort(),r[t]=o[s]}return r}function f(e,t){let r=Math.pow(10,t);return Math.round(e*r)/r}function M(e){let t=Math.round(e);return Math.abs(e)%1==.5?t%2==0?t:t-1:t}function w(e){let t=e.length,r=e[0].length,o=[t+1,r+1],s=Array.from({length:o[0]},()=>Array(o[1]).fill(1/0));s[0][0]=0;let a=Array.from({length:o[0]},()=>Array(o[1]).fill(-1));for(let t=1;t<o[1];++t)for(let r=1;r<o[0];++r){let o,i;let n=s[r-1][t-1],l=s[r-1][t],c=s[r][t-1];n<l&&n<c?(o=n,i=0):l<n&&l<c?(o=l,i=1):(o=c,i=2),s[r][t]=e[r-1][t-1]+o,a[r][t]=i}for(let e=0;e<o[1];++e)a[0][e]=2;for(let e=0;e<o[0];++e)a[e][0]=1;let i=t,n=r,l=[],c=[];for(;i>0||n>0;)switch(l.push(i-1),c.push(n-1),a[i][n]){case 0:--i,--n;break;case 1:--i;break;case 2:--n;break;default:throw Error(`Internal error in dynamic time warping. Unexpected trace[${i}, ${n}]. Please file a bug report.`)}return l.reverse(),c.reverse(),[l,c]}},"./src/utils/tensor.js":(e,t,r)=>{r.r(t),r.d(t,{DataTypeMap:()=>i,Tensor:()=>n,cat:()=>P,full:()=>v,full_like:()=>C,interpolate:()=>c,interpolate_4d:()=>d,layer_norm:()=>f,matmul:()=>u,mean:()=>k,mean_pooling:()=>g,ones:()=>S,ones_like:()=>E,permute:()=>l,quantize_embeddings:()=>z,rand:()=>I,randn:()=>D,rfft:()=>m,slice:()=>h,stack:()=>x,std_mean:()=>F,topk:()=>p,zeros:()=>A,zeros_like:()=>L});var o=r("./src/utils/maths.js"),s=r("./src/backends/onnx.js"),a=r("./src/ops/registry.js");let i=Object.freeze({float32:Float32Array,float16:"undefined"!=typeof Float16Array?Float16Array:Uint16Array,float64:Float64Array,string:Array,int8:Int8Array,uint8:Uint8Array,int16:Int16Array,uint16:Uint16Array,int32:Int32Array,uint32:Uint32Array,int64:BigInt64Array,uint64:BigUint64Array,bool:Uint8Array,uint4:Uint8Array,int4:Int8Array});class n{get dims(){return this.ort_tensor.dims}set dims(e){this.ort_tensor.dims=e}get type(){return this.ort_tensor.type}get data(){return this.ort_tensor.data}get size(){return this.ort_tensor.size}get location(){return this.ort_tensor.location}ort_tensor;constructor(...e){return(0,s.isONNXTensor)(e[0])?this.ort_tensor=e[0]:this.ort_tensor=new s.Tensor(e[0],e[1],e[2]),new Proxy(this,{get:(e,t)=>{if("string"==typeof t){let r=Number(t);if(Number.isInteger(r))return e._getitem(r)}return e[t]},set:(e,t,r)=>e[t]=r})}dispose(){this.ort_tensor.dispose()}*[Symbol.iterator](){let[e,...t]=this.dims;if(t.length>0){let r=t.reduce((e,t)=>e*t);for(let o=0;o<e;++o)yield this._subarray(o,r,t)}else yield*this.data}_getitem(e){let[t,...r]=this.dims;if(e=T(e,t),!(r.length>0))return new n(this.type,[this.data[e]],r);{let t=r.reduce((e,t)=>e*t);return this._subarray(e,t,r)}}indexOf(e){let t=this.data;for(let r=0;r<t.length;++r)if(t[r]==e)return r;return -1}_subarray(e,t,r){let o=e*t,s=(e+1)*t,a="subarray"in this.data?this.data.subarray(o,s):this.data.slice(o,s);return new n(this.type,a,r)}item(){let e=this.data;if(1!==e.length)throw Error(`a Tensor with ${e.length} elements cannot be converted to Scalar`);return e[0]}tolist(){return function(e,t){let r=e.length;if(r!==t.reduce((e,t)=>e*t))throw Error(`cannot reshape array of size ${r} into shape (${t})`);let o=e;for(let e=t.length-1;e>=0;e--)o=o.reduce((r,o)=>{let s=r[r.length-1];return s.length<t[e]?s.push(o):r.push([o]),r},[[]]);return o[0]}(this.data,this.dims)}sigmoid(){return this.clone().sigmoid_()}sigmoid_(){let e=this.data;for(let t=0;t<e.length;++t)e[t]=1/(1+Math.exp(-e[t]));return this}map(e){return this.clone().map_(e)}map_(e){let t=this.data;for(let r=0;r<t.length;++r)t[r]=e(t[r],r,t);return this}mul(e){return this.clone().mul_(e)}mul_(e){let t=this.data;for(let r=0;r<t.length;++r)t[r]*=e;return this}div(e){return this.clone().div_(e)}div_(e){let t=this.data;for(let r=0;r<t.length;++r)t[r]/=e;return this}add(e){return this.clone().add_(e)}add_(e){let t=this.data;for(let r=0;r<t.length;++r)t[r]+=e;return this}sub(e){return this.clone().sub_(e)}sub_(e){let t=this.data;for(let r=0;r<t.length;++r)t[r]-=e;return this}clone(){return new n(this.type,this.data.slice(),this.dims.slice())}slice(...e){let t=[],r=[];for(let o=0;o<this.dims.length;++o){let s=e[o];if(null==s)r.push([0,this.dims[o]]),t.push(this.dims[o]);else if("number"==typeof s)s=T(s,this.dims[o],o),r.push([s,s+1]);else if(Array.isArray(s)&&2===s.length){let[e,a]=s;if((e=null===e?0:T(e,this.dims[o],o,!1))>(a=null===a?this.dims[o]:T(a,this.dims[o],o,!1)))throw Error(`Invalid slice: ${s}`);let i=[Math.max(e,0),Math.min(a,this.dims[o])];r.push(i),t.push(i[1]-i[0])}else throw Error(`Invalid slice: ${s}`)}let o=r.map(([e,t])=>t-e),s=o.reduce((e,t)=>e*t),a=this.data,i=new a.constructor(s),l=this.stride(),c=!0;for(let e=1;e<o.length;++e)if(0!==r[e][0]||r[e][1]!==this.dims[e]){c=!1;break}if(c){let e=r[0][0]*l[0],t=r[0][1]*l[0];if(ArrayBuffer.isView(a))i.set(a.subarray(e,t));else if(Array.isArray(a)){let r=a.slice(e,t);for(let e=0;e<r.length;++e)i[e]=r[e]}else throw Error("Unsupported data type for slicing")}else for(let e=0;e<s;++e){let t=0;for(let s=o.length-1,a=e;s>=0;--s){let e=o[s];t+=(a%e+r[s][0])*l[s],a=Math.floor(a/e)}i[e]=a[t]}return new n(this.type,i,t)}permute(...e){return l(this,e)}transpose(...e){return this.permute(...e)}sum(e=null,t=!1){return this.norm(1,e,t)}norm(e="fro",t=null,r=!1){if("fro"===e)e=2;else if("string"==typeof e)throw Error(`Unsupported norm: ${e}`);let o=this.data,s=(t,r)=>t+r**e;if(null===t){let t=o.reduce(s,0)**(1/e);return new n(this.type,[t],[])}let[a,i,l]=b(s,this,t,r);if(1!==e)for(let t=0;t<i.length;++t)i[t]=i[t]**(1/e);return new n(a,i,l)}normalize_(e=2,t=1){t=T(t,this.dims.length);let r=this.norm(e,t,!0),o=this.data,s=r.data;for(let e=0;e<o.length;++e){let r=0;for(let o=this.dims.length-1,s=e,a=1;o>=0;--o){let e=this.dims[o];o!==t&&(r+=s%e*a,a*=this.dims[o]),s=Math.floor(s/e)}o[e]/=s[r]}return this}normalize(e=2,t=1){return this.clone().normalize_(e,t)}stride(){return function(e){let t=Array(e.length);for(let r=e.length-1,o=1;r>=0;--r)t[r]=o,o*=e[r];return t}(this.dims)}squeeze(e=null){return new n(this.type,this.data,M(this.dims,e))}squeeze_(e=null){return this.dims=M(this.dims,e),this}unsqueeze(e=null){return new n(this.type,this.data,w(this.dims,e))}unsqueeze_(e=null){return this.dims=w(this.dims,e),this}flatten_(e=0,t=-1){t=(t+this.dims.length)%this.dims.length;let r=this.dims.slice(0,e),o=this.dims.slice(e,t+1),s=this.dims.slice(t+1);return this.dims=[...r,o.reduce((e,t)=>e*t,1),...s],this}flatten(e=0,t=-1){return this.clone().flatten_(e,t)}view(...e){let t=-1;for(let r=0;r<e.length;++r)if(-1===e[r]){if(-1!==t)throw Error("Only one dimension can be inferred");t=r}let r=this.data;if(-1!==t){let o=e.reduce((e,r,o)=>o!==t?e*r:e,1);e[t]=r.length/o}return new n(this.type,r,e)}neg_(){let e=this.data;for(let t=0;t<e.length;++t)e[t]=-e[t];return this}neg(){return this.clone().neg_()}gt(e){let t=new Uint8Array(this.data.length),r=this.data;for(let o=0;o<r.length;++o)t[o]=+(r[o]>e);return new n("bool",t,this.dims)}lt(e){let t=new Uint8Array(this.data.length),r=this.data;for(let o=0;o<r.length;++o)t[o]=+(r[o]<e);return new n("bool",t,this.dims)}clamp_(e,t){let r=this.data;for(let o=0;o<r.length;++o)r[o]=Math.min(Math.max(r[o],e),t);return this}clamp(e,t){return this.clone().clamp_(e,t)}round_(){let e=this.data;for(let t=0;t<e.length;++t)e[t]=Math.round(e[t]);return this}round(){return this.clone().round_()}mean(e=null,t=!1){return k(this,e,t)}min(e=null,t=!1){if(null===e){let e=(0,o.min)(this.data)[0];return new n(this.type,[e],[])}let[r,s,a]=b((e,t)=>Math.min(e,t),this,e,t,1/0);return new n(r,s,a)}max(e=null,t=!1){if(null===e){let e=(0,o.max)(this.data)[0];return new n(this.type,[e],[])}let[r,s,a]=b((e,t)=>Math.max(e,t),this,e,t,-1/0);return new n(r,s,a)}argmin(e=null,t=!1){if(null!==e)throw Error("`dim !== null` not yet implemented.");return new n("int64",[BigInt((0,o.min)(this.data)[1])],[])}argmax(e=null,t=!1){if(null!==e)throw Error("`dim !== null` not yet implemented.");return new n("int64",[BigInt((0,o.max)(this.data)[1])],[])}to(e){let t;if(this.type===e)return this;if(!i.hasOwnProperty(e))throw Error(`Unsupported type: ${e}`);let r=["int64","uint64"].includes(this.type),o=["int64","uint64"].includes(e);return r&&!o?t=Number:!r&&o&&(t=["float16","float32","float64"].includes(this.type)?e=>BigInt(Math.floor(e)):BigInt),new n(e,i[e].from(this.data,t),this.dims)}}function l(e,t){let[r,s]=(0,o.permute_data)(e.data,e.dims,t);return new n(e.type,r,s)}function c(e,[t,r],s="bilinear",a=!1){let i=e.dims.at(-3)??1,l=e.dims.at(-2),d=e.dims.at(-1),u=(0,o.interpolate_data)(e.data,[i,l,d],[t,r],s,a);return new n(e.type,u,[i,t,r])}async function d(e,{size:t=null,mode:r="bilinear"}={}){let o,s;if(4!==e.dims.length)throw Error("`interpolate_4d` currently only supports 4D input.");if(!t)throw Error("`interpolate_4d` requires a `size` argument.");if(2===t.length)o=[...e.dims.slice(0,2),...t];else if(3===t.length)o=[e.dims[0],...t];else if(4===t.length)o=t;else throw Error("`size` must be of length 2, 3, or 4.");if("nearest"===r)s=await a.TensorOpRegistry.nearest_interpolate_4d;else if("bilinear"===r)s=await a.TensorOpRegistry.bilinear_interpolate_4d;else if("bicubic"===r)s=await a.TensorOpRegistry.bicubic_interpolate_4d;else throw Error(`Unsupported mode: ${r}`);let i=new n("int64",new BigInt64Array(o.map(BigInt)),[o.length]);return await s({x:e,s:i})}async function u(e,t){let r=await a.TensorOpRegistry.matmul;return await r({a:e,b:t})}async function m(e,t){let r=await a.TensorOpRegistry.rfft;return await r({x:e,a:t})}async function p(e,t){let r=await a.TensorOpRegistry.top_k;return t=null==t?e.dims.at(-1):Math.min(t,e.dims.at(-1)),await r({x:e,k:new n("int64",[BigInt(t)],[1])})}let _=e=>new n("int64",e,[e.length]);async function h(e,t,r,o,s){let i=await a.TensorOpRegistry.slice;return await i({x:e,s:_(t),e:_(r),a:_(o),t:_(s??Array(o.length).fill(1))})}function g(e,t){let r=e.data,o=t.data,s=[e.dims[0],e.dims[2]],a=new r.constructor(s[0]*s[1]),[i,l,c]=e.dims,d=0;for(let e=0;e<i;++e){let t=e*c*l;for(let s=0;s<c;++s){let i=0,n=0,u=e*l,m=t+s;for(let e=0;e<l;++e){let t=Number(o[u+e]);n+=t,i+=r[m+e*c]*t}let p=i/n;a[d++]=p}}return new n(e.type,a,s)}function f(e,t,{eps:r=1e-5}={}){if(2!==e.dims.length)throw Error("`layer_norm` currently only supports 2D input.");let[o,s]=e.dims;if(1!==t.length&&t[0]!==s)throw Error("`normalized_shape` must be a 1D array with shape `[input.dims[1]]`.");let[a,i]=F(e,1,0,!0),l=a.data,c=i.data,d=e.data,u=new d.constructor(d.length);for(let e=0;e<o;++e){let t=e*s;for(let o=0;o<s;++o){let s=t+o;u[s]=(d[s]-c[e])/(l[e]+r)}}return new n(e.type,u,e.dims)}function M(e,t){return e=e.slice(),null===t?e=e.filter(e=>1!==e):"number"==typeof t?1===e[t]&&e.splice(t,1):Array.isArray(t)&&(e=e.filter((e,r)=>1!==e||!t.includes(r))),e}function w(e,t){return t=T(t,e.length+1),(e=e.slice()).splice(t,0,1),e}function T(e,t,r=null,o=!0){if(e<-t||e>=t){if(!o)return e<-t?0:t;throw Error(`IndexError: index ${e} is out of bounds for dimension${null===r?"":" "+r} with size ${t}`)}return e<0&&(e=(e%t+t)%t),e}function P(e,t=0){t=T(t,e[0].dims.length);let r=e[0].dims.slice();r[t]=e.reduce((e,r)=>e+r.dims[t],0);let o=r.reduce((e,t)=>e*t,1),s=new e[0].data.constructor(o),a=e[0].type;if(0===t){let t=0;for(let r of e){let e=r.data;s.set(e,t),t+=e.length}}else{let o=0;for(let a=0;a<e.length;++a){let{data:i,dims:n}=e[a];for(let e=0;e<i.length;++e){let a=0;for(let s=n.length-1,i=e,l=1;s>=0;--s){let e=n[s],c=i%e;s===t&&(c+=o),a+=c*l,l*=r[s],i=Math.floor(i/e)}s[a]=i[e]}o+=n[t]}}return new n(a,s,r)}function x(e,t=0){return P(e.map(e=>e.unsqueeze(t)),t)}function b(e,t,r=null,o=!1,s=null){let a=t.data,i=t.dims;r=T(r,i.length);let n=i.slice();n[r]=1;let l=new a.constructor(a.length/i[r]);null!==s&&l.fill(s);for(let t=0;t<a.length;++t){let o=0;for(let e=i.length-1,s=t,a=1;e>=0;--e){let t=i[e];e!==r&&(o+=s%t*a,a*=n[e]),s=Math.floor(s/t)}l[o]=e(l[o],a[t],t,o)}return o||n.splice(r,1),[t.type,l,n]}function F(e,t=null,r=1,o=!1){let s=e.data,a=e.dims;if(null===t){let t=s.reduce((e,t)=>e+t,0)/s.length,o=Math.sqrt(s.reduce((e,r)=>e+(r-t)**2,0)/(s.length-r)),a=new n(e.type,[t],[]);return[new n(e.type,[o],[]),a]}let i=k(e,t=T(t,a.length),o),l=i.data,[c,d,u]=b((e,t,r,o)=>e+(t-l[o])**2,e,t,o);for(let e=0;e<d.length;++e)d[e]=Math.sqrt(d[e]/(a[t]-r));return[new n(c,d,u),i]}function k(e,t=null,r=!1){let o=e.dims,s=e.data;if(null===t){let t=s.reduce((e,t)=>e+t,0);return new n(e.type,[t/s.length],[])}let[a,i,l]=b((e,t)=>e+t,e,t=T(t,o.length),r);if(1!==o[t])for(let e=0;e<i.length;++e)i[e]/=o[t];return new n(a,i,l)}function y(e,t,r,o){return new n(r,new o(e.reduce((e,t)=>e*t,1)).fill(t),e)}function v(e,t){let r,o;if("number"==typeof t)r="float32",o=Float32Array;else if("bigint"==typeof t)r="int64",o=BigInt64Array;else if("boolean"==typeof t)r="bool",o=Uint8Array;else throw Error(`Unsupported data type: ${typeof t}`);return y(e,t,r,o)}function C(e,t){return v(e.dims,t)}function S(e){return y(e,1n,"int64",BigInt64Array)}function E(e){return S(e.dims)}function A(e){return y(e,0n,"int64",BigInt64Array)}function L(e){return A(e.dims)}function I(e){let t=e.reduce((e,t)=>e*t,1);return new n("float32",Float32Array.from({length:t},()=>Math.random()),e)}function D(e){let t=e.reduce((e,t)=>e*t,1);return new n("float32",Float32Array.from({length:t},()=>Math.sqrt(-2*Math.log(1-Math.random()))*Math.cos(2*Math.PI*(1-Math.random()))),e)}function z(e,t){if(2!==e.dims.length)throw Error("The tensor must have 2 dimensions");if(e.dims.at(-1)%8!=0)throw Error("The last dimension of the tensor must be a multiple of 8");if(!["binary","ubinary"].includes(t))throw Error("The precision must be either 'binary' or 'ubinary'");let r="binary"===t,o=r?Int8Array:Uint8Array,s=e.data,a=new o(s.length/8);for(let e=0;e<s.length;++e){let t=+(s[e]>0),o=Math.floor(e/8),i=e%8;a[o]|=t<<7-i,r&&0===i&&(a[o]-=128)}return new n(r?"int8":"uint8",a,[e.dims[0],e.dims[1]/8])}},"./src/utils/video.js":(e,t,r)=>{r.r(t),r.d(t,{RawVideo:()=>i,RawVideoFrame:()=>a,load_video:()=>n});var o=r("./src/utils/image.js"),s=r("./src/env.js");class a{constructor(e,t){this.image=e,this.timestamp=t}}class i{constructor(e,t){e.length>0&&e[0]instanceof o.RawImage&&(e=e.map((r,o)=>new a(r,(o+1)/(e.length+1)*t))),this.frames=e,this.duration=t}get width(){return this.frames[0].image.width}get height(){return this.frames[0].image.height}get fps(){return this.frames.length/this.duration}}async function n(e,{num_frames:t=null,fps:r=null}={}){let l,c;if(!s.apis.IS_BROWSER_ENV)throw Error("`load_video` is currently only supported in browser environments.");if(null==t&&null==r)throw Error("Either num_frames or fps must be provided.");let d=[],u=document.createElement("video");if(u.crossOrigin="anonymous",u.muted=!0,"string"==typeof e)u.src=e;else if(e instanceof Blob)u.src=URL.createObjectURL(e);else if(e instanceof HTMLVideoElement)u.src=e.src;else throw Error("Invalid URL or video element provided.");if(await new Promise(e=>u.onloadedmetadata=e),u.seekable.start(0)===u.seekable.end(0)){let e=await fetch(u.src),t=await e.blob();u.src=URL.createObjectURL(t),await new Promise(e=>u.onloadedmetadata=e)}let m=u.duration;null!=t?(l=t,c=1===t?0:m/(t-1)):l=Math.floor(m/(c=1/r));let p=[];for(let e=0;e<l;++e)p.push(1===t?m/2:e*c);let _=document.createElement("canvas");_.width=u.videoWidth,_.height=u.videoHeight;let h=_.getContext("2d",{willReadFrequently:!0});for(let e of p){u.currentTime=e,await new Promise(e=>{u.onseeked=e}),h.drawImage(u,0,0,_.width,_.height);let t=h.getImageData(0,0,_.width,_.height),r=new a(new o.RawImage(t.data,_.width,_.height,4),e);d.push(r)}return u.remove(),new i(d,m)}}},l={};function c(e){var t=l[e];if(void 0!==t)return t.exports;var r=l[e]={exports:{}};return n[e](r,r.exports,c),r.exports}(()=>{var e,t=Object.getPrototypeOf?e=>Object.getPrototypeOf(e):e=>e.__proto__;c.t=function(r,o){if(1&o&&(r=this(r)),8&o||"object"==typeof r&&r&&(4&o&&r.__esModule||16&o&&"function"==typeof r.then))return r;var s=Object.create(null);c.r(s);var a={};e=e||[null,t({}),t([]),t(t)];for(var i=2&o&&r;"object"==typeof i&&!~e.indexOf(i);i=t(i))Object.getOwnPropertyNames(i).forEach(e=>a[e]=()=>r[e]);return a.default=()=>r,c.d(s,a),s}})(),c.d=(e,t)=>{for(var r in t)c.o(t,r)&&!c.o(e,r)&&Object.defineProperty(e,r,{enumerable:!0,get:t[r]})},c.o=(e,t)=>Object.prototype.hasOwnProperty.call(e,t),c.r=e=>{"undefined"!=typeof Symbol&&Symbol.toStringTag&&Object.defineProperty(e,Symbol.toStringTag,{value:"Module"}),Object.defineProperty(e,"__esModule",{value:!0})};var d={};(()=>{c.r(d),c.d(d,{ASTFeatureExtractor:()=>p.ASTFeatureExtractor,ASTForAudioClassification:()=>r.ASTForAudioClassification,ASTModel:()=>r.ASTModel,ASTPreTrainedModel:()=>r.ASTPreTrainedModel,AlbertForMaskedLM:()=>r.AlbertForMaskedLM,AlbertForQuestionAnswering:()=>r.AlbertForQuestionAnswering,AlbertForSequenceClassification:()=>r.AlbertForSequenceClassification,AlbertModel:()=>r.AlbertModel,AlbertPreTrainedModel:()=>r.AlbertPreTrainedModel,AlbertTokenizer:()=>o.AlbertTokenizer,ArceeForCausalLM:()=>r.ArceeForCausalLM,ArceeModel:()=>r.ArceeModel,ArceePreTrainedModel:()=>r.ArceePreTrainedModel,AudioClassificationPipeline:()=>t.AudioClassificationPipeline,AutoConfig:()=>s.AutoConfig,AutoFeatureExtractor:()=>_.AutoFeatureExtractor,AutoImageProcessor:()=>f.AutoImageProcessor,AutoModel:()=>r.AutoModel,AutoModelForAudioClassification:()=>r.AutoModelForAudioClassification,AutoModelForAudioFrameClassification:()=>r.AutoModelForAudioFrameClassification,AutoModelForAudioTextToText:()=>r.AutoModelForAudioTextToText,AutoModelForCTC:()=>r.AutoModelForCTC,AutoModelForCausalLM:()=>r.AutoModelForCausalLM,AutoModelForDepthEstimation:()=>r.AutoModelForDepthEstimation,AutoModelForDocumentQuestionAnswering:()=>r.AutoModelForDocumentQuestionAnswering,AutoModelForImageClassification:()=>r.AutoModelForImageClassification,AutoModelForImageFeatureExtraction:()=>r.AutoModelForImageFeatureExtraction,AutoModelForImageMatting:()=>r.AutoModelForImageMatting,AutoModelForImageSegmentation:()=>r.AutoModelForImageSegmentation,AutoModelForImageTextToText:()=>r.AutoModelForImageTextToText,AutoModelForImageToImage:()=>r.AutoModelForImageToImage,AutoModelForMaskGeneration:()=>r.AutoModelForMaskGeneration,AutoModelForMaskedLM:()=>r.AutoModelForMaskedLM,AutoModelForNormalEstimation:()=>r.AutoModelForNormalEstimation,AutoModelForObjectDetection:()=>r.AutoModelForObjectDetection,AutoModelForPoseEstimation:()=>r.AutoModelForPoseEstimation,AutoModelForQuestionAnswering:()=>r.AutoModelForQuestionAnswering,AutoModelForSemanticSegmentation:()=>r.AutoModelForSemanticSegmentation,AutoModelForSeq2SeqLM:()=>r.AutoModelForSeq2SeqLM,AutoModelForSequenceClassification:()=>r.AutoModelForSequenceClassification,AutoModelForSpeechSeq2Seq:()=>r.AutoModelForSpeechSeq2Seq,AutoModelForTextToSpectrogram:()=>r.AutoModelForTextToSpectrogram,AutoModelForTextToWaveform:()=>r.AutoModelForTextToWaveform,AutoModelForTokenClassification:()=>r.AutoModelForTokenClassification,AutoModelForUniversalSegmentation:()=>r.AutoModelForUniversalSegmentation,AutoModelForVision2Seq:()=>r.AutoModelForVision2Seq,AutoModelForXVector:()=>r.AutoModelForXVector,AutoModelForZeroShotObjectDetection:()=>r.AutoModelForZeroShotObjectDetection,AutoProcessor:()=>T.AutoProcessor,AutoTokenizer:()=>o.AutoTokenizer,AutomaticSpeechRecognitionPipeline:()=>t.AutomaticSpeechRecognitionPipeline,BackgroundRemovalPipeline:()=>t.BackgroundRemovalPipeline,BartForConditionalGeneration:()=>r.BartForConditionalGeneration,BartForSequenceClassification:()=>r.BartForSequenceClassification,BartModel:()=>r.BartModel,BartPretrainedModel:()=>r.BartPretrainedModel,BartTokenizer:()=>o.BartTokenizer,BaseModelOutput:()=>r.BaseModelOutput,BaseStreamer:()=>P.BaseStreamer,BeitFeatureExtractor:()=>g.BeitFeatureExtractor,BeitForImageClassification:()=>r.BeitForImageClassification,BeitModel:()=>r.BeitModel,BeitPreTrainedModel:()=>r.BeitPreTrainedModel,BertForMaskedLM:()=>r.BertForMaskedLM,BertForQuestionAnswering:()=>r.BertForQuestionAnswering,BertForSequenceClassification:()=>r.BertForSequenceClassification,BertForTokenClassification:()=>r.BertForTokenClassification,BertModel:()=>r.BertModel,BertPreTrainedModel:()=>r.BertPreTrainedModel,BertTokenizer:()=>o.BertTokenizer,BitImageProcessor:()=>g.BitImageProcessor,BlenderbotForConditionalGeneration:()=>r.BlenderbotForConditionalGeneration,BlenderbotModel:()=>r.BlenderbotModel,BlenderbotPreTrainedModel:()=>r.BlenderbotPreTrainedModel,BlenderbotSmallForConditionalGeneration:()=>r.BlenderbotSmallForConditionalGeneration,BlenderbotSmallModel:()=>r.BlenderbotSmallModel,BlenderbotSmallPreTrainedModel:()=>r.BlenderbotSmallPreTrainedModel,BlenderbotSmallTokenizer:()=>o.BlenderbotSmallTokenizer,BlenderbotTokenizer:()=>o.BlenderbotTokenizer,BloomForCausalLM:()=>r.BloomForCausalLM,BloomModel:()=>r.BloomModel,BloomPreTrainedModel:()=>r.BloomPreTrainedModel,BloomTokenizer:()=>o.BloomTokenizer,CLIPFeatureExtractor:()=>g.CLIPFeatureExtractor,CLIPImageProcessor:()=>g.CLIPImageProcessor,CLIPModel:()=>r.CLIPModel,CLIPPreTrainedModel:()=>r.CLIPPreTrainedModel,CLIPSegForImageSegmentation:()=>r.CLIPSegForImageSegmentation,CLIPSegModel:()=>r.CLIPSegModel,CLIPSegPreTrainedModel:()=>r.CLIPSegPreTrainedModel,CLIPTextModel:()=>r.CLIPTextModel,CLIPTextModelWithProjection:()=>r.CLIPTextModelWithProjection,CLIPTokenizer:()=>o.CLIPTokenizer,CLIPVisionModel:()=>r.CLIPVisionModel,CLIPVisionModelWithProjection:()=>r.CLIPVisionModelWithProjection,CamembertForMaskedLM:()=>r.CamembertForMaskedLM,CamembertForQuestionAnswering:()=>r.CamembertForQuestionAnswering,CamembertForSequenceClassification:()=>r.CamembertForSequenceClassification,CamembertForTokenClassification:()=>r.CamembertForTokenClassification,CamembertModel:()=>r.CamembertModel,CamembertPreTrainedModel:()=>r.CamembertPreTrainedModel,CamembertTokenizer:()=>o.CamembertTokenizer,CausalLMOutput:()=>r.CausalLMOutput,CausalLMOutputWithPast:()=>r.CausalLMOutputWithPast,ChineseCLIPFeatureExtractor:()=>g.ChineseCLIPFeatureExtractor,ChineseCLIPModel:()=>r.ChineseCLIPModel,ChineseCLIPPreTrainedModel:()=>r.ChineseCLIPPreTrainedModel,ClapAudioModelWithProjection:()=>r.ClapAudioModelWithProjection,ClapFeatureExtractor:()=>p.ClapFeatureExtractor,ClapModel:()=>r.ClapModel,ClapPreTrainedModel:()=>r.ClapPreTrainedModel,ClapTextModelWithProjection:()=>r.ClapTextModelWithProjection,ClassifierFreeGuidanceLogitsProcessor:()=>b.ClassifierFreeGuidanceLogitsProcessor,CodeGenForCausalLM:()=>r.CodeGenForCausalLM,CodeGenModel:()=>r.CodeGenModel,CodeGenPreTrainedModel:()=>r.CodeGenPreTrainedModel,CodeGenTokenizer:()=>o.CodeGenTokenizer,CodeLlamaTokenizer:()=>o.CodeLlamaTokenizer,CohereForCausalLM:()=>r.CohereForCausalLM,CohereModel:()=>r.CohereModel,CoherePreTrainedModel:()=>r.CoherePreTrainedModel,CohereTokenizer:()=>o.CohereTokenizer,ConvBertForMaskedLM:()=>r.ConvBertForMaskedLM,ConvBertForQuestionAnswering:()=>r.ConvBertForQuestionAnswering,ConvBertForSequenceClassification:()=>r.ConvBertForSequenceClassification,ConvBertForTokenClassification:()=>r.ConvBertForTokenClassification,ConvBertModel:()=>r.ConvBertModel,ConvBertPreTrainedModel:()=>r.ConvBertPreTrainedModel,ConvBertTokenizer:()=>o.ConvBertTokenizer,ConvNextFeatureExtractor:()=>g.ConvNextFeatureExtractor,ConvNextForImageClassification:()=>r.ConvNextForImageClassification,ConvNextImageProcessor:()=>g.ConvNextImageProcessor,ConvNextModel:()=>r.ConvNextModel,ConvNextPreTrainedModel:()=>r.ConvNextPreTrainedModel,ConvNextV2ForImageClassification:()=>r.ConvNextV2ForImageClassification,ConvNextV2Model:()=>r.ConvNextV2Model,ConvNextV2PreTrainedModel:()=>r.ConvNextV2PreTrainedModel,DFineForObjectDetection:()=>r.DFineForObjectDetection,DFineModel:()=>r.DFineModel,DFinePreTrainedModel:()=>r.DFinePreTrainedModel,DINOv3ConvNextModel:()=>r.DINOv3ConvNextModel,DINOv3ConvNextPreTrainedModel:()=>r.DINOv3ConvNextPreTrainedModel,DINOv3ViTImageProcessor:()=>g.DINOv3ViTImageProcessor,DINOv3ViTModel:()=>r.DINOv3ViTModel,DINOv3ViTPreTrainedModel:()=>r.DINOv3ViTPreTrainedModel,DPTFeatureExtractor:()=>g.DPTFeatureExtractor,DPTForDepthEstimation:()=>r.DPTForDepthEstimation,DPTImageProcessor:()=>g.DPTImageProcessor,DPTModel:()=>r.DPTModel,DPTPreTrainedModel:()=>r.DPTPreTrainedModel,DacDecoderModel:()=>r.DacDecoderModel,DacDecoderOutput:()=>r.DacDecoderOutput,DacEncoderModel:()=>r.DacEncoderModel,DacEncoderOutput:()=>r.DacEncoderOutput,DacFeatureExtractor:()=>p.DacFeatureExtractor,DacModel:()=>r.DacModel,DacPreTrainedModel:()=>r.DacPreTrainedModel,DataTypeMap:()=>l.DataTypeMap,DebertaForMaskedLM:()=>r.DebertaForMaskedLM,DebertaForQuestionAnswering:()=>r.DebertaForQuestionAnswering,DebertaForSequenceClassification:()=>r.DebertaForSequenceClassification,DebertaForTokenClassification:()=>r.DebertaForTokenClassification,DebertaModel:()=>r.DebertaModel,DebertaPreTrainedModel:()=>r.DebertaPreTrainedModel,DebertaTokenizer:()=>o.DebertaTokenizer,DebertaV2ForMaskedLM:()=>r.DebertaV2ForMaskedLM,DebertaV2ForQuestionAnswering:()=>r.DebertaV2ForQuestionAnswering,DebertaV2ForSequenceClassification:()=>r.DebertaV2ForSequenceClassification,DebertaV2ForTokenClassification:()=>r.DebertaV2ForTokenClassification,DebertaV2Model:()=>r.DebertaV2Model,DebertaV2PreTrainedModel:()=>r.DebertaV2PreTrainedModel,DebertaV2Tokenizer:()=>o.DebertaV2Tokenizer,DecisionTransformerModel:()=>r.DecisionTransformerModel,DecisionTransformerPreTrainedModel:()=>r.DecisionTransformerPreTrainedModel,DeiTFeatureExtractor:()=>g.DeiTFeatureExtractor,DeiTForImageClassification:()=>r.DeiTForImageClassification,DeiTImageProcessor:()=>g.DeiTImageProcessor,DeiTModel:()=>r.DeiTModel,DeiTPreTrainedModel:()=>r.DeiTPreTrainedModel,DepthAnythingForDepthEstimation:()=>r.DepthAnythingForDepthEstimation,DepthAnythingPreTrainedModel:()=>r.DepthAnythingPreTrainedModel,DepthEstimationPipeline:()=>t.DepthEstimationPipeline,DepthProForDepthEstimation:()=>r.DepthProForDepthEstimation,DepthProPreTrainedModel:()=>r.DepthProPreTrainedModel,DetrFeatureExtractor:()=>g.DetrFeatureExtractor,DetrForObjectDetection:()=>r.DetrForObjectDetection,DetrForSegmentation:()=>r.DetrForSegmentation,DetrImageProcessor:()=>g.DetrImageProcessor,DetrModel:()=>r.DetrModel,DetrObjectDetectionOutput:()=>r.DetrObjectDetectionOutput,DetrPreTrainedModel:()=>r.DetrPreTrainedModel,DetrSegmentationOutput:()=>r.DetrSegmentationOutput,Dinov2ForImageClassification:()=>r.Dinov2ForImageClassification,Dinov2Model:()=>r.Dinov2Model,Dinov2PreTrainedModel:()=>r.Dinov2PreTrainedModel,Dinov2WithRegistersForImageClassification:()=>r.Dinov2WithRegistersForImageClassification,Dinov2WithRegistersModel:()=>r.Dinov2WithRegistersModel,Dinov2WithRegistersPreTrainedModel:()=>r.Dinov2WithRegistersPreTrainedModel,DistilBertForMaskedLM:()=>r.DistilBertForMaskedLM,DistilBertForQuestionAnswering:()=>r.DistilBertForQuestionAnswering,DistilBertForSequenceClassification:()=>r.DistilBertForSequenceClassification,DistilBertForTokenClassification:()=>r.DistilBertForTokenClassification,DistilBertModel:()=>r.DistilBertModel,DistilBertPreTrainedModel:()=>r.DistilBertPreTrainedModel,DistilBertTokenizer:()=>o.DistilBertTokenizer,DocumentQuestionAnsweringPipeline:()=>t.DocumentQuestionAnsweringPipeline,DonutFeatureExtractor:()=>g.DonutFeatureExtractor,DonutImageProcessor:()=>g.DonutImageProcessor,DonutSwinModel:()=>r.DonutSwinModel,DonutSwinPreTrainedModel:()=>r.DonutSwinPreTrainedModel,EdgeTamModel:()=>r.EdgeTamModel,EfficientNetForImageClassification:()=>r.EfficientNetForImageClassification,EfficientNetImageProcessor:()=>g.EfficientNetImageProcessor,EfficientNetModel:()=>r.EfficientNetModel,EfficientNetPreTrainedModel:()=>r.EfficientNetPreTrainedModel,ElectraForMaskedLM:()=>r.ElectraForMaskedLM,ElectraForQuestionAnswering:()=>r.ElectraForQuestionAnswering,ElectraForSequenceClassification:()=>r.ElectraForSequenceClassification,ElectraForTokenClassification:()=>r.ElectraForTokenClassification,ElectraModel:()=>r.ElectraModel,ElectraPreTrainedModel:()=>r.ElectraPreTrainedModel,ElectraTokenizer:()=>o.ElectraTokenizer,EncodecFeatureExtractor:()=>p.EncodecFeatureExtractor,EosTokenCriteria:()=>x.EosTokenCriteria,Ernie4_5ForCausalLM:()=>r.Ernie4_5ForCausalLM,Ernie4_5Model:()=>r.Ernie4_5Model,Ernie4_5PreTrainedModel:()=>r.Ernie4_5PreTrainedModel,EsmForMaskedLM:()=>r.EsmForMaskedLM,EsmForSequenceClassification:()=>r.EsmForSequenceClassification,EsmForTokenClassification:()=>r.EsmForTokenClassification,EsmModel:()=>r.EsmModel,EsmPreTrainedModel:()=>r.EsmPreTrainedModel,EsmTokenizer:()=>o.EsmTokenizer,ExaoneForCausalLM:()=>r.ExaoneForCausalLM,ExaoneModel:()=>r.ExaoneModel,ExaonePreTrainedModel:()=>r.ExaonePreTrainedModel,FFT:()=>u.FFT,FalconForCausalLM:()=>r.FalconForCausalLM,FalconModel:()=>r.FalconModel,FalconPreTrainedModel:()=>r.FalconPreTrainedModel,FalconTokenizer:()=>o.FalconTokenizer,FastViTForImageClassification:()=>r.FastViTForImageClassification,FastViTModel:()=>r.FastViTModel,FastViTPreTrainedModel:()=>r.FastViTPreTrainedModel,FeatureExtractionPipeline:()=>t.FeatureExtractionPipeline,FeatureExtractor:()=>m.FeatureExtractor,FillMaskPipeline:()=>t.FillMaskPipeline,Florence2ForConditionalGeneration:()=>r.Florence2ForConditionalGeneration,Florence2PreTrainedModel:()=>r.Florence2PreTrainedModel,Florence2Processor:()=>w.Florence2Processor,ForcedBOSTokenLogitsProcessor:()=>b.ForcedBOSTokenLogitsProcessor,ForcedEOSTokenLogitsProcessor:()=>b.ForcedEOSTokenLogitsProcessor,GLPNFeatureExtractor:()=>g.GLPNFeatureExtractor,GLPNForDepthEstimation:()=>r.GLPNForDepthEstimation,GLPNModel:()=>r.GLPNModel,GLPNPreTrainedModel:()=>r.GLPNPreTrainedModel,GPT2LMHeadModel:()=>r.GPT2LMHeadModel,GPT2Model:()=>r.GPT2Model,GPT2PreTrainedModel:()=>r.GPT2PreTrainedModel,GPT2Tokenizer:()=>o.GPT2Tokenizer,GPTBigCodeForCausalLM:()=>r.GPTBigCodeForCausalLM,GPTBigCodeModel:()=>r.GPTBigCodeModel,GPTBigCodePreTrainedModel:()=>r.GPTBigCodePreTrainedModel,GPTJForCausalLM:()=>r.GPTJForCausalLM,GPTJModel:()=>r.GPTJModel,GPTJPreTrainedModel:()=>r.GPTJPreTrainedModel,GPTNeoForCausalLM:()=>r.GPTNeoForCausalLM,GPTNeoModel:()=>r.GPTNeoModel,GPTNeoPreTrainedModel:()=>r.GPTNeoPreTrainedModel,GPTNeoXForCausalLM:()=>r.GPTNeoXForCausalLM,GPTNeoXModel:()=>r.GPTNeoXModel,GPTNeoXPreTrainedModel:()=>r.GPTNeoXPreTrainedModel,GPTNeoXTokenizer:()=>o.GPTNeoXTokenizer,Gemma2ForCausalLM:()=>r.Gemma2ForCausalLM,Gemma2Model:()=>r.Gemma2Model,Gemma2PreTrainedModel:()=>r.Gemma2PreTrainedModel,Gemma3ForCausalLM:()=>r.Gemma3ForCausalLM,Gemma3Model:()=>r.Gemma3Model,Gemma3PreTrainedModel:()=>r.Gemma3PreTrainedModel,Gemma3nAudioFeatureExtractor:()=>p.Gemma3nAudioFeatureExtractor,Gemma3nForConditionalGeneration:()=>r.Gemma3nForConditionalGeneration,Gemma3nPreTrainedModel:()=>r.Gemma3nPreTrainedModel,Gemma3nProcessor:()=>w.Gemma3nProcessor,GemmaForCausalLM:()=>r.GemmaForCausalLM,GemmaModel:()=>r.GemmaModel,GemmaPreTrainedModel:()=>r.GemmaPreTrainedModel,GemmaTokenizer:()=>o.GemmaTokenizer,GlmForCausalLM:()=>r.GlmForCausalLM,GlmModel:()=>r.GlmModel,GlmPreTrainedModel:()=>r.GlmPreTrainedModel,GraniteForCausalLM:()=>r.GraniteForCausalLM,GraniteModel:()=>r.GraniteModel,GraniteMoeHybridForCausalLM:()=>r.GraniteMoeHybridForCausalLM,GraniteMoeHybridModel:()=>r.GraniteMoeHybridModel,GraniteMoeHybridPreTrainedModel:()=>r.GraniteMoeHybridPreTrainedModel,GranitePreTrainedModel:()=>r.GranitePreTrainedModel,Grok1Tokenizer:()=>o.Grok1Tokenizer,GroundingDinoForObjectDetection:()=>r.GroundingDinoForObjectDetection,GroundingDinoImageProcessor:()=>g.GroundingDinoImageProcessor,GroundingDinoPreTrainedModel:()=>r.GroundingDinoPreTrainedModel,GroundingDinoProcessor:()=>w.GroundingDinoProcessor,GroupViTModel:()=>r.GroupViTModel,GroupViTPreTrainedModel:()=>r.GroupViTPreTrainedModel,HeliumForCausalLM:()=>r.HeliumForCausalLM,HeliumModel:()=>r.HeliumModel,HeliumPreTrainedModel:()=>r.HeliumPreTrainedModel,HerbertTokenizer:()=>o.HerbertTokenizer,HieraForImageClassification:()=>r.HieraForImageClassification,HieraModel:()=>r.HieraModel,HieraPreTrainedModel:()=>r.HieraPreTrainedModel,HubertForCTC:()=>r.HubertForCTC,HubertForSequenceClassification:()=>r.HubertForSequenceClassification,HubertModel:()=>r.HubertModel,HubertPreTrainedModel:()=>r.HubertPreTrainedModel,IJepaForImageClassification:()=>r.IJepaForImageClassification,IJepaModel:()=>r.IJepaModel,IJepaPreTrainedModel:()=>r.IJepaPreTrainedModel,Idefics3ForConditionalGeneration:()=>r.Idefics3ForConditionalGeneration,Idefics3ImageProcessor:()=>g.Idefics3ImageProcessor,Idefics3PreTrainedModel:()=>r.Idefics3PreTrainedModel,Idefics3Processor:()=>w.Idefics3Processor,ImageClassificationPipeline:()=>t.ImageClassificationPipeline,ImageFeatureExtractionPipeline:()=>t.ImageFeatureExtractionPipeline,ImageFeatureExtractor:()=>p.ImageFeatureExtractor,ImageMattingOutput:()=>r.ImageMattingOutput,ImageProcessor:()=>h.ImageProcessor,ImageSegmentationPipeline:()=>t.ImageSegmentationPipeline,ImageToImagePipeline:()=>t.ImageToImagePipeline,ImageToTextPipeline:()=>t.ImageToTextPipeline,InterruptableStoppingCriteria:()=>x.InterruptableStoppingCriteria,JAISLMHeadModel:()=>r.JAISLMHeadModel,JAISModel:()=>r.JAISModel,JAISPreTrainedModel:()=>r.JAISPreTrainedModel,JinaCLIPImageProcessor:()=>g.JinaCLIPImageProcessor,JinaCLIPModel:()=>r.JinaCLIPModel,JinaCLIPPreTrainedModel:()=>r.JinaCLIPPreTrainedModel,JinaCLIPProcessor:()=>w.JinaCLIPProcessor,JinaCLIPTextModel:()=>r.JinaCLIPTextModel,JinaCLIPVisionModel:()=>r.JinaCLIPVisionModel,Lfm2ForCausalLM:()=>r.Lfm2ForCausalLM,Lfm2Model:()=>r.Lfm2Model,Lfm2PreTrainedModel:()=>r.Lfm2PreTrainedModel,LiteWhisperForConditionalGeneration:()=>r.LiteWhisperForConditionalGeneration,Llama4ForCausalLM:()=>r.Llama4ForCausalLM,Llama4PreTrainedModel:()=>r.Llama4PreTrainedModel,LlamaForCausalLM:()=>r.LlamaForCausalLM,LlamaModel:()=>r.LlamaModel,LlamaPreTrainedModel:()=>r.LlamaPreTrainedModel,LlamaTokenizer:()=>o.LlamaTokenizer,LlavaForConditionalGeneration:()=>r.LlavaForConditionalGeneration,LlavaOnevisionForConditionalGeneration:()=>r.LlavaOnevisionForConditionalGeneration,LlavaOnevisionImageProcessor:()=>g.LlavaOnevisionImageProcessor,LlavaPreTrainedModel:()=>r.LlavaPreTrainedModel,LlavaProcessor:()=>w.LlavaProcessor,LlavaQwen2ForCausalLM:()=>r.LlavaQwen2ForCausalLM,LogitsProcessor:()=>b.LogitsProcessor,LogitsProcessorList:()=>b.LogitsProcessorList,LogitsWarper:()=>b.LogitsWarper,LongT5ForConditionalGeneration:()=>r.LongT5ForConditionalGeneration,LongT5Model:()=>r.LongT5Model,LongT5PreTrainedModel:()=>r.LongT5PreTrainedModel,M2M100ForConditionalGeneration:()=>r.M2M100ForConditionalGeneration,M2M100Model:()=>r.M2M100Model,M2M100PreTrainedModel:()=>r.M2M100PreTrainedModel,M2M100Tokenizer:()=>o.M2M100Tokenizer,MBart50Tokenizer:()=>o.MBart50Tokenizer,MBartForCausalLM:()=>r.MBartForCausalLM,MBartForConditionalGeneration:()=>r.MBartForConditionalGeneration,MBartForSequenceClassification:()=>r.MBartForSequenceClassification,MBartModel:()=>r.MBartModel,MBartPreTrainedModel:()=>r.MBartPreTrainedModel,MBartTokenizer:()=>o.MBartTokenizer,MPNetForMaskedLM:()=>r.MPNetForMaskedLM,MPNetForQuestionAnswering:()=>r.MPNetForQuestionAnswering,MPNetForSequenceClassification:()=>r.MPNetForSequenceClassification,MPNetForTokenClassification:()=>r.MPNetForTokenClassification,MPNetModel:()=>r.MPNetModel,MPNetPreTrainedModel:()=>r.MPNetPreTrainedModel,MPNetTokenizer:()=>o.MPNetTokenizer,MT5ForConditionalGeneration:()=>r.MT5ForConditionalGeneration,MT5Model:()=>r.MT5Model,MT5PreTrainedModel:()=>r.MT5PreTrainedModel,MarianMTModel:()=>r.MarianMTModel,MarianModel:()=>r.MarianModel,MarianPreTrainedModel:()=>r.MarianPreTrainedModel,MarianTokenizer:()=>o.MarianTokenizer,Mask2FormerImageProcessor:()=>g.Mask2FormerImageProcessor,MaskFormerFeatureExtractor:()=>g.MaskFormerFeatureExtractor,MaskFormerForInstanceSegmentation:()=>r.MaskFormerForInstanceSegmentation,MaskFormerImageProcessor:()=>g.MaskFormerImageProcessor,MaskFormerModel:()=>r.MaskFormerModel,MaskFormerPreTrainedModel:()=>r.MaskFormerPreTrainedModel,MaskedLMOutput:()=>r.MaskedLMOutput,MaxLengthCriteria:()=>x.MaxLengthCriteria,Metric3DForDepthEstimation:()=>r.Metric3DForDepthEstimation,Metric3DPreTrainedModel:()=>r.Metric3DPreTrainedModel,Metric3Dv2ForDepthEstimation:()=>r.Metric3Dv2ForDepthEstimation,Metric3Dv2PreTrainedModel:()=>r.Metric3Dv2PreTrainedModel,MgpstrForSceneTextRecognition:()=>r.MgpstrForSceneTextRecognition,MgpstrModelOutput:()=>r.MgpstrModelOutput,MgpstrPreTrainedModel:()=>r.MgpstrPreTrainedModel,MgpstrProcessor:()=>w.MgpstrProcessor,MgpstrTokenizer:()=>o.MgpstrTokenizer,MimiDecoderModel:()=>r.MimiDecoderModel,MimiDecoderOutput:()=>r.MimiDecoderOutput,MimiEncoderModel:()=>r.MimiEncoderModel,MimiEncoderOutput:()=>r.MimiEncoderOutput,MimiModel:()=>r.MimiModel,MimiPreTrainedModel:()=>r.MimiPreTrainedModel,MinLengthLogitsProcessor:()=>b.MinLengthLogitsProcessor,MinNewTokensLengthLogitsProcessor:()=>b.MinNewTokensLengthLogitsProcessor,Ministral3ForCausalLM:()=>r.Ministral3ForCausalLM,Ministral3Model:()=>r.Ministral3Model,Ministral3PreTrainedModel:()=>r.Ministral3PreTrainedModel,MinistralForCausalLM:()=>r.MinistralForCausalLM,MinistralModel:()=>r.MinistralModel,MinistralPreTrainedModel:()=>r.MinistralPreTrainedModel,Mistral3ForConditionalGeneration:()=>r.Mistral3ForConditionalGeneration,MistralForCausalLM:()=>r.MistralForCausalLM,MistralModel:()=>r.MistralModel,MistralPreTrainedModel:()=>r.MistralPreTrainedModel,MobileBertForMaskedLM:()=>r.MobileBertForMaskedLM,MobileBertForQuestionAnswering:()=>r.MobileBertForQuestionAnswering,MobileBertForSequenceClassification:()=>r.MobileBertForSequenceClassification,MobileBertModel:()=>r.MobileBertModel,MobileBertPreTrainedModel:()=>r.MobileBertPreTrainedModel,MobileBertTokenizer:()=>o.MobileBertTokenizer,MobileLLMForCausalLM:()=>r.MobileLLMForCausalLM,MobileLLMModel:()=>r.MobileLLMModel,MobileLLMPreTrainedModel:()=>r.MobileLLMPreTrainedModel,MobileNetV1FeatureExtractor:()=>g.MobileNetV1FeatureExtractor,MobileNetV1ForImageClassification:()=>r.MobileNetV1ForImageClassification,MobileNetV1ForSemanticSegmentation:()=>r.MobileNetV1ForSemanticSegmentation,MobileNetV1ImageProcessor:()=>g.MobileNetV1ImageProcessor,MobileNetV1Model:()=>r.MobileNetV1Model,MobileNetV1PreTrainedModel:()=>r.MobileNetV1PreTrainedModel,MobileNetV2FeatureExtractor:()=>g.MobileNetV2FeatureExtractor,MobileNetV2ForImageClassification:()=>r.MobileNetV2ForImageClassification,MobileNetV2ForSemanticSegmentation:()=>r.MobileNetV2ForSemanticSegmentation,MobileNetV2ImageProcessor:()=>g.MobileNetV2ImageProcessor,MobileNetV2Model:()=>r.MobileNetV2Model,MobileNetV2PreTrainedModel:()=>r.MobileNetV2PreTrainedModel,MobileNetV3FeatureExtractor:()=>g.MobileNetV3FeatureExtractor,MobileNetV3ForImageClassification:()=>r.MobileNetV3ForImageClassification,MobileNetV3ForSemanticSegmentation:()=>r.MobileNetV3ForSemanticSegmentation,MobileNetV3ImageProcessor:()=>g.MobileNetV3ImageProcessor,MobileNetV3Model:()=>r.MobileNetV3Model,MobileNetV3PreTrainedModel:()=>r.MobileNetV3PreTrainedModel,MobileNetV4FeatureExtractor:()=>g.MobileNetV4FeatureExtractor,MobileNetV4ForImageClassification:()=>r.MobileNetV4ForImageClassification,MobileNetV4ForSemanticSegmentation:()=>r.MobileNetV4ForSemanticSegmentation,MobileNetV4ImageProcessor:()=>g.MobileNetV4ImageProcessor,MobileNetV4Model:()=>r.MobileNetV4Model,MobileNetV4PreTrainedModel:()=>r.MobileNetV4PreTrainedModel,MobileViTFeatureExtractor:()=>g.MobileViTFeatureExtractor,MobileViTForImageClassification:()=>r.MobileViTForImageClassification,MobileViTImageProcessor:()=>g.MobileViTImageProcessor,MobileViTModel:()=>r.MobileViTModel,MobileViTPreTrainedModel:()=>r.MobileViTPreTrainedModel,MobileViTV2ForImageClassification:()=>r.MobileViTV2ForImageClassification,MobileViTV2Model:()=>r.MobileViTV2Model,MobileViTV2PreTrainedModel:()=>r.MobileViTV2PreTrainedModel,ModelOutput:()=>r.ModelOutput,ModernBertDecoderForCausalLM:()=>r.ModernBertDecoderForCausalLM,ModernBertDecoderModel:()=>r.ModernBertDecoderModel,ModernBertDecoderPreTrainedModel:()=>r.ModernBertDecoderPreTrainedModel,ModernBertForMaskedLM:()=>r.ModernBertForMaskedLM,ModernBertForSequenceClassification:()=>r.ModernBertForSequenceClassification,ModernBertForTokenClassification:()=>r.ModernBertForTokenClassification,ModernBertModel:()=>r.ModernBertModel,ModernBertPreTrainedModel:()=>r.ModernBertPreTrainedModel,Moondream1ForConditionalGeneration:()=>r.Moondream1ForConditionalGeneration,MoonshineFeatureExtractor:()=>p.MoonshineFeatureExtractor,MoonshineForConditionalGeneration:()=>r.MoonshineForConditionalGeneration,MoonshineModel:()=>r.MoonshineModel,MoonshinePreTrainedModel:()=>r.MoonshinePreTrainedModel,MoonshineProcessor:()=>w.MoonshineProcessor,MptForCausalLM:()=>r.MptForCausalLM,MptModel:()=>r.MptModel,MptPreTrainedModel:()=>r.MptPreTrainedModel,MultiModalityCausalLM:()=>r.MultiModalityCausalLM,MultiModalityPreTrainedModel:()=>r.MultiModalityPreTrainedModel,MusicgenForCausalLM:()=>r.MusicgenForCausalLM,MusicgenForConditionalGeneration:()=>r.MusicgenForConditionalGeneration,MusicgenModel:()=>r.MusicgenModel,MusicgenPreTrainedModel:()=>r.MusicgenPreTrainedModel,NanoChatForCausalLM:()=>r.NanoChatForCausalLM,NanoChatModel:()=>r.NanoChatModel,NanoChatPreTrainedModel:()=>r.NanoChatPreTrainedModel,NeoBertForMaskedLM:()=>r.NeoBertForMaskedLM,NeoBertForQuestionAnswering:()=>r.NeoBertForQuestionAnswering,NeoBertForSequenceClassification:()=>r.NeoBertForSequenceClassification,NeoBertForTokenClassification:()=>r.NeoBertForTokenClassification,NeoBertModel:()=>r.NeoBertModel,NeoBertPreTrainedModel:()=>r.NeoBertPreTrainedModel,NllbTokenizer:()=>o.NllbTokenizer,NoBadWordsLogitsProcessor:()=>b.NoBadWordsLogitsProcessor,NoRepeatNGramLogitsProcessor:()=>b.NoRepeatNGramLogitsProcessor,NomicBertModel:()=>r.NomicBertModel,NomicBertPreTrainedModel:()=>r.NomicBertPreTrainedModel,NougatImageProcessor:()=>g.NougatImageProcessor,NougatTokenizer:()=>o.NougatTokenizer,OPTForCausalLM:()=>r.OPTForCausalLM,OPTModel:()=>r.OPTModel,OPTPreTrainedModel:()=>r.OPTPreTrainedModel,ObjectDetectionPipeline:()=>t.ObjectDetectionPipeline,Olmo2ForCausalLM:()=>r.Olmo2ForCausalLM,Olmo2Model:()=>r.Olmo2Model,Olmo2PreTrainedModel:()=>r.Olmo2PreTrainedModel,OlmoForCausalLM:()=>r.OlmoForCausalLM,OlmoModel:()=>r.OlmoModel,OlmoPreTrainedModel:()=>r.OlmoPreTrainedModel,OpenELMForCausalLM:()=>r.OpenELMForCausalLM,OpenELMModel:()=>r.OpenELMModel,OpenELMPreTrainedModel:()=>r.OpenELMPreTrainedModel,OwlViTFeatureExtractor:()=>g.OwlViTFeatureExtractor,OwlViTForObjectDetection:()=>r.OwlViTForObjectDetection,OwlViTImageProcessor:()=>g.OwlViTImageProcessor,OwlViTModel:()=>r.OwlViTModel,OwlViTPreTrainedModel:()=>r.OwlViTPreTrainedModel,OwlViTProcessor:()=>w.OwlViTProcessor,Owlv2ForObjectDetection:()=>r.Owlv2ForObjectDetection,Owlv2ImageProcessor:()=>g.Owlv2ImageProcessor,Owlv2Model:()=>r.Owlv2Model,Owlv2PreTrainedModel:()=>r.Owlv2PreTrainedModel,PaliGemmaForConditionalGeneration:()=>r.PaliGemmaForConditionalGeneration,PaliGemmaPreTrainedModel:()=>r.PaliGemmaPreTrainedModel,PaliGemmaProcessor:()=>w.PaliGemmaProcessor,ParakeetFeatureExtractor:()=>p.ParakeetFeatureExtractor,ParakeetForCTC:()=>r.ParakeetForCTC,ParakeetPreTrainedModel:()=>r.ParakeetPreTrainedModel,PatchTSMixerForPrediction:()=>r.PatchTSMixerForPrediction,PatchTSMixerModel:()=>r.PatchTSMixerModel,PatchTSMixerPreTrainedModel:()=>r.PatchTSMixerPreTrainedModel,PatchTSTForPrediction:()=>r.PatchTSTForPrediction,PatchTSTModel:()=>r.PatchTSTModel,PatchTSTPreTrainedModel:()=>r.PatchTSTPreTrainedModel,Phi3ForCausalLM:()=>r.Phi3ForCausalLM,Phi3Model:()=>r.Phi3Model,Phi3PreTrainedModel:()=>r.Phi3PreTrainedModel,Phi3VForCausalLM:()=>r.Phi3VForCausalLM,Phi3VImageProcessor:()=>g.Phi3VImageProcessor,Phi3VPreTrainedModel:()=>r.Phi3VPreTrainedModel,Phi3VProcessor:()=>w.Phi3VProcessor,PhiForCausalLM:()=>r.PhiForCausalLM,PhiModel:()=>r.PhiModel,PhiPreTrainedModel:()=>r.PhiPreTrainedModel,Pipeline:()=>t.Pipeline,PixtralImageProcessor:()=>g.PixtralImageProcessor,PixtralProcessor:()=>w.PixtralProcessor,PreTrainedModel:()=>r.PreTrainedModel,PreTrainedTokenizer:()=>o.PreTrainedTokenizer,PretrainedConfig:()=>s.PretrainedConfig,PretrainedMixin:()=>r.PretrainedMixin,Processor:()=>M.Processor,PvtForImageClassification:()=>r.PvtForImageClassification,PvtImageProcessor:()=>g.PvtImageProcessor,PvtModel:()=>r.PvtModel,PvtPreTrainedModel:()=>r.PvtPreTrainedModel,PyAnnoteFeatureExtractor:()=>p.PyAnnoteFeatureExtractor,PyAnnoteForAudioFrameClassification:()=>r.PyAnnoteForAudioFrameClassification,PyAnnoteModel:()=>r.PyAnnoteModel,PyAnnotePreTrainedModel:()=>r.PyAnnotePreTrainedModel,PyAnnoteProcessor:()=>w.PyAnnoteProcessor,QuestionAnsweringModelOutput:()=>r.QuestionAnsweringModelOutput,QuestionAnsweringPipeline:()=>t.QuestionAnsweringPipeline,Qwen2ForCausalLM:()=>r.Qwen2ForCausalLM,Qwen2Model:()=>r.Qwen2Model,Qwen2PreTrainedModel:()=>r.Qwen2PreTrainedModel,Qwen2Tokenizer:()=>o.Qwen2Tokenizer,Qwen2VLForConditionalGeneration:()=>r.Qwen2VLForConditionalGeneration,Qwen2VLImageProcessor:()=>g.Qwen2VLImageProcessor,Qwen2VLPreTrainedModel:()=>r.Qwen2VLPreTrainedModel,Qwen2VLProcessor:()=>w.Qwen2VLProcessor,Qwen3ForCausalLM:()=>r.Qwen3ForCausalLM,Qwen3Model:()=>r.Qwen3Model,Qwen3PreTrainedModel:()=>r.Qwen3PreTrainedModel,RFDetrForObjectDetection:()=>r.RFDetrForObjectDetection,RFDetrModel:()=>r.RFDetrModel,RFDetrObjectDetectionOutput:()=>r.RFDetrObjectDetectionOutput,RFDetrPreTrainedModel:()=>r.RFDetrPreTrainedModel,RTDetrForObjectDetection:()=>r.RTDetrForObjectDetection,RTDetrImageProcessor:()=>g.RTDetrImageProcessor,RTDetrModel:()=>r.RTDetrModel,RTDetrObjectDetectionOutput:()=>r.RTDetrObjectDetectionOutput,RTDetrPreTrainedModel:()=>r.RTDetrPreTrainedModel,RTDetrV2ForObjectDetection:()=>r.RTDetrV2ForObjectDetection,RTDetrV2Model:()=>r.RTDetrV2Model,RTDetrV2ObjectDetectionOutput:()=>r.RTDetrV2ObjectDetectionOutput,RTDetrV2PreTrainedModel:()=>r.RTDetrV2PreTrainedModel,RawAudio:()=>a.RawAudio,RawImage:()=>i.RawImage,RawVideo:()=>n.RawVideo,RawVideoFrame:()=>n.RawVideoFrame,RepetitionPenaltyLogitsProcessor:()=>b.RepetitionPenaltyLogitsProcessor,ResNetForImageClassification:()=>r.ResNetForImageClassification,ResNetModel:()=>r.ResNetModel,ResNetPreTrainedModel:()=>r.ResNetPreTrainedModel,RoFormerForMaskedLM:()=>r.RoFormerForMaskedLM,RoFormerForQuestionAnswering:()=>r.RoFormerForQuestionAnswering,RoFormerForSequenceClassification:()=>r.RoFormerForSequenceClassification,RoFormerForTokenClassification:()=>r.RoFormerForTokenClassification,RoFormerModel:()=>r.RoFormerModel,RoFormerPreTrainedModel:()=>r.RoFormerPreTrainedModel,RoFormerTokenizer:()=>o.RoFormerTokenizer,RobertaForMaskedLM:()=>r.RobertaForMaskedLM,RobertaForQuestionAnswering:()=>r.RobertaForQuestionAnswering,RobertaForSequenceClassification:()=>r.RobertaForSequenceClassification,RobertaForTokenClassification:()=>r.RobertaForTokenClassification,RobertaModel:()=>r.RobertaModel,RobertaPreTrainedModel:()=>r.RobertaPreTrainedModel,RobertaTokenizer:()=>o.RobertaTokenizer,Sam2ImageProcessor:()=>g.Sam2ImageProcessor,Sam2ImageSegmentationOutput:()=>r.Sam2ImageSegmentationOutput,Sam2Model:()=>r.Sam2Model,Sam2PreTrainedModel:()=>r.Sam2PreTrainedModel,Sam2Processor:()=>w.Sam2Processor,Sam2VideoProcessor:()=>w.Sam2VideoProcessor,Sam3ImageProcessor:()=>g.Sam3ImageProcessor,Sam3TrackerModel:()=>r.Sam3TrackerModel,SamImageProcessor:()=>g.SamImageProcessor,SamImageSegmentationOutput:()=>r.SamImageSegmentationOutput,SamModel:()=>r.SamModel,SamPreTrainedModel:()=>r.SamPreTrainedModel,SamProcessor:()=>w.SamProcessor,SapiensForDepthEstimation:()=>r.SapiensForDepthEstimation,SapiensForNormalEstimation:()=>r.SapiensForNormalEstimation,SapiensForSemanticSegmentation:()=>r.SapiensForSemanticSegmentation,SapiensPreTrainedModel:()=>r.SapiensPreTrainedModel,SeamlessM4TFeatureExtractor:()=>p.SeamlessM4TFeatureExtractor,SegformerFeatureExtractor:()=>g.SegformerFeatureExtractor,SegformerForImageClassification:()=>r.SegformerForImageClassification,SegformerForSemanticSegmentation:()=>r.SegformerForSemanticSegmentation,SegformerImageProcessor:()=>g.SegformerImageProcessor,SegformerModel:()=>r.SegformerModel,SegformerPreTrainedModel:()=>r.SegformerPreTrainedModel,Seq2SeqLMOutput:()=>r.Seq2SeqLMOutput,SequenceClassifierOutput:()=>r.SequenceClassifierOutput,SiglipImageProcessor:()=>g.SiglipImageProcessor,SiglipModel:()=>r.SiglipModel,SiglipPreTrainedModel:()=>r.SiglipPreTrainedModel,SiglipTextModel:()=>r.SiglipTextModel,SiglipTokenizer:()=>o.SiglipTokenizer,SiglipVisionModel:()=>r.SiglipVisionModel,SmolLM3ForCausalLM:()=>r.SmolLM3ForCausalLM,SmolLM3Model:()=>r.SmolLM3Model,SmolLM3PreTrainedModel:()=>r.SmolLM3PreTrainedModel,SmolVLMForConditionalGeneration:()=>r.SmolVLMForConditionalGeneration,SmolVLMImageProcessor:()=>g.SmolVLMImageProcessor,SmolVLMProcessor:()=>w.SmolVLMProcessor,SnacDecoderModel:()=>r.SnacDecoderModel,SnacEncoderModel:()=>r.SnacEncoderModel,SnacFeatureExtractor:()=>p.SnacFeatureExtractor,SnacModel:()=>r.SnacModel,SnacPreTrainedModel:()=>r.SnacPreTrainedModel,SpeechT5FeatureExtractor:()=>p.SpeechT5FeatureExtractor,SpeechT5ForSpeechToText:()=>r.SpeechT5ForSpeechToText,SpeechT5ForTextToSpeech:()=>r.SpeechT5ForTextToSpeech,SpeechT5HifiGan:()=>r.SpeechT5HifiGan,SpeechT5Model:()=>r.SpeechT5Model,SpeechT5PreTrainedModel:()=>r.SpeechT5PreTrainedModel,SpeechT5Processor:()=>w.SpeechT5Processor,SpeechT5Tokenizer:()=>o.SpeechT5Tokenizer,SqueezeBertForMaskedLM:()=>r.SqueezeBertForMaskedLM,SqueezeBertForQuestionAnswering:()=>r.SqueezeBertForQuestionAnswering,SqueezeBertForSequenceClassification:()=>r.SqueezeBertForSequenceClassification,SqueezeBertModel:()=>r.SqueezeBertModel,SqueezeBertPreTrainedModel:()=>r.SqueezeBertPreTrainedModel,SqueezeBertTokenizer:()=>o.SqueezeBertTokenizer,StableLmForCausalLM:()=>r.StableLmForCausalLM,StableLmModel:()=>r.StableLmModel,StableLmPreTrainedModel:()=>r.StableLmPreTrainedModel,Starcoder2ForCausalLM:()=>r.Starcoder2ForCausalLM,Starcoder2Model:()=>r.Starcoder2Model,Starcoder2PreTrainedModel:()=>r.Starcoder2PreTrainedModel,StoppingCriteria:()=>x.StoppingCriteria,StoppingCriteriaList:()=>x.StoppingCriteriaList,StyleTextToSpeech2Model:()=>r.StyleTextToSpeech2Model,StyleTextToSpeech2PreTrainedModel:()=>r.StyleTextToSpeech2PreTrainedModel,SummarizationPipeline:()=>t.SummarizationPipeline,SupertonicForConditionalGeneration:()=>r.SupertonicForConditionalGeneration,SupertonicPreTrainedModel:()=>r.SupertonicPreTrainedModel,SuppressTokensAtBeginLogitsProcessor:()=>b.SuppressTokensAtBeginLogitsProcessor,Swin2SRForImageSuperResolution:()=>r.Swin2SRForImageSuperResolution,Swin2SRImageProcessor:()=>g.Swin2SRImageProcessor,Swin2SRModel:()=>r.Swin2SRModel,Swin2SRPreTrainedModel:()=>r.Swin2SRPreTrainedModel,SwinForImageClassification:()=>r.SwinForImageClassification,SwinForSemanticSegmentation:()=>r.SwinForSemanticSegmentation,SwinModel:()=>r.SwinModel,SwinPreTrainedModel:()=>r.SwinPreTrainedModel,T5ForConditionalGeneration:()=>r.T5ForConditionalGeneration,T5Model:()=>r.T5Model,T5PreTrainedModel:()=>r.T5PreTrainedModel,T5Tokenizer:()=>o.T5Tokenizer,TableTransformerForObjectDetection:()=>r.TableTransformerForObjectDetection,TableTransformerModel:()=>r.TableTransformerModel,TableTransformerObjectDetectionOutput:()=>r.TableTransformerObjectDetectionOutput,TableTransformerPreTrainedModel:()=>r.TableTransformerPreTrainedModel,TemperatureLogitsWarper:()=>b.TemperatureLogitsWarper,Tensor:()=>l.Tensor,Text2TextGenerationPipeline:()=>t.Text2TextGenerationPipeline,TextClassificationPipeline:()=>t.TextClassificationPipeline,TextGenerationPipeline:()=>t.TextGenerationPipeline,TextStreamer:()=>P.TextStreamer,TextToAudioPipeline:()=>t.TextToAudioPipeline,TokenClassificationPipeline:()=>t.TokenClassificationPipeline,TokenClassifierOutput:()=>r.TokenClassifierOutput,TokenizerModel:()=>o.TokenizerModel,TopKLogitsWarper:()=>b.TopKLogitsWarper,TopPLogitsWarper:()=>b.TopPLogitsWarper,TrOCRForCausalLM:()=>r.TrOCRForCausalLM,TrOCRPreTrainedModel:()=>r.TrOCRPreTrainedModel,TranslationPipeline:()=>t.TranslationPipeline,UltravoxModel:()=>r.UltravoxModel,UltravoxPreTrainedModel:()=>r.UltravoxPreTrainedModel,UltravoxProcessor:()=>w.UltravoxProcessor,UniSpeechForCTC:()=>r.UniSpeechForCTC,UniSpeechForSequenceClassification:()=>r.UniSpeechForSequenceClassification,UniSpeechModel:()=>r.UniSpeechModel,UniSpeechPreTrainedModel:()=>r.UniSpeechPreTrainedModel,UniSpeechSatForAudioFrameClassification:()=>r.UniSpeechSatForAudioFrameClassification,UniSpeechSatForCTC:()=>r.UniSpeechSatForCTC,UniSpeechSatForSequenceClassification:()=>r.UniSpeechSatForSequenceClassification,UniSpeechSatModel:()=>r.UniSpeechSatModel,UniSpeechSatPreTrainedModel:()=>r.UniSpeechSatPreTrainedModel,VLChatProcessor:()=>w.VLChatProcessor,VLMImageProcessor:()=>g.VLMImageProcessor,VaultGemmaForCausalLM:()=>r.VaultGemmaForCausalLM,VaultGemmaModel:()=>r.VaultGemmaModel,VaultGemmaPreTrainedModel:()=>r.VaultGemmaPreTrainedModel,ViTFeatureExtractor:()=>g.ViTFeatureExtractor,ViTForImageClassification:()=>r.ViTForImageClassification,ViTImageProcessor:()=>g.ViTImageProcessor,ViTMAEModel:()=>r.ViTMAEModel,ViTMAEPreTrainedModel:()=>r.ViTMAEPreTrainedModel,ViTMSNForImageClassification:()=>r.ViTMSNForImageClassification,ViTMSNModel:()=>r.ViTMSNModel,ViTMSNPreTrainedModel:()=>r.ViTMSNPreTrainedModel,ViTModel:()=>r.ViTModel,ViTPreTrainedModel:()=>r.ViTPreTrainedModel,VisionEncoderDecoderModel:()=>r.VisionEncoderDecoderModel,VitMatteForImageMatting:()=>r.VitMatteForImageMatting,VitMatteImageProcessor:()=>g.VitMatteImageProcessor,VitMattePreTrainedModel:()=>r.VitMattePreTrainedModel,VitPoseForPoseEstimation:()=>r.VitPoseForPoseEstimation,VitPoseImageProcessor:()=>g.VitPoseImageProcessor,VitPosePreTrainedModel:()=>r.VitPosePreTrainedModel,VitsModel:()=>r.VitsModel,VitsModelOutput:()=>r.VitsModelOutput,VitsPreTrainedModel:()=>r.VitsPreTrainedModel,VitsTokenizer:()=>o.VitsTokenizer,VoxtralForConditionalGeneration:()=>r.VoxtralForConditionalGeneration,VoxtralProcessor:()=>w.VoxtralProcessor,Wav2Vec2BertForCTC:()=>r.Wav2Vec2BertForCTC,Wav2Vec2BertForSequenceClassification:()=>r.Wav2Vec2BertForSequenceClassification,Wav2Vec2BertModel:()=>r.Wav2Vec2BertModel,Wav2Vec2BertPreTrainedModel:()=>r.Wav2Vec2BertPreTrainedModel,Wav2Vec2CTCTokenizer:()=>o.Wav2Vec2CTCTokenizer,Wav2Vec2FeatureExtractor:()=>p.Wav2Vec2FeatureExtractor,Wav2Vec2ForAudioFrameClassification:()=>r.Wav2Vec2ForAudioFrameClassification,Wav2Vec2ForCTC:()=>r.Wav2Vec2ForCTC,Wav2Vec2ForSequenceClassification:()=>r.Wav2Vec2ForSequenceClassification,Wav2Vec2Model:()=>r.Wav2Vec2Model,Wav2Vec2PreTrainedModel:()=>r.Wav2Vec2PreTrainedModel,Wav2Vec2Processor:()=>w.Wav2Vec2Processor,Wav2Vec2ProcessorWithLM:()=>w.Wav2Vec2ProcessorWithLM,WavLMForAudioFrameClassification:()=>r.WavLMForAudioFrameClassification,WavLMForCTC:()=>r.WavLMForCTC,WavLMForSequenceClassification:()=>r.WavLMForSequenceClassification,WavLMForXVector:()=>r.WavLMForXVector,WavLMModel:()=>r.WavLMModel,WavLMPreTrainedModel:()=>r.WavLMPreTrainedModel,WeSpeakerFeatureExtractor:()=>p.WeSpeakerFeatureExtractor,WeSpeakerResNetModel:()=>r.WeSpeakerResNetModel,WeSpeakerResNetPreTrainedModel:()=>r.WeSpeakerResNetPreTrainedModel,WhisperFeatureExtractor:()=>p.WhisperFeatureExtractor,WhisperForConditionalGeneration:()=>r.WhisperForConditionalGeneration,WhisperModel:()=>r.WhisperModel,WhisperPreTrainedModel:()=>r.WhisperPreTrainedModel,WhisperProcessor:()=>w.WhisperProcessor,WhisperTextStreamer:()=>P.WhisperTextStreamer,WhisperTimeStampLogitsProcessor:()=>b.WhisperTimeStampLogitsProcessor,WhisperTokenizer:()=>o.WhisperTokenizer,XLMForQuestionAnswering:()=>r.XLMForQuestionAnswering,XLMForSequenceClassification:()=>r.XLMForSequenceClassification,XLMForTokenClassification:()=>r.XLMForTokenClassification,XLMModel:()=>r.XLMModel,XLMPreTrainedModel:()=>r.XLMPreTrainedModel,XLMRobertaForMaskedLM:()=>r.XLMRobertaForMaskedLM,XLMRobertaForQuestionAnswering:()=>r.XLMRobertaForQuestionAnswering,XLMRobertaForSequenceClassification:()=>r.XLMRobertaForSequenceClassification,XLMRobertaForTokenClassification:()=>r.XLMRobertaForTokenClassification,XLMRobertaModel:()=>r.XLMRobertaModel,XLMRobertaPreTrainedModel:()=>r.XLMRobertaPreTrainedModel,XLMRobertaTokenizer:()=>o.XLMRobertaTokenizer,XLMTokenizer:()=>o.XLMTokenizer,XLMWithLMHeadModel:()=>r.XLMWithLMHeadModel,XVectorOutput:()=>r.XVectorOutput,YolosFeatureExtractor:()=>g.YolosFeatureExtractor,YolosForObjectDetection:()=>r.YolosForObjectDetection,YolosImageProcessor:()=>g.YolosImageProcessor,YolosModel:()=>r.YolosModel,YolosObjectDetectionOutput:()=>r.YolosObjectDetectionOutput,YolosPreTrainedModel:()=>r.YolosPreTrainedModel,ZeroShotAudioClassificationPipeline:()=>t.ZeroShotAudioClassificationPipeline,ZeroShotClassificationPipeline:()=>t.ZeroShotClassificationPipeline,ZeroShotImageClassificationPipeline:()=>t.ZeroShotImageClassificationPipeline,ZeroShotObjectDetectionPipeline:()=>t.ZeroShotObjectDetectionPipeline,bankers_round:()=>u.bankers_round,cat:()=>l.cat,cos_sim:()=>u.cos_sim,dot:()=>u.dot,dynamic_time_warping:()=>u.dynamic_time_warping,env:()=>e.env,full:()=>l.full,full_like:()=>l.full_like,getCacheShapes:()=>s.getCacheShapes,hamming:()=>a.hamming,hanning:()=>a.hanning,interpolate:()=>l.interpolate,interpolate_4d:()=>l.interpolate_4d,interpolate_data:()=>u.interpolate_data,is_chinese_char:()=>o.is_chinese_char,layer_norm:()=>l.layer_norm,load_image:()=>i.load_image,load_video:()=>n.load_video,log_softmax:()=>u.log_softmax,magnitude:()=>u.magnitude,matmul:()=>l.matmul,max:()=>u.max,mean:()=>l.mean,mean_pooling:()=>l.mean_pooling,medianFilter:()=>u.medianFilter,mel_filter_bank:()=>a.mel_filter_bank,min:()=>u.min,ones:()=>l.ones,ones_like:()=>l.ones_like,permute:()=>l.permute,permute_data:()=>u.permute_data,pipeline:()=>t.pipeline,quantize_embeddings:()=>l.quantize_embeddings,rand:()=>l.rand,randn:()=>l.randn,read_audio:()=>a.read_audio,rfft:()=>l.rfft,round:()=>u.round,slice:()=>l.slice,softmax:()=>u.softmax,spectrogram:()=>a.spectrogram,stack:()=>l.stack,std_mean:()=>l.std_mean,topk:()=>l.topk,window_function:()=>a.window_function,zeros:()=>l.zeros,zeros_like:()=>l.zeros_like});var e=c("./src/env.js"),t=c("./src/pipelines.js"),r=c("./src/models.js"),o=c("./src/tokenizers.js"),s=c("./src/configs.js"),a=c("./src/utils/audio.js"),i=c("./src/utils/image.js"),n=c("./src/utils/video.js"),l=c("./src/utils/tensor.js"),u=c("./src/utils/maths.js"),m=c("./src/base/feature_extraction_utils.js"),p=c("./src/models/feature_extractors.js"),_=c("./src/models/auto/feature_extraction_auto.js"),h=c("./src/base/image_processors_utils.js"),g=c("./src/models/image_processors.js"),f=c("./src/models/auto/image_processing_auto.js"),M=c("./src/base/processing_utils.js"),w=c("./src/models/processors.js"),T=c("./src/models/auto/processing_auto.js"),P=c("./src/generation/streamers.js"),x=c("./src/generation/stopping_criteria.js"),b=c("./src/generation/logits_process.js")})();var u=d.ASTFeatureExtractor,m=d.ASTForAudioClassification,p=d.ASTModel,_=d.ASTPreTrainedModel,h=d.AlbertForMaskedLM,g=d.AlbertForQuestionAnswering,f=d.AlbertForSequenceClassification,M=d.AlbertModel,w=d.AlbertPreTrainedModel,T=d.AlbertTokenizer,P=d.ArceeForCausalLM,x=d.ArceeModel,b=d.ArceePreTrainedModel,F=d.AudioClassificationPipeline,k=d.AutoConfig,y=d.AutoFeatureExtractor,v=d.AutoImageProcessor,C=d.AutoModel,S=d.AutoModelForAudioClassification,E=d.AutoModelForAudioFrameClassification,A=d.AutoModelForAudioTextToText,L=d.AutoModelForCTC,I=d.AutoModelForCausalLM,D=d.AutoModelForDepthEstimation,z=d.AutoModelForDocumentQuestionAnswering,j=d.AutoModelForImageClassification,V=d.AutoModelForImageFeatureExtraction,O=d.AutoModelForImageMatting,N=d.AutoModelForImageSegmentation,B=d.AutoModelForImageTextToText,G=d.AutoModelForImageToImage,R=d.AutoModelForMaskGeneration,q=d.AutoModelForMaskedLM,$=d.AutoModelForNormalEstimation,W=d.AutoModelForObjectDetection,U=d.AutoModelForPoseEstimation,Q=d.AutoModelForQuestionAnswering,X=d.AutoModelForSemanticSegmentation,H=d.AutoModelForSeq2SeqLM,J=d.AutoModelForSequenceClassification,Y=d.AutoModelForSpeechSeq2Seq,K=d.AutoModelForTextToSpectrogram,Z=d.AutoModelForTextToWaveform,ee=d.AutoModelForTokenClassification,et=d.AutoModelForUniversalSegmentation,er=d.AutoModelForVision2Seq,eo=d.AutoModelForXVector,es=d.AutoModelForZeroShotObjectDetection,ea=d.AutoProcessor,ei=d.AutoTokenizer,en=d.AutomaticSpeechRecognitionPipeline,el=d.BackgroundRemovalPipeline,ec=d.BartForConditionalGeneration,ed=d.BartForSequenceClassification,eu=d.BartModel,em=d.BartPretrainedModel,ep=d.BartTokenizer,e_=d.BaseModelOutput,eh=d.BaseStreamer,eg=d.BeitFeatureExtractor,ef=d.BeitForImageClassification,eM=d.BeitModel,ew=d.BeitPreTrainedModel,eT=d.BertForMaskedLM,eP=d.BertForQuestionAnswering,ex=d.BertForSequenceClassification,eb=d.BertForTokenClassification,eF=d.BertModel,ek=d.BertPreTrainedModel,ey=d.BertTokenizer,ev=d.BitImageProcessor,eC=d.BlenderbotForConditionalGeneration,eS=d.BlenderbotModel,eE=d.BlenderbotPreTrainedModel,eA=d.BlenderbotSmallForConditionalGeneration,eL=d.BlenderbotSmallModel,eI=d.BlenderbotSmallPreTrainedModel,eD=d.BlenderbotSmallTokenizer,ez=d.BlenderbotTokenizer,ej=d.BloomForCausalLM,eV=d.BloomModel,eO=d.BloomPreTrainedModel,eN=d.BloomTokenizer,eB=d.CLIPFeatureExtractor,eG=d.CLIPImageProcessor,eR=d.CLIPModel,eq=d.CLIPPreTrainedModel,e$=d.CLIPSegForImageSegmentation,eW=d.CLIPSegModel,eU=d.CLIPSegPreTrainedModel,eQ=d.CLIPTextModel,eX=d.CLIPTextModelWithProjection,eH=d.CLIPTokenizer,eJ=d.CLIPVisionModel,eY=d.CLIPVisionModelWithProjection,eK=d.CamembertForMaskedLM,eZ=d.CamembertForQuestionAnswering,e0=d.CamembertForSequenceClassification,e1=d.CamembertForTokenClassification,e2=d.CamembertModel,e3=d.CamembertPreTrainedModel,e4=d.CamembertTokenizer,e5=d.CausalLMOutput,e8=d.CausalLMOutputWithPast,e6=d.ChineseCLIPFeatureExtractor,e9=d.ChineseCLIPModel,e7=d.ChineseCLIPPreTrainedModel,te=d.ClapAudioModelWithProjection,tt=d.ClapFeatureExtractor,tr=d.ClapModel,to=d.ClapPreTrainedModel,ts=d.ClapTextModelWithProjection,ta=d.ClassifierFreeGuidanceLogitsProcessor,ti=d.CodeGenForCausalLM,tn=d.CodeGenModel,tl=d.CodeGenPreTrainedModel,tc=d.CodeGenTokenizer,td=d.CodeLlamaTokenizer,tu=d.CohereForCausalLM,tm=d.CohereModel,tp=d.CoherePreTrainedModel,t_=d.CohereTokenizer,th=d.ConvBertForMaskedLM,tg=d.ConvBertForQuestionAnswering,tf=d.ConvBertForSequenceClassification,tM=d.ConvBertForTokenClassification,tw=d.ConvBertModel,tT=d.ConvBertPreTrainedModel,tP=d.ConvBertTokenizer,tx=d.ConvNextFeatureExtractor,tb=d.ConvNextForImageClassification,tF=d.ConvNextImageProcessor,tk=d.ConvNextModel,ty=d.ConvNextPreTrainedModel,tv=d.ConvNextV2ForImageClassification,tC=d.ConvNextV2Model,tS=d.ConvNextV2PreTrainedModel,tE=d.DFineForObjectDetection,tA=d.DFineModel,tL=d.DFinePreTrainedModel,tI=d.DINOv3ConvNextModel,tD=d.DINOv3ConvNextPreTrainedModel,tz=d.DINOv3ViTImageProcessor,tj=d.DINOv3ViTModel,tV=d.DINOv3ViTPreTrainedModel,tO=d.DPTFeatureExtractor,tN=d.DPTForDepthEstimation,tB=d.DPTImageProcessor,tG=d.DPTModel,tR=d.DPTPreTrainedModel,tq=d.DacDecoderModel,t$=d.DacDecoderOutput,tW=d.DacEncoderModel,tU=d.DacEncoderOutput,tQ=d.DacFeatureExtractor,tX=d.DacModel,tH=d.DacPreTrainedModel,tJ=d.DataTypeMap,tY=d.DebertaForMaskedLM,tK=d.DebertaForQuestionAnswering,tZ=d.DebertaForSequenceClassification,t0=d.DebertaForTokenClassification,t1=d.DebertaModel,t2=d.DebertaPreTrainedModel,t3=d.DebertaTokenizer,t4=d.DebertaV2ForMaskedLM,t5=d.DebertaV2ForQuestionAnswering,t8=d.DebertaV2ForSequenceClassification,t6=d.DebertaV2ForTokenClassification,t9=d.DebertaV2Model,t7=d.DebertaV2PreTrainedModel,re=d.DebertaV2Tokenizer,rt=d.DecisionTransformerModel,rr=d.DecisionTransformerPreTrainedModel,ro=d.DeiTFeatureExtractor,rs=d.DeiTForImageClassification,ra=d.DeiTImageProcessor,ri=d.DeiTModel,rn=d.DeiTPreTrainedModel,rl=d.DepthAnythingForDepthEstimation,rc=d.DepthAnythingPreTrainedModel,rd=d.DepthEstimationPipeline,ru=d.DepthProForDepthEstimation,rm=d.DepthProPreTrainedModel,rp=d.DetrFeatureExtractor,r_=d.DetrForObjectDetection,rh=d.DetrForSegmentation,rg=d.DetrImageProcessor,rf=d.DetrModel,rM=d.DetrObjectDetectionOutput,rw=d.DetrPreTrainedModel,rT=d.DetrSegmentationOutput,rP=d.Dinov2ForImageClassification,rx=d.Dinov2Model,rb=d.Dinov2PreTrainedModel,rF=d.Dinov2WithRegistersForImageClassification,rk=d.Dinov2WithRegistersModel,ry=d.Dinov2WithRegistersPreTrainedModel,rv=d.DistilBertForMaskedLM,rC=d.DistilBertForQuestionAnswering,rS=d.DistilBertForSequenceClassification,rE=d.DistilBertForTokenClassification,rA=d.DistilBertModel,rL=d.DistilBertPreTrainedModel,rI=d.DistilBertTokenizer,rD=d.DocumentQuestionAnsweringPipeline,rz=d.DonutFeatureExtractor,rj=d.DonutImageProcessor,rV=d.DonutSwinModel,rO=d.DonutSwinPreTrainedModel,rN=d.EdgeTamModel,rB=d.EfficientNetForImageClassification,rG=d.EfficientNetImageProcessor,rR=d.EfficientNetModel,rq=d.EfficientNetPreTrainedModel,r$=d.ElectraForMaskedLM,rW=d.ElectraForQuestionAnswering,rU=d.ElectraForSequenceClassification,rQ=d.ElectraForTokenClassification,rX=d.ElectraModel,rH=d.ElectraPreTrainedModel,rJ=d.ElectraTokenizer,rY=d.EncodecFeatureExtractor,rK=d.EosTokenCriteria,rZ=d.Ernie4_5ForCausalLM,r0=d.Ernie4_5Model,r1=d.Ernie4_5PreTrainedModel,r2=d.EsmForMaskedLM,r3=d.EsmForSequenceClassification,r4=d.EsmForTokenClassification,r5=d.EsmModel,r8=d.EsmPreTrainedModel,r6=d.EsmTokenizer,r9=d.ExaoneForCausalLM,r7=d.ExaoneModel,oe=d.ExaonePreTrainedModel,ot=d.FFT,or=d.FalconForCausalLM,oo=d.FalconModel,os=d.FalconPreTrainedModel,oa=d.FalconTokenizer,oi=d.FastViTForImageClassification,on=d.FastViTModel,ol=d.FastViTPreTrainedModel,oc=d.FeatureExtractionPipeline,od=d.FeatureExtractor,ou=d.FillMaskPipeline,om=d.Florence2ForConditionalGeneration,op=d.Florence2PreTrainedModel,o_=d.Florence2Processor,oh=d.ForcedBOSTokenLogitsProcessor,og=d.ForcedEOSTokenLogitsProcessor,of=d.GLPNFeatureExtractor,oM=d.GLPNForDepthEstimation,ow=d.GLPNModel,oT=d.GLPNPreTrainedModel,oP=d.GPT2LMHeadModel,ox=d.GPT2Model,ob=d.GPT2PreTrainedModel,oF=d.GPT2Tokenizer,ok=d.GPTBigCodeForCausalLM,oy=d.GPTBigCodeModel,ov=d.GPTBigCodePreTrainedModel,oC=d.GPTJForCausalLM,oS=d.GPTJModel,oE=d.GPTJPreTrainedModel,oA=d.GPTNeoForCausalLM,oL=d.GPTNeoModel,oI=d.GPTNeoPreTrainedModel,oD=d.GPTNeoXForCausalLM,oz=d.GPTNeoXModel,oj=d.GPTNeoXPreTrainedModel,oV=d.GPTNeoXTokenizer,oO=d.Gemma2ForCausalLM,oN=d.Gemma2Model,oB=d.Gemma2PreTrainedModel,oG=d.Gemma3ForCausalLM,oR=d.Gemma3Model,oq=d.Gemma3PreTrainedModel,o$=d.Gemma3nAudioFeatureExtractor,oW=d.Gemma3nForConditionalGeneration,oU=d.Gemma3nPreTrainedModel,oQ=d.Gemma3nProcessor,oX=d.GemmaForCausalLM,oH=d.GemmaModel,oJ=d.GemmaPreTrainedModel,oY=d.GemmaTokenizer,oK=d.GlmForCausalLM,oZ=d.GlmModel,o0=d.GlmPreTrainedModel,o1=d.GraniteForCausalLM,o2=d.GraniteModel,o3=d.GraniteMoeHybridForCausalLM,o4=d.GraniteMoeHybridModel,o5=d.GraniteMoeHybridPreTrainedModel,o8=d.GranitePreTrainedModel,o6=d.Grok1Tokenizer,o9=d.GroundingDinoForObjectDetection,o7=d.GroundingDinoImageProcessor,se=d.GroundingDinoPreTrainedModel,st=d.GroundingDinoProcessor,sr=d.GroupViTModel,so=d.GroupViTPreTrainedModel,ss=d.HeliumForCausalLM,sa=d.HeliumModel,si=d.HeliumPreTrainedModel,sn=d.HerbertTokenizer,sl=d.HieraForImageClassification,sc=d.HieraModel,sd=d.HieraPreTrainedModel,su=d.HubertForCTC,sm=d.HubertForSequenceClassification,sp=d.HubertModel,s_=d.HubertPreTrainedModel,sh=d.IJepaForImageClassification,sg=d.IJepaModel,sf=d.IJepaPreTrainedModel,sM=d.Idefics3ForConditionalGeneration,sw=d.Idefics3ImageProcessor,sT=d.Idefics3PreTrainedModel,sP=d.Idefics3Processor,sx=d.ImageClassificationPipeline,sb=d.ImageFeatureExtractionPipeline,sF=d.ImageFeatureExtractor,sk=d.ImageMattingOutput,sy=d.ImageProcessor,sv=d.ImageSegmentationPipeline,sC=d.ImageToImagePipeline,sS=d.ImageToTextPipeline,sE=d.InterruptableStoppingCriteria,sA=d.JAISLMHeadModel,sL=d.JAISModel,sI=d.JAISPreTrainedModel,sD=d.JinaCLIPImageProcessor,sz=d.JinaCLIPModel,sj=d.JinaCLIPPreTrainedModel,sV=d.JinaCLIPProcessor,sO=d.JinaCLIPTextModel,sN=d.JinaCLIPVisionModel,sB=d.Lfm2ForCausalLM,sG=d.Lfm2Model,sR=d.Lfm2PreTrainedModel,sq=d.LiteWhisperForConditionalGeneration,s$=d.Llama4ForCausalLM,sW=d.Llama4PreTrainedModel,sU=d.LlamaForCausalLM,sQ=d.LlamaModel,sX=d.LlamaPreTrainedModel,sH=d.LlamaTokenizer,sJ=d.LlavaForConditionalGeneration,sY=d.LlavaOnevisionForConditionalGeneration,sK=d.LlavaOnevisionImageProcessor,sZ=d.LlavaPreTrainedModel,s0=d.LlavaProcessor,s1=d.LlavaQwen2ForCausalLM,s2=d.LogitsProcessor,s3=d.LogitsProcessorList,s4=d.LogitsWarper,s5=d.LongT5ForConditionalGeneration,s8=d.LongT5Model,s6=d.LongT5PreTrainedModel,s9=d.M2M100ForConditionalGeneration,s7=d.M2M100Model,ae=d.M2M100PreTrainedModel,at=d.M2M100Tokenizer,ar=d.MBart50Tokenizer,ao=d.MBartForCausalLM,as=d.MBartForConditionalGeneration,aa=d.MBartForSequenceClassification,ai=d.MBartModel,an=d.MBartPreTrainedModel,al=d.MBartTokenizer,ac=d.MPNetForMaskedLM,ad=d.MPNetForQuestionAnswering,au=d.MPNetForSequenceClassification,am=d.MPNetForTokenClassification,ap=d.MPNetModel,a_=d.MPNetPreTrainedModel,ah=d.MPNetTokenizer,ag=d.MT5ForConditionalGeneration,af=d.MT5Model,aM=d.MT5PreTrainedModel,aw=d.MarianMTModel,aT=d.MarianModel,aP=d.MarianPreTrainedModel,ax=d.MarianTokenizer,ab=d.Mask2FormerImageProcessor,aF=d.MaskFormerFeatureExtractor,ak=d.MaskFormerForInstanceSegmentation,ay=d.MaskFormerImageProcessor,av=d.MaskFormerModel,aC=d.MaskFormerPreTrainedModel,aS=d.MaskedLMOutput,aE=d.MaxLengthCriteria,aA=d.Metric3DForDepthEstimation,aL=d.Metric3DPreTrainedModel,aI=d.Metric3Dv2ForDepthEstimation,aD=d.Metric3Dv2PreTrainedModel,az=d.MgpstrForSceneTextRecognition,aj=d.MgpstrModelOutput,aV=d.MgpstrPreTrainedModel,aO=d.MgpstrProcessor,aN=d.MgpstrTokenizer,aB=d.MimiDecoderModel,aG=d.MimiDecoderOutput,aR=d.MimiEncoderModel,aq=d.MimiEncoderOutput,a$=d.MimiModel,aW=d.MimiPreTrainedModel,aU=d.MinLengthLogitsProcessor,aQ=d.MinNewTokensLengthLogitsProcessor,aX=d.Ministral3ForCausalLM,aH=d.Ministral3Model,aJ=d.Ministral3PreTrainedModel,aY=d.MinistralForCausalLM,aK=d.MinistralModel,aZ=d.MinistralPreTrainedModel,a0=d.Mistral3ForConditionalGeneration,a1=d.MistralForCausalLM,a2=d.MistralModel,a3=d.MistralPreTrainedModel,a4=d.MobileBertForMaskedLM,a5=d.MobileBertForQuestionAnswering,a8=d.MobileBertForSequenceClassification,a6=d.MobileBertModel,a9=d.MobileBertPreTrainedModel,a7=d.MobileBertTokenizer,ie=d.MobileLLMForCausalLM,it=d.MobileLLMModel,ir=d.MobileLLMPreTrainedModel,io=d.MobileNetV1FeatureExtractor,is=d.MobileNetV1ForImageClassification,ia=d.MobileNetV1ForSemanticSegmentation,ii=d.MobileNetV1ImageProcessor,il=d.MobileNetV1Model,ic=d.MobileNetV1PreTrainedModel,id=d.MobileNetV2FeatureExtractor,iu=d.MobileNetV2ForImageClassification,im=d.MobileNetV2ForSemanticSegmentation,ip=d.MobileNetV2ImageProcessor,i_=d.MobileNetV2Model,ih=d.MobileNetV2PreTrainedModel,ig=d.MobileNetV3FeatureExtractor,iM=d.MobileNetV3ForImageClassification,iw=d.MobileNetV3ForSemanticSegmentation,iT=d.MobileNetV3ImageProcessor,iP=d.MobileNetV3Model,ix=d.MobileNetV3PreTrainedModel,ib=d.MobileNetV4FeatureExtractor,iF=d.MobileNetV4ForImageClassification,ik=d.MobileNetV4ForSemanticSegmentation,iy=d.MobileNetV4ImageProcessor,iv=d.MobileNetV4Model,iC=d.MobileNetV4PreTrainedModel,iS=d.MobileViTFeatureExtractor,iE=d.MobileViTForImageClassification,iA=d.MobileViTImageProcessor,iL=d.MobileViTModel,iI=d.MobileViTPreTrainedModel,iD=d.MobileViTV2ForImageClassification,iz=d.MobileViTV2Model,ij=d.MobileViTV2PreTrainedModel,iV=d.ModelOutput,iO=d.ModernBertDecoderForCausalLM,iN=d.ModernBertDecoderModel,iB=d.ModernBertDecoderPreTrainedModel,iG=d.ModernBertForMaskedLM,iR=d.ModernBertForSequenceClassification,iq=d.ModernBertForTokenClassification,i$=d.ModernBertModel,iW=d.ModernBertPreTrainedModel,iU=d.Moondream1ForConditionalGeneration,iQ=d.MoonshineFeatureExtractor,iX=d.MoonshineForConditionalGeneration,iH=d.MoonshineModel,iJ=d.MoonshinePreTrainedModel,iY=d.MoonshineProcessor,iK=d.MptForCausalLM,iZ=d.MptModel,i0=d.MptPreTrainedModel,i1=d.MultiModalityCausalLM,i2=d.MultiModalityPreTrainedModel,i3=d.MusicgenForCausalLM,i4=d.MusicgenForConditionalGeneration,i5=d.MusicgenModel,i8=d.MusicgenPreTrainedModel,i6=d.NanoChatForCausalLM,i9=d.NanoChatModel,i7=d.NanoChatPreTrainedModel,ne=d.NeoBertForMaskedLM,nt=d.NeoBertForQuestionAnswering,nr=d.NeoBertForSequenceClassification,no=d.NeoBertForTokenClassification,ns=d.NeoBertModel,na=d.NeoBertPreTrainedModel,ni=d.NllbTokenizer,nn=d.NoBadWordsLogitsProcessor,nl=d.NoRepeatNGramLogitsProcessor,nc=d.NomicBertModel,nd=d.NomicBertPreTrainedModel,nu=d.NougatImageProcessor,nm=d.NougatTokenizer,np=d.OPTForCausalLM,n_=d.OPTModel,nh=d.OPTPreTrainedModel,ng=d.ObjectDetectionPipeline,nf=d.Olmo2ForCausalLM,nM=d.Olmo2Model,nw=d.Olmo2PreTrainedModel,nT=d.OlmoForCausalLM,nP=d.OlmoModel,nx=d.OlmoPreTrainedModel,nb=d.OpenELMForCausalLM,nF=d.OpenELMModel,nk=d.OpenELMPreTrainedModel,ny=d.OwlViTFeatureExtractor,nv=d.OwlViTForObjectDetection,nC=d.OwlViTImageProcessor,nS=d.OwlViTModel,nE=d.OwlViTPreTrainedModel,nA=d.OwlViTProcessor,nL=d.Owlv2ForObjectDetection,nI=d.Owlv2ImageProcessor,nD=d.Owlv2Model,nz=d.Owlv2PreTrainedModel,nj=d.PaliGemmaForConditionalGeneration,nV=d.PaliGemmaPreTrainedModel,nO=d.PaliGemmaProcessor,nN=d.ParakeetFeatureExtractor,nB=d.ParakeetForCTC,nG=d.ParakeetPreTrainedModel,nR=d.PatchTSMixerForPrediction,nq=d.PatchTSMixerModel,n$=d.PatchTSMixerPreTrainedModel,nW=d.PatchTSTForPrediction,nU=d.PatchTSTModel,nQ=d.PatchTSTPreTrainedModel,nX=d.Phi3ForCausalLM,nH=d.Phi3Model,nJ=d.Phi3PreTrainedModel,nY=d.Phi3VForCausalLM,nK=d.Phi3VImageProcessor,nZ=d.Phi3VPreTrainedModel,n0=d.Phi3VProcessor,n1=d.PhiForCausalLM,n2=d.PhiModel,n3=d.PhiPreTrainedModel,n4=d.Pipeline,n5=d.PixtralImageProcessor,n8=d.PixtralProcessor,n6=d.PreTrainedModel,n9=d.PreTrainedTokenizer,n7=d.PretrainedConfig,le=d.PretrainedMixin,lt=d.Processor,lr=d.PvtForImageClassification,lo=d.PvtImageProcessor,ls=d.PvtModel,la=d.PvtPreTrainedModel,li=d.PyAnnoteFeatureExtractor,ln=d.PyAnnoteForAudioFrameClassification,ll=d.PyAnnoteModel,lc=d.PyAnnotePreTrainedModel,ld=d.PyAnnoteProcessor,lu=d.QuestionAnsweringModelOutput,lm=d.QuestionAnsweringPipeline,lp=d.Qwen2ForCausalLM,l_=d.Qwen2Model,lh=d.Qwen2PreTrainedModel,lg=d.Qwen2Tokenizer,lf=d.Qwen2VLForConditionalGeneration,lM=d.Qwen2VLImageProcessor,lw=d.Qwen2VLPreTrainedModel,lT=d.Qwen2VLProcessor,lP=d.Qwen3ForCausalLM,lx=d.Qwen3Model,lb=d.Qwen3PreTrainedModel,lF=d.RFDetrForObjectDetection,lk=d.RFDetrModel,ly=d.RFDetrObjectDetectionOutput,lv=d.RFDetrPreTrainedModel,lC=d.RTDetrForObjectDetection,lS=d.RTDetrImageProcessor,lE=d.RTDetrModel,lA=d.RTDetrObjectDetectionOutput,lL=d.RTDetrPreTrainedModel,lI=d.RTDetrV2ForObjectDetection,lD=d.RTDetrV2Model,lz=d.RTDetrV2ObjectDetectionOutput,lj=d.RTDetrV2PreTrainedModel,lV=d.RawAudio,lO=d.RawImage,lN=d.RawVideo,lB=d.RawVideoFrame,lG=d.RepetitionPenaltyLogitsProcessor,lR=d.ResNetForImageClassification,lq=d.ResNetModel,l$=d.ResNetPreTrainedModel,lW=d.RoFormerForMaskedLM,lU=d.RoFormerForQuestionAnswering,lQ=d.RoFormerForSequenceClassification,lX=d.RoFormerForTokenClassification,lH=d.RoFormerModel,lJ=d.RoFormerPreTrainedModel,lY=d.RoFormerTokenizer,lK=d.RobertaForMaskedLM,lZ=d.RobertaForQuestionAnswering,l0=d.RobertaForSequenceClassification,l1=d.RobertaForTokenClassification,l2=d.RobertaModel,l3=d.RobertaPreTrainedModel,l4=d.RobertaTokenizer,l5=d.Sam2ImageProcessor,l8=d.Sam2ImageSegmentationOutput,l6=d.Sam2Model,l9=d.Sam2PreTrainedModel,l7=d.Sam2Processor,ce=d.Sam2VideoProcessor,ct=d.Sam3ImageProcessor,cr=d.Sam3TrackerModel,co=d.SamImageProcessor,cs=d.SamImageSegmentationOutput,ca=d.SamModel,ci=d.SamPreTrainedModel,cn=d.SamProcessor,cl=d.SapiensForDepthEstimation,cc=d.SapiensForNormalEstimation,cd=d.SapiensForSemanticSegmentation,cu=d.SapiensPreTrainedModel,cm=d.SeamlessM4TFeatureExtractor,cp=d.SegformerFeatureExtractor,c_=d.SegformerForImageClassification,ch=d.SegformerForSemanticSegmentation,cg=d.SegformerImageProcessor,cf=d.SegformerModel,cM=d.SegformerPreTrainedModel,cw=d.Seq2SeqLMOutput,cT=d.SequenceClassifierOutput,cP=d.SiglipImageProcessor,cx=d.SiglipModel,cb=d.SiglipPreTrainedModel,cF=d.SiglipTextModel,ck=d.SiglipTokenizer,cy=d.SiglipVisionModel,cv=d.SmolLM3ForCausalLM,cC=d.SmolLM3Model,cS=d.SmolLM3PreTrainedModel,cE=d.SmolVLMForConditionalGeneration,cA=d.SmolVLMImageProcessor,cL=d.SmolVLMProcessor,cI=d.SnacDecoderModel,cD=d.SnacEncoderModel,cz=d.SnacFeatureExtractor,cj=d.SnacModel,cV=d.SnacPreTrainedModel,cO=d.SpeechT5FeatureExtractor,cN=d.SpeechT5ForSpeechToText,cB=d.SpeechT5ForTextToSpeech,cG=d.SpeechT5HifiGan,cR=d.SpeechT5Model,cq=d.SpeechT5PreTrainedModel,c$=d.SpeechT5Processor,cW=d.SpeechT5Tokenizer,cU=d.SqueezeBertForMaskedLM,cQ=d.SqueezeBertForQuestionAnswering,cX=d.SqueezeBertForSequenceClassification,cH=d.SqueezeBertModel,cJ=d.SqueezeBertPreTrainedModel,cY=d.SqueezeBertTokenizer,cK=d.StableLmForCausalLM,cZ=d.StableLmModel,c0=d.StableLmPreTrainedModel,c1=d.Starcoder2ForCausalLM,c2=d.Starcoder2Model,c3=d.Starcoder2PreTrainedModel,c4=d.StoppingCriteria,c5=d.StoppingCriteriaList,c8=d.StyleTextToSpeech2Model,c6=d.StyleTextToSpeech2PreTrainedModel,c9=d.SummarizationPipeline,c7=d.SupertonicForConditionalGeneration,de=d.SupertonicPreTrainedModel,dt=d.SuppressTokensAtBeginLogitsProcessor,dr=d.Swin2SRForImageSuperResolution,ds=d.Swin2SRImageProcessor,da=d.Swin2SRModel,di=d.Swin2SRPreTrainedModel,dn=d.SwinForImageClassification,dl=d.SwinForSemanticSegmentation,dc=d.SwinModel,dd=d.SwinPreTrainedModel,du=d.T5ForConditionalGeneration,dm=d.T5Model,dp=d.T5PreTrainedModel,d_=d.T5Tokenizer,dh=d.TableTransformerForObjectDetection,dg=d.TableTransformerModel,df=d.TableTransformerObjectDetectionOutput,dM=d.TableTransformerPreTrainedModel,dw=d.TemperatureLogitsWarper,dT=d.Tensor,dP=d.Text2TextGenerationPipeline,dx=d.TextClassificationPipeline,db=d.TextGenerationPipeline,dF=d.TextStreamer,dk=d.TextToAudioPipeline,dy=d.TokenClassificationPipeline,dv=d.TokenClassifierOutput,dC=d.TokenizerModel,dS=d.TopKLogitsWarper,dE=d.TopPLogitsWarper,dA=d.TrOCRForCausalLM,dL=d.TrOCRPreTrainedModel,dI=d.TranslationPipeline,dD=d.UltravoxModel,dz=d.UltravoxPreTrainedModel,dj=d.UltravoxProcessor,dV=d.UniSpeechForCTC,dO=d.UniSpeechForSequenceClassification,dN=d.UniSpeechModel,dB=d.UniSpeechPreTrainedModel,dG=d.UniSpeechSatForAudioFrameClassification,dR=d.UniSpeechSatForCTC,dq=d.UniSpeechSatForSequenceClassification,d$=d.UniSpeechSatModel,dW=d.UniSpeechSatPreTrainedModel,dU=d.VLChatProcessor,dQ=d.VLMImageProcessor,dX=d.VaultGemmaForCausalLM,dH=d.VaultGemmaModel,dJ=d.VaultGemmaPreTrainedModel,dY=d.ViTFeatureExtractor,dK=d.ViTForImageClassification,dZ=d.ViTImageProcessor,d0=d.ViTMAEModel,d1=d.ViTMAEPreTrainedModel,d2=d.ViTMSNForImageClassification,d3=d.ViTMSNModel,d4=d.ViTMSNPreTrainedModel,d5=d.ViTModel,d8=d.ViTPreTrainedModel,d6=d.VisionEncoderDecoderModel,d9=d.VitMatteForImageMatting,d7=d.VitMatteImageProcessor,ue=d.VitMattePreTrainedModel,ut=d.VitPoseForPoseEstimation,ur=d.VitPoseImageProcessor,uo=d.VitPosePreTrainedModel,us=d.VitsModel,ua=d.VitsModelOutput,ui=d.VitsPreTrainedModel,un=d.VitsTokenizer,ul=d.VoxtralForConditionalGeneration,uc=d.VoxtralProcessor,ud=d.Wav2Vec2BertForCTC,uu=d.Wav2Vec2BertForSequenceClassification,um=d.Wav2Vec2BertModel,up=d.Wav2Vec2BertPreTrainedModel,u_=d.Wav2Vec2CTCTokenizer,uh=d.Wav2Vec2FeatureExtractor,ug=d.Wav2Vec2ForAudioFrameClassification,uf=d.Wav2Vec2ForCTC,uM=d.Wav2Vec2ForSequenceClassification,uw=d.Wav2Vec2Model,uT=d.Wav2Vec2PreTrainedModel,uP=d.Wav2Vec2Processor,ux=d.Wav2Vec2ProcessorWithLM,ub=d.WavLMForAudioFrameClassification,uF=d.WavLMForCTC,uk=d.WavLMForSequenceClassification,uy=d.WavLMForXVector,uv=d.WavLMModel,uC=d.WavLMPreTrainedModel,uS=d.WeSpeakerFeatureExtractor,uE=d.WeSpeakerResNetModel,uA=d.WeSpeakerResNetPreTrainedModel,uL=d.WhisperFeatureExtractor,uI=d.WhisperForConditionalGeneration,uD=d.WhisperModel,uz=d.WhisperPreTrainedModel,uj=d.WhisperProcessor,uV=d.WhisperTextStreamer,uO=d.WhisperTimeStampLogitsProcessor,uN=d.WhisperTokenizer,uB=d.XLMForQuestionAnswering,uG=d.XLMForSequenceClassification,uR=d.XLMForTokenClassification,uq=d.XLMModel,u$=d.XLMPreTrainedModel,uW=d.XLMRobertaForMaskedLM,uU=d.XLMRobertaForQuestionAnswering,uQ=d.XLMRobertaForSequenceClassification,uX=d.XLMRobertaForTokenClassification,uH=d.XLMRobertaModel,uJ=d.XLMRobertaPreTrainedModel,uY=d.XLMRobertaTokenizer,uK=d.XLMTokenizer,uZ=d.XLMWithLMHeadModel,u0=d.XVectorOutput,u1=d.YolosFeatureExtractor,u2=d.YolosForObjectDetection,u3=d.YolosImageProcessor,u4=d.YolosModel,u5=d.YolosObjectDetectionOutput,u8=d.YolosPreTrainedModel,u6=d.ZeroShotAudioClassificationPipeline,u9=d.ZeroShotClassificationPipeline,u7=d.ZeroShotImageClassificationPipeline,me=d.ZeroShotObjectDetectionPipeline,mt=d.bankers_round,mr=d.cat,mo=d.cos_sim,ms=d.dot,ma=d.dynamic_time_warping,mi=d.env,mn=d.full,ml=d.full_like,mc=d.getCacheShapes,md=d.hamming,mu=d.hanning,mm=d.interpolate,mp=d.interpolate_4d,m_=d.interpolate_data,mh=d.is_chinese_char,mg=d.layer_norm,mf=d.load_image,mM=d.load_video,mw=d.log_softmax,mT=d.magnitude,mP=d.matmul,mx=d.max,mb=d.mean,mF=d.mean_pooling,mk=d.medianFilter,my=d.mel_filter_bank,mv=d.min,mC=d.ones,mS=d.ones_like,mE=d.permute,mA=d.permute_data,mL=d.pipeline,mI=d.quantize_embeddings,mD=d.rand,mz=d.randn,mj=d.read_audio,mV=d.rfft,mO=d.round,mN=d.slice,mB=d.softmax,mG=d.spectrogram,mR=d.stack,mq=d.std_mean,m$=d.topk,mW=d.window_function,mU=d.zeros,mQ=d.zeros_like}}]);